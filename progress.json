[
  {
    "id": "47091419",
    "title": "Keep Android Open",
    "url": "https://f-droid.org/2026/02/20/twif.html",
    "summary": "This edition of \"This Week in F-Droid\" primarily serves as a critical warning about Android's future. The F-Droid team clarifies that Google's planned restrictions on sideloading apps (announced in August 2025) are still active, despite public perception that they were canceled. They argue that a misleading PR campaign has created a false sense of security, and the community is running out of time to prevent Google from becoming the sole gatekeeper for Android devices.\n\nIn response, F-Droid has launched a website and added warning banners to its official and basic app clients to raise awareness and encourage users to voice concerns to regulators. Other app stores like IzzyOnDroid and Obtainium have joined this effort.\n\nThe update also covers development news, announcing F-Droid Basic 2.0-alpha3 with new features like CSV export for installed apps and an install history. Community app highlights include updates to Conversations/Quicksy (which removed a Google library), Dolphin Emulator, ProtonVPN, and SimpleEmail.\n\nFinally, the weekly roundup notes that 287 apps were updated, 1 was newly added (NeoDB You), and 5 were removed from the repository.",
    "chinese_title": "保持安卓开放",
    "chinese_summary": "本期《F-Droid周报》主要作为对安卓未来发展的严重警告。F-Droid团队澄清，谷歌计划中对侧载应用的限制（于2025年8月宣布）仍在推进，尽管公众误以为该计划已被取消。团队指出，一场误导性的公关活动营造了虚假的安全感，而社区阻止谷歌成为安卓设备唯一守门人的时间已所剩无几。\n\n作为回应，F-Droid已上线专题网站，并在其官方及基础版应用客户端中添加警示横幅，以提高公众意识并鼓励用户向监管机构表达关切。IzzyOnDroid和Obtainium等其他应用商店也加入了这一行动。\n\n本期更新还涵盖了开发动态：F-Droid Basic 2.0-alpha3版本推出新功能，包括已安装应用的CSV导出和安装历史记录。社区应用亮点包括Conversations/Quicksy（移除了谷歌库）、Dolphin Emulator、ProtonVPN和SimpleEmail的更新。\n\n最后，本周汇总数据显示共有287款应用获得更新，新增1款应用（NeoDB You），另有5款应用从仓库中移除。"
  },
  {
    "id": "47088037",
    "title": "Ggml.ai joins Hugging Face to ensure the long-term progress of Local AI",
    "url": "https://github.com/ggml-org/llama.cpp/discussions/19759",
    "summary": "**Summary:** The team behind ggml.ai, the creators of the popular open-source project llama.cpp, is joining Hugging Face. The primary goal of this partnership is to ensure the long-term sustainability and progress of the local AI ecosystem.\n\n**Key Points:**\n*   **Continuity:** The ggml and llama.cpp projects will remain 100% open-source and community-driven. The core team will continue to lead and maintain them full-time.\n*   **Rationale:** The move formalizes an existing, strong collaboration with Hugging Face, which has been a major contributor to the projects. It provides the resources needed for the projects to scale and thrive.\n*   **Future Focus:** Joint efforts will prioritize:\n    1.  Seamless integration with Hugging Face's Transformers library for broader and faster model support.\n    2.  Improved packaging and user experience to make local AI inference more accessible.\n*   **Vision:** The shared long-term goal is to build the foundational technology to make open-source AI superintelligence efficiently run on consumer devices.\n\nThe announcement was met with widespread congratulations and excitement from the community, viewing Hugging Face as a natural and supportive home for the projects.",
    "chinese_title": "Ggml.ai加入Hugging Face，共同确保本地AI的长期发展。",
    "chinese_summary": "**摘要：** ggml.ai 团队，即广受欢迎的开源项目 llama.cpp 的创建者，将加入 Hugging Face。此次合作的主要目标是确保本地 AI 生态系统的长期可持续性与发展。\n\n**关键点：**\n*   **延续性：** ggml 与 llama.cpp 项目将保持 100% 开源并由社区驱动。核心团队将继续全职领导并维护这些项目。\n*   **缘由：** 此举旨在正式确立与 Hugging Face 已有的紧密合作，后者一直是这些项目的主要贡献者。这将为项目的规模化发展和繁荣提供所需资源。\n*   **未来重点：** 双方将优先致力于：\n    1.  与 Hugging Face 的 Transformers 库实现无缝集成，以提供更广泛、更快速的模型支持。\n    2.  改进打包和用户体验，使本地 AI 推理更易于使用。\n*   **愿景：** 双方的长期共同目标是构建基础技术，使开源 AI 超级智能能够高效地在消费级设备上运行。\n\n此公告获得了社区的广泛祝贺与热烈反响，大家普遍认为 Hugging Face 是这些项目自然而理想的支持平台。"
  },
  {
    "id": "47088181",
    "title": "I found a useful Git one liner buried in leaked CIA developer docs",
    "url": "https://spencer.wtf/2026/02/20/cleaning-up-merged-git-branches-a-one-liner-from-the-cias-leaked-dev-docs.html",
    "summary": "This article describes a Git command for cleaning up stale local branches, which the author discovered in leaked CIA developer documents.\n\nThe core problem is that local Git repositories accumulate merged branches (like old feature or hotfix branches), cluttering the output of `git branch`. While `git branch --merged` lists these, deleting them individually is tedious.\n\nThe key command automates this cleanup:\n1.  `git branch --merged origin/main` lists branches merged into `main`.\n2.  `grep -vE \"^\\s*(\\*|main|develop)\"` filters out and protects the current branch (`*`), `main`, and `develop`.\n3.  `xargs -n 1 git branch -d` safely deletes each remaining branch (using `-d` ensures only fully merged branches are removed).\n\nThe author recommends creating a Git alias (e.g., `ciaclean`) for this command to run it easily after deployments, turning a list of dozens of branches back to a manageable few and saving regular maintenance time.",
    "chinese_title": "我在泄露的CIA开发者文档中发现了一个实用的Git单行命令。",
    "chinese_summary": "本文介绍了一个用于清理过时本地Git分支的命令，该命令是作者在泄露的CIA开发者文档中发现的。\n\n核心问题在于本地Git仓库会积累已合并的分支（如旧的功能或热修复分支），导致`git branch`的输出杂乱。虽然`git branch --merged`能列出这些分支，但逐个删除非常繁琐。\n\n关键命令可自动完成清理：\n1. `git branch --merged origin/main`列出已合并到`main`的分支。\n2. `grep -vE \"^\\s*(\\*|main|develop)\"`过滤并保护当前分支（`*`）、`main`和`develop`分支。\n3. `xargs -n 1 git branch -d`安全删除每个剩余分支（使用`-d`确保仅删除完全合并的分支）。\n\n作者建议为此命令创建Git别名（如`ciaclean`），以便在部署后轻松运行，将数十个分支列表恢复为少数几个可管理的分支，从而节省日常维护时间。"
  },
  {
    "id": "47092578",
    "title": "I found a Vulnerability. They found a Lawyer",
    "url": "https://dixken.de/blog/i-found-a-vulnerability-they-found-a-lawyer",
    "summary": "A diving instructor and platform engineer discovered a critical security vulnerability in a major diving insurer's member portal during a trip in April 2025. The flaw allowed anyone to access full user profiles—including names, addresses, phone numbers, and dates of birth—by simply guessing sequential numeric user IDs and using a static default password that was never forced to be changed. The exposed data included information on minors.\n\nThe researcher followed responsible disclosure protocols, reporting the issue to both the organization and the Maltese national cybersecurity authority (CSIRT Malta), and set a standard 30-day embargo before public disclosure. Instead of gratitude, the organization's legal team responded with threats, citing potential criminal liability under Maltese law for the researcher's actions and demanding he sign a confidentiality agreement. They also blamed users for not changing their default passwords.\n\nThe vulnerability was fixed after the disclosure, with passwords reset and two-factor authentication planned. However, the researcher has not received confirmation that affected users were notified of the data breach as likely required by GDPR. The article highlights the tension between ethical security research and an organization's defensive legal posture, even when sensitive data is at risk.",
    "chinese_title": "我发现了一个漏洞。他们找来了一个律师。",
    "chinese_summary": "2025年4月，一名潜水教练兼平台工程师在旅行期间发现某大型潜水保险公司的会员门户存在严重安全漏洞。该漏洞允许任何人仅通过猜测连续数字用户ID并使用从未被强制更改的静态默认密码，即可访问完整的用户资料——包括姓名、地址、电话号码和出生日期。泄露的数据甚至包含未成年人信息。\n\n研究人员遵循负责任披露原则，将问题同时报告给该机构和马耳他国家网络安全中心（CSIRT Malta），并设定了标准的30天保密期后才公开披露。然而，该机构法律团队不仅未表感谢，反而以马耳他法律下的潜在刑事责任为由威胁研究人员，要求其签署保密协议，并指责用户未修改默认密码。\n\n漏洞在披露后已修复，密码被重置并计划启用双重认证。但研究人员尚未收到确认，证明受影响用户已按《通用数据保护条例》要求获知数据泄露情况。本文揭示了即使敏感数据面临风险，伦理安全研究与企业防御性法律立场之间的紧张关系。"
  },
  {
    "id": "47091071",
    "title": "Lil' Fun Langs",
    "url": "https://taylor.town/scrapscript-000",
    "summary": "This article highlights a collection of small, educational implementations of ML-style functional programming languages (like Haskell, OCaml, and F#). It focuses on projects that are notable for their minimal code size while implementing core features such as Hindley-Milner type inference, algebraic data types, pattern matching, and closures.\n\nThe author provides a comparative table of over 20 languages, detailing their size (from ~70 to ~30,000 lines of code), implementation language, supported features, and compilation target (e.g., interpreters, native code, or type checkers only). A second table breaks down the approximate code cost of adding specific language features.\n\nKey examples include:\n*   **MinCaml** (~2K LOC): A gold-standard native-code compiler for a strict functional language.\n*   **Algorithm W** and **THIH** (~300-400 LOC): Canonical, educational implementations of type inference for Haskell.\n*   **Ben Lynn's compiler** (~2K LOC): A remarkable bootstrapping chain that builds a near-Haskell 98 compiler from a tiny C runtime.\n*   **Hirrolot's CoC** (~70 LOC): An extremely compact implementation of the dependent Calculus of Constructions.\n\nThe article serves as both a reference and an inspiration, arguing that sophisticated type systems and language implementations can be built concisely, and it points readers to foundational papers and tutorials for further learning.",
    "chinese_title": "小趣语言",
    "chinese_summary": "本文重点介绍了一系列ML风格函数式编程语言（如Haskell、OCaml和F#）的小型教学实现。这些项目的突出特点在于用极简的代码量实现了核心功能，包括Hindley-Milner类型推断、代数数据类型、模式匹配和闭包。\n\n作者提供了一个包含20多种语言的对比表格，详细列出了它们的代码规模（从约70行到约30,000行）、实现语言、支持特性以及编译目标（例如解释器、原生代码或仅类型检查器）。第二张表格则分解了添加特定语言功能所需的近似代码量。\n\n关键案例如下：\n*   **MinCaml**（约2千行）：严格函数式语言的金标准原生代码编译器。\n*   **Algorithm W**与**THIH**（约300-400行）：Haskell类型推断的经典教学实现。\n*   **Ben Lynn的编译器**（约2千行）：通过微型C运行时构建近乎Haskell 98编译器的卓越自举链。\n*   **Hirrolot的CoC**（约70行）：依赖构造演算的极致精简实现。\n\n本文兼具参考价值与启发意义，论证了精妙的类型系统与语言实现可以简洁构建，同时为读者指明了深入学习所需的基础论文与教程资源。"
  },
  {
    "id": "47091469",
    "title": "Making frontier cybersecurity capabilities available to defenders",
    "url": "https://www.anthropic.com/news/claude-code-security",
    "summary": "Anthropic has launched Claude Code Security, a new AI-powered cybersecurity tool now available in a limited research preview for its Enterprise and Team customers. The tool is designed to help defenders find and fix complex software vulnerabilities that traditional, rule-based scanning tools often miss.\n\nUnlike conventional static analysis, Claude Code Security reads and reasons about code like a human researcher, understanding component interactions and data flow to detect subtle, context-dependent vulnerabilities. It employs a multi-stage verification process to reduce false positives, assigns severity ratings, and provides suggested patches along with a confidence score for each finding. Crucially, all fixes require human approval before implementation.\n\nThe capability builds on over a year of research, including competitive security testing and partnerships with national labs. Using the latest Claude Opus model, Anthropic’s team has already identified over 500 previously undetected vulnerabilities in open-source projects.\n\nAnthropic positions this release as a critical defensive measure, anticipating that AI will soon scan much of the world's code. The goal is to empower defenders to find and patch weaknesses before attackers can exploit them, thereby raising the overall security baseline. The company is offering expedited access to open-source maintainers and invites selected customers to collaborate on refining the tool.",
    "chinese_title": "将前沿网络安全能力提供给防御者",
    "chinese_summary": "Anthropic推出了Claude Code Security，这是一款新型AI驱动的网络安全工具，目前面向其企业及团队客户提供有限的研究预览。该工具旨在帮助防御者发现并修复传统基于规则的扫描工具常常遗漏的复杂软件漏洞。\n\n与传统的静态分析不同，Claude Code Security能像人类研究员一样阅读和推理代码，理解组件交互与数据流，从而检测出细微且依赖上下文的漏洞。它采用多阶段验证流程以减少误报，为每个发现分配严重性评级，并提供建议的补丁及置信度评分。关键的是，所有修复措施在实施前均需经过人工批准。\n\n这一能力基于超过一年的研究积累，包括竞争性安全测试以及与国家级实验室的合作。借助最新的Claude Opus模型，Anthropic团队已在开源项目中识别出500多个先前未被发现的漏洞。\n\nAnthropic将此次发布定位为一项关键防御措施，并预见AI将很快扫描全球大部分代码。其目标是让防御者能在攻击者利用漏洞前发现并修补弱点，从而提升整体安全基线。公司正为开源维护者提供快速接入通道，并邀请部分客户共同参与工具的优化工作。"
  },
  {
    "id": "47089213",
    "title": "Trump's global tariffs struck down by US Supreme Court",
    "url": "https://www.bbc.com/news/live/c0l9r67drg7t",
    "summary": "The US Supreme Court has struck down former President Trump's global tariff program, creating uncertainty for businesses that paid the levies. The court's ruling did not address whether companies are entitled to refunds, a sum estimated at around $130 billion.\n\nThis omission means the refund issue will likely be litigated in the Court of International Trade. While such refunds have been authorized in the past, the unprecedented scale of these tariffs presents a new challenge.\n\nPresident Trump has indicated he expects the refund process to be tied up in court for years, suggesting the White House will not release the funds quickly. Although a streamlined electronic claims process is possible, the prospect of lengthy and costly litigation means many smaller businesses may be unable to pursue their claims, potentially leaving them without reimbursement.",
    "chinese_title": "特朗普全球关税政策遭美国最高法院否决。",
    "chinese_summary": "美国最高法院推翻了前总统特朗普的全球关税计划，令已缴纳关税的企业陷入不确定性。法院裁决未涉及企业是否有权获得退税的问题，这笔款项估计约为1300亿美元。\n\n这一疏漏意味着退税问题很可能将在国际贸易法院进行诉讼。虽然过去曾批准过此类退税，但此次关税规模空前，带来了新的挑战。\n\n特朗普总统表示，他预计退税程序将在法院拖延数年，暗示白宫不会迅速发放资金。尽管可能建立简化的电子索赔流程，但漫长且昂贵的诉讼前景意味着许多小型企业可能无法追索其索赔，最终可能无法获得退款。"
  },
  {
    "id": "47092348",
    "title": "Testing Super Mario Using a Behavior Model Autonomously",
    "url": "https://testflows.com/blog/testing-super-mario-using-a-behavior-model-autonomously-part1/",
    "summary": "This article describes an autonomous testing approach for Super Mario Bros. using a mutation-based Genetic Algorithm (GA). Instead of manually writing tests, the system explores the game's state space by generating input sequences (button presses) through random bit-flip mutations.\n\nThe core algorithm maintains a population of \"paths\" (input sequences) and their associated fitness scores, based primarily on Mario's horizontal progress (x-position). It selects a promising path, replays it to a deterministic game state, and then extends it with new mutated inputs. Paths that lead to Mario's death are pruned. This cycle of selection, replay, mutation, and evaluation repeats continuously.\n\nThe implementation details a hybrid input generator that combines random fuzzy mutations with predefined, human-like move patterns to balance exploration and efficient progress. Path selection uses a weighted probability distribution to favor high-scoring paths while maintaining population diversity. Scoring prioritizes level completion, then distance traveled, then speed.\n\nThe author frames this as a specialized GA, where input sequences act as genotypes enabling specific in-game states. While the system currently uses only mutation (not crossover), it effectively demonstrates how autonomous exploration can systematically test complex software by evolving successful behavioral strategies.",
    "chinese_title": "基于行为模型自主测试超级马里奥",
    "chinese_summary": "本文介绍了一种基于变异遗传算法的《超级马里奥兄弟》自主测试方法。该系统无需手动编写测试用例，而是通过随机位翻转变异生成输入序列（按键操作），从而探索游戏的状态空间。\n\n核心算法维护着一组“路径”（输入序列）及其适应度评分，评分主要依据马里奥的水平前进距离（x轴位置）。算法选择一条有潜力的路径，将其回放至确定的游戏状态，随后通过新变异的输入进行延伸。导致马里奥死亡的路径会被剔除。这种选择、回放、变异和评估的循环持续进行。\n\n实现细节包括一种混合输入生成器，它结合了随机模糊变异与预定义的类人操作模式，以平衡探索效率与推进速度。路径选择采用加权概率分布，既倾向于高分路径，又保持种群多样性。评分机制优先考量关卡完成度，其次为行进距离，最后是移动速度。\n\n作者将其定义为一种特殊遗传算法：输入序列作为基因型，对应特定的游戏内状态。尽管当前系统仅使用变异（未采用交叉操作），但它有效展示了如何通过演化成功行为策略，以自主探索的方式系统化测试复杂软件。"
  },
  {
    "id": "47086181",
    "title": "The path to ubiquitous AI (17k tokens/sec)",
    "url": "https://taalas.com/the-path-to-ubiquitous-ai/",
    "summary": "Taalas is a company aiming to make AI ubiquitous by solving its two main adoption barriers: high latency and high cost. It does this by transforming AI models directly into specialized, custom silicon chips.\n\nTheir core innovation involves three principles: 1) **Total specialization**, creating optimal hardware for each individual model; 2) **Merging storage and computation** on a single chip at DRAM density, eliminating the speed bottleneck between memory and processors; and 3) **Radical simplification** of the hardware stack, avoiding complex, expensive components like HBM and liquid cooling.\n\nThe result is their \"Hardcore Models.\" Their first product is a hard-wired Llama 3.1 8B model that achieves **17,000 tokens/second**—nearly 10x faster than current leaders—while being 20x cheaper to build and 10x more power-efficient. They acknowledge this first-gen model has some quality trade-offs due to aggressive quantization, which their second-generation silicon (using standard 4-bit formats) will address.\n\nTaalas emphasizes its lean, craft-focused approach, having developed this product with a team of 24 and $30M of its funding. They are releasing it as a beta service to let developers experiment with near-zero latency and cost, paving the way for upcoming mid-sized and frontier models. Their goal is to enable a new paradigm of instantaneous, affordable AI.",
    "chinese_title": "通往普及人工智能之路（每秒17千令牌）",
    "chinese_summary": "Taalas是一家致力于通过解决人工智能两大主要应用障碍——高延迟和高成本——来让人工智能无处不在的公司。其实现方式是将人工智能模型直接转化为专用的定制硅芯片。\n\n他们的核心创新基于三大原则：1）**完全专业化**，为每个独立模型创建最优硬件；2）在DRAM密度级别上实现**存储与计算的单芯片融合**，消除内存与处理器之间的速度瓶颈；3）**硬件栈的彻底简化**，避免使用HBM和液冷等复杂昂贵组件。\n\n由此诞生了他们的“硬核模型”。其首款产品是一个硬连线的Llama 3.1 8B模型，可实现**每秒17,000个token**的处理速度——比当前领先方案快近10倍——同时构建成本降低20倍，能效提升10倍。他们承认第一代模型因采用激进的量化技术存在质量折衷，而第二代芯片（采用标准4位格式）将解决这一问题。\n\nTaalas强调其精益求精、注重工艺的开发模式，仅用24人团队和3000万美元资金就完成了产品研发。他们正以测试服务形式发布该产品，让开发者能以近乎零延迟和零成本的代价进行实验，为即将推出的中型和前沿模型铺平道路。他们的目标是开创即时、普惠的人工智能新范式。"
  },
  {
    "id": "47091748",
    "title": "Facebook is absolutely cooked",
    "url": "https://pilk.website/3/facebook-is-absolutely-cooked",
    "summary": "The author describes logging into Facebook for the first time in eight years and finding the main News Feed overrun with low-quality, algorithmically-recommended content. Instead of posts from friends, the feed was dominated by AI-generated \"thirst trap\" images of young women, sloppy memes, and engagement bait, including some content that appeared to sexualize minors.\n\nThe author expresses shock that this \"slop conveyor belt\" has become the core experience on the platform that defined social media, noting it seems designed to exploit \"lizard-brain\" engagement. They speculate the algorithm may target demographics like \"lonely old\" men, and question whether the degradation was gradual for regular users or acute for inactive accounts like theirs.\n\nThe experience, culminating in seeing AI-generated images of underage-looking girls, led the author to log off in disgust, vowing only to return for practical necessities like school updates. The core argument is that Facebook's primary feed has devolved into a spammy, AI-driven wasteland of low-quality and potentially harmful content.",
    "chinese_title": "脸书彻底玩完了。",
    "chinese_summary": "作者描述了时隔八年首次登录Facebook，发现首页动态已被低质量的算法推荐内容淹没。原本应展示好友动态的信息流，如今充斥着AI生成的年轻女性“钓鱼”照片、粗制滥造的梗图以及互动诱饵内容，其中甚至包含一些疑似对未成年人进行性暗示的帖子。\n\n作者震惊于这个“垃圾内容流水线”竟已成为这个定义过社交媒体的平台的核心体验，指出其设计似乎专门利用人类“蜥蜴脑”式的本能参与。他们推测算法可能针对“孤独老年男性”等群体，并质疑这种内容退化对常驻用户是渐进的，还是对自己这类非活跃账户尤为剧烈。\n\n最终，当看到AI生成的未成年模样女孩图像时，作者在厌恶中退出登录，发誓今后仅为学校通知等实际需求才会重返。核心论点是：Facebook的主信息流已退化为一个由AI驱动的、充斥低质量且潜在有害内容的垃圾信息荒原。"
  },
  {
    "id": "47088685",
    "title": "Child's Play: Tech's new generation and the end of thinking",
    "url": "https://harpers.org/archive/2026/03/childs-play-sam-kriss-ai-startup-roy-lee/",
    "summary": "This article profiles Chungin \"Roy\" Lee, the controversial co-founder of the AI startup Cluely, to critique a new, \"highly agentic\" generation in Silicon Valley that values relentless action over thought.\n\nThe piece opens by describing San Francisco's alienating atmosphere, filled with absurd tech ads and social decay, setting the stage for Cluely's disruptive presence. Cluely's product—an AI tool that assists with meetings and calls—is framed as a symbol of a deeper shift: the industry's belief in an impending \"bifurcation event.\" The future, it argues, will not reward intelligence or expertise, which AI will supersede, but rather \"agency\"—the bulldozer-like personality trait of acting without permission or reflection.\n\nRoy Lee is presented as the archetype of this new overclass. His story—using AI to cheat on schoolwork and job interviews, getting expelled from Columbia, and building a viral startup—exemplifies a philosophy where \"the future won’t reward effort. It’ll reward leverage.\" The article details his frat-house company culture and unsettlingly direct personality, suggesting he and his peers envision a future where humans simply execute machine instructions.\n\nUltimately, the article uses Lee and Cluely to argue that tech's new ethos champions mindless action over human reason, creativity, and thought, potentially consigning those who rely on such skills to irrelevance.",
    "chinese_title": "儿童游戏：科技新生代与思考的终结",
    "chinese_summary": "本文聚焦人工智能初创公司Cluely的争议性联合创始人李忠仁（绰号“罗伊”），旨在批判硅谷新一代“高度自主”的价值观——他们崇尚无休止的行动，而非思考。\n\n文章开篇描绘了旧金山疏离的社会氛围：荒诞的科技广告与城市衰败景象交织，为Cluely的颠覆性登场铺设背景。该公司的产品——一款辅助会议与通话的AI工具——被视作深层变革的象征：行业坚信“分化事件”即将来临。文章指出，未来奖赏的将不是智力或专业知识（这些终将被AI取代），而是“自主力”——一种推土机般无需许可、不经反思就行动的人格特质。\n\n罗伊·李正是这一新兴精英阶层的典型代表。他的经历——利用AI作弊完成课业与面试、被哥伦比亚大学开除、创立病毒式传播的初创公司——诠释了其哲学信条：“未来不会奖赏努力，而会奖赏杠杆效应。”文章详述了他 frat-house式的公司文化及其令人不安的直率性格，暗示罗伊及其同辈所构想的未来里，人类只需执行机器指令。\n\n最终，文章借李忠仁与Cluely案例论证：科技界的新思潮正推崇无脑行动，凌驾于人类理性、创造力与思考之上，而那些依赖这些传统能力的人，或将面临被时代淘汰的命运。"
  },
  {
    "id": "47044700",
    "title": "How to Review an AUR Package",
    "url": "https://bertptrs.nl/2026/01/30/how-to-review-an-aur-package.html",
    "summary": "This article explains how to review Arch User Repository (AUR) packages for safety, prompted by a recent malware incident. The AUR is a community repository of PKGBUILD scripts—bash scripts that build software packages—which anyone can upload. Since these scripts run on your machine, vetting them is crucial.\n\nA PKGBUILD contains metadata (like `pkgname`, `pkgver`) and build functions (`prepare()`, `build()`, `check()`, `package()`). Key review steps include:\n\n1.  **Check the sources:** Verify that download URLs point to official, trusted upstream projects. Patches should be from legitimate sources.\n2.  **Review build steps:** Ensure functions only run standard packaging commands. No downloads should occur in `build()`, `check()`, or `package()`, and scripts should never use `sudo`.\n3.  **Scrutinize install scripts and hooks:** These run as root during package management. Their presence is rare and warrants extra caution.\n\nThe article advises that if you don't understand a PKGBUILD, don't install it. If you suspect a package is malicious, report it via the #archlinux-aur IRC channel, forums, or mailing list for maintainers to investigate.\n\nFinally, the author notes that the AUR's trust-based, open system is aging but functional, and improvements would require community effort.",
    "chinese_title": "如何审查AUR软件包",
    "chinese_summary": "本文旨在说明如何审查Arch用户仓库（AUR）软件包的安全性，此举源于近期发生的恶意软件事件。AUR是一个由社区维护的PKGBUILD脚本仓库——这些用于构建软件包的bash脚本可由任何人上传。由于这些脚本会在用户设备上运行，严格审查至关重要。\n\nPKGBUILD包含元数据（如`pkgname`、`pkgver`）和构建函数（`prepare()`、`build()`、`check()`、`package()`）。关键审查步骤包括：\n\n1.  **检查软件源：** 确认下载链接指向官方可信的上游项目，补丁文件应来自合法来源。\n2.  **审查构建步骤：** 确保函数仅运行标准打包命令。`build()`、`check()`或`package()`中不应包含下载操作，且脚本绝不应使用`sudo`。\n3.  **仔细检查安装脚本与钩子：** 这些内容会在软件包管理期间以root权限运行。此类脚本较为罕见，需格外谨慎对待。\n\n文章建议：若无法理解PKGBUILD内容，请勿安装对应软件包。若怀疑某软件包存在恶意行为，可通过#archlinux-aur IRC频道、论坛或邮件列表向维护者举报以供调查。\n\n最后作者指出，AUR基于信任的开放体系虽显陈旧但仍可运作，其改进需要社区共同努力。"
  },
  {
    "id": "47090610",
    "title": "Legion Health (YC) Is Hiring Cracked SWEs for Autonomous Mental Health",
    "url": "https://jobs.ashbyhq.com/legionhealth/ffdd2b52-eb21-489e-b124-3c0804231424",
    "summary": "Legion Health, a Y Combinator-backed startup, is seeking a Founding Engineer to join its team. The company operates in the AI-native mental health care space, focusing on building autonomous systems to deliver therapy and support.\n\nKey company details include significant traction, with over $3.3 million in annual recurring revenue (ARR) and more than $7 million in total funding raised.\n\nThe role is aimed at a senior, \"cracked\" (exceptional) software engineer who will be instrumental in shaping the core technology and product. The position implies high responsibility and impact, typical of an early-stage founding role, with a focus on developing AI-driven solutions for mental health services.",
    "chinese_title": "Legion Health（YC）正在招聘顶尖软件工程师，致力于自主心理健康服务。",
    "chinese_summary": "Legion Health是一家获得Y Combinator支持的初创公司，现正招募一位创始工程师加入团队。该公司专注于人工智能原生心理健康护理领域，致力于构建自主系统以提供治疗和支持服务。\n\n公司关键数据表现强劲：年度经常性收入（ARR）已超过330万美元，累计融资总额逾700万美元。\n\n该职位面向资深且能力出众的软件工程师，入选者将在塑造核心技术与产品方面发挥关键作用。作为典型的早期创始团队成员，职位意味着高责任与高影响力，工作重心将围绕开发面向心理健康服务的人工智能驱动解决方案展开。"
  },
  {
    "id": "47085425",
    "title": "Untapped Way to Learn a Codebase: Build a Visualizer",
    "url": "https://jimmyhmiller.com/learn-codebase-visualizer",
    "summary": "This article outlines a method for learning a complex, unfamiliar codebase by building a visualizer and using a specific bug as a learning tool. The author chooses the Next.js/Turbopack project to investigate why an unused enum isn't being removed (\"tree-shaken\") during a Turbopack build.\n\nThe process begins with setting a clear learning goal rather than aiming to fix the bug immediately. The author starts by reproducing the issue and then embarks on a \"side quest\" to set up a local development environment, uncovering and fixing a build script bug in the process.\n\nWith the environment working, the investigation reveals that Turbopack's experimental tree-shaking feature is off by default and crashes when enabled. This shifts the focus from tree-shaking to understanding the general bundling flow. The author uses simple techniques—like adding `println!` statements and searching for file operations—to trace how code is parsed by SWC and ultimately written into output chunks.\n\nThe core takeaway is a hands-on, exploratory approach: use a concrete issue to drive exploration, accept necessary detours, and employ basic tactics (like strategic logging) to incrementally map out how the system works, building understanding piece by piece.",
    "chinese_title": "学习代码库的未开发途径：构建可视化工具",
    "chinese_summary": "本文概述了一种通过构建可视化工具并以特定bug作为学习手段，来理解复杂陌生代码库的方法。作者选择Next.js/Turbopack项目作为案例，探究为何在Turbopack构建过程中未使用的枚举未被移除（即“tree-shaken”）。\n\n该过程始于设定明确的学习目标，而非立即修复bug。作者首先复现问题，随后通过搭建本地开发环境的“支线任务”，在此过程中发现并修复了一个构建脚本的缺陷。\n\n环境就绪后，调查显示Turbopack的实验性tree-shaking功能默认关闭，且在启用时会崩溃。这使得关注点从tree-shaking转向理解整体打包流程。作者运用简单技巧——如添加`println!`语句和搜索文件操作——追踪代码如何被SWC解析并最终写入输出块。\n\n核心启示在于实践探索式学习：以具体问题驱动探索，接受必要的迂回过程，并运用基础策略（如针对性日志记录）逐步梳理系统运作机制，逐块构建对系统的理解。"
  },
  {
    "id": "47048181",
    "title": "Do you want to build a community where users search or hang? (2021)",
    "url": "https://www.mooreds.com/wordpress/archives/3486",
    "summary": "Based on the article, the author argues that the most successful and sustainable online communities are built around **search** rather than **hanging out**.\n\nThe core distinction is:\n*   **Search Communities:** Users come with a specific goal or need (e.g., finding a solution, getting advice, researching a purchase). The community's value is in its **accumulated knowledge** (FAQs, forums, archives). Examples include Stack Overflow, TripAdvisor, and support forums.\n*   **Hangout Communities:** Users come primarily for social interaction, entertainment, or connection (e.g., Facebook, Twitter, Discord servers). The value is in the **live conversation and network**.\n\nThe author's key points are:\n1.  **Search communities are easier to start and sustain.** You can begin by creating a valuable resource (like a blog or knowledge base) that attracts people searching for answers. This \"content-first\" approach provides immediate value.\n2.  **They have a clearer purpose and value proposition.** It's easier to attract and retain members when the community solves a specific, recurring problem.\n3.  **They are more durable.** While social platforms and trends change, people's need to find answers to important problems is constant. The archived knowledge becomes a lasting asset.\n4.  **\"Hangout\" communities are much harder to build from scratch.** They require a critical mass of engaged users from day one to generate the social interaction people seek, creating a cold-start problem.\n\nThe article concludes that founders should focus on building a community where users come to **search** for valuable information. While \"hanging out\" may develop organically over time, making it the primary goal from the outset is a much riskier strategy.",
    "chinese_title": "你想建立一个用户搜索或闲逛的社区吗？（2021）",
    "chinese_summary": "根据文章所述，作者认为最成功且可持续的在线社区是围绕**搜索**而非**闲逛**建立的。\n\n核心区别在于：\n*   **搜索型社区：** 用户带着特定目标或需求而来（例如寻找解决方案、获取建议、研究购买决策）。社区的价值在于其**积累的知识**（常见问题解答、论坛、存档）。例如 Stack Overflow、TripAdvisor 和支持论坛。\n*   **闲逛型社区：** 用户主要为社交互动、娱乐或建立联系而来（例如 Facebook、Twitter、Discord 服务器）。其价值在于**实时对话和网络**。\n\n作者的主要观点是：\n1.  **搜索型社区更容易启动和维持。** 你可以从创建有价值的资源（如博客或知识库）开始，吸引那些寻找答案的人。这种“内容优先”的方法能提供即时价值。\n2.  **它们有更明确的目标和价值主张。** 当社区能解决一个具体的、反复出现的问题时，更容易吸引和留住成员。\n3.  **它们更具持久性。** 虽然社交平台和趋势会变化，但人们寻找重要问题答案的需求是恒定的。存档的知识成为持久的资产。\n4.  **“闲逛型”社区从零开始构建要困难得多。** 它们需要从一开始就有大量积极参与的用户来产生人们所寻求的社交互动，这就产生了冷启动问题。\n\n文章总结道，创始人应专注于建立用户前来**搜索**有价值信息的社区。虽然“闲逛”可能会随着时间的推移自然形成，但将其作为最初的主要目标是一种风险高得多的策略。"
  },
  {
    "id": "47087719",
    "title": "PayPal discloses data breach that exposed user info for 6 months",
    "url": "https://www.bleepingcomputer.com/news/security/paypal-discloses-data-breach-exposing-users-personal-information/",
    "summary": "PayPal has notified customers of a data breach stemming from a software error in its PayPal Working Capital (PPWC) loan application. The error exposed sensitive personal information, including names, email addresses, phone numbers, business addresses, Social Security numbers, and dates of birth.\n\nThe exposure occurred from July 1, 2025, until PayPal discovered and blocked access to the data on December 13, 2025. The company attributed the incident to a specific code change, which it has since reversed.\n\nIn a subsequent update, a PayPal spokesperson clarified that the company's systems were not directly breached and that approximately 100 customers were potentially impacted. Unauthorized transactions were detected on a small number of accounts as a direct result, and those customers have been refunded.\n\nAs a remedy, PayPal is offering affected users two years of free credit monitoring and identity restoration services. The company has also reset passwords for all impacted accounts. Affected customers are advised to monitor their accounts and credit reports for suspicious activity.\n\nThis incident follows a previous data breach in late 2022, for which PayPal reached a $2 million settlement with New York State in early 2025 over cybersecurity regulation failures.",
    "chinese_title": "PayPal披露数据泄露事件，用户信息暴露长达六个月。",
    "chinese_summary": "PayPal已通知客户，其PayPal Working Capital（PPWC）贷款应用程序因软件错误导致数据泄露。该错误暴露了包括姓名、电子邮件地址、电话号码、公司地址、社会安全号码和出生日期在内的敏感个人信息。\n\n此次数据暴露发生于2025年7月1日至2025年12月13日，直至PayPal发现并阻止了对数据的访问。公司将此事件归因于一次特定的代码变更，并已将其恢复。\n\n在后续更新中，PayPal发言人澄清，公司系统并未被直接入侵，大约有100名客户可能受到影响。直接导致少数账户出现未经授权的交易，相关客户已获得退款。\n\n作为补救措施，PayPal为受影响的用户提供两年免费的信用监控和身份恢复服务。公司还重置了所有受影响账户的密码。建议受影响客户监控其账户和信用报告，以防可疑活动。\n\n此次事件之前，PayPal曾在2022年底发生另一起数据泄露事件，并于2025年初因网络安全监管失职向纽约州支付了200万美元的和解金。"
  },
  {
    "id": "47072849",
    "title": "The Popper Principle",
    "url": "https://theamericanscholar.org/the-popper-principle/",
    "summary": "In his article \"The Popper Principle,\" Robert Zaretsky examines Karl Popper's controversial critique of Plato as a philosophical forerunner of totalitarianism. Popper, a 20th-century philosopher of science, argued in his 1945 work *The Open Society and Its Enemies* that Plato’s ideal Republic—with its rigid class structure, \"noble lies,\" and philosopher-kings—was a blueprint for a \"closed society\" designed to arrest all social and political change. Popper saw direct intellectual lines from Plato’s vision to the 20th century’s totalitarian regimes and their pseudoscientific ideologies.\n\nWriting from exile as a Jewish academic fleeing Nazism, Popper interpreted Plato’s model as fundamentally opposed to the \"critical attitude\" and fallibilism essential to an \"open society,\" where truth is tested through debate and experience. While acknowledging his own emotional and harsh tone—informed by the Holocaust's horrors, which claimed members of his family—Popper stood by his central thesis.\n\nZaretsky notes that this is one interpretation among many, and that Plato’s dialogic form itself encourages critical thought. He concludes by highlighting Popper’s enduring warning: the appeal of closed societies lies not only with power-hungry rulers but also with citizens who fear the uncertainties of freedom. Ultimately, Popper saw the study of history not as a cause for despair but as a call to actively defend open societies, reason, and justice.",
    "chinese_title": "波普尔原则",
    "chinese_summary": "在《波普尔原则》一文中，罗伯特·扎雷茨基审视了卡尔·波普尔对柏拉图作为极权主义哲学先驱的争议性批判。波普尔作为20世纪科学哲学家，在其1945年的著作《开放社会及其敌人》中提出，柏拉图的理想国——以其僵化的阶级结构、“高贵的谎言”和哲人王统治——是一个旨在扼杀一切社会与政治变革的“封闭社会”蓝图。波普尔认为，从柏拉图的构想到20世纪极权主义政权及其伪科学意识形态，存在着直接的思想脉络。\n\n身为逃离纳粹迫害的犹太流亡学者，波普尔将柏拉图模式解读为根本上与“批判态度”和可错论相悖的体系，而这些正是“开放社会”的核心——在开放社会中，真理通过辩论与实践检验而确立。尽管波普尔承认自己受大屠杀（其家族成员亦遭迫害）影响而笔调激烈，但他始终坚守这一核心论点。\n\n扎雷茨基指出，这只是众多解读之一，且柏拉图对话录的形式本身便鼓励批判性思考。他最后强调波普尔经久不衰的警示：封闭社会的吸引力不仅源于权力饥渴的统治者，也来自畏惧自由不确定性的公民。归根结底，波普尔将历史研究视为对积极捍卫开放社会、理性与正义的呼唤，而非绝望的缘由。"
  },
  {
    "id": "47089907",
    "title": "No Skill. No Taste",
    "url": "https://blog.kinglycrow.com/no-skill-no-taste/",
    "summary": "This article argues that the proliferation of AI-generated code has exposed a fundamental problem in tech: a widespread lack of both skill and taste. The author contends that while LLMs create an \"illusion of a lower barrier to entry,\" the real barrier has always been taste—the ability to discern what is genuinely interesting, useful, or well-executed.\n\nThey observe that many new, derivative \"vibe-coded\" applications flood platforms like Hacker News, representing \"slop\" from builders with neither technical skill nor good taste. However, the core issue isn't the use of LLMs itself. The author notes that even simple or technically flawed projects can succeed if they possess strong, resonant taste (citing examples like a self-destructing message app or the popular OpenClaw).\n\nThe piece concludes that LLMs actually amplify the importance of taste. As it becomes easier for anyone to build, the market will be saturated with low-quality output, making discerning taste the critical differentiator. The author advises aspiring builders to focus on developing taste before publicly sharing their work.",
    "chinese_title": "没有技巧。没有品味。",
    "chinese_summary": "本文指出，人工智能生成代码的泛滥暴露了科技行业的一个根本问题：普遍缺乏技能与审美。作者认为，尽管大语言模型营造了“准入门槛降低的假象”，但真正的门槛始终是审美——即辨别何为真正有趣、有用或执行出色的能力。\n\n作者观察到，许多缺乏原创性、仅凭“感觉编码”的衍生应用充斥了Hacker News等平台，这些出自既无技术能力又缺乏审美的构建者之手的“粗制品”泛滥成灾。然而，核心问题并非大语言模型本身的使用。作者指出，即使是简单或存在技术缺陷的项目，只要具备强烈共鸣的审美（例如自毁消息应用或流行的OpenClaw），仍可能获得成功。\n\n文章总结道，大语言模型实际上放大了审美的重要性。随着构建门槛降低，市场将充斥低质量产出，这使得卓越的审美成为关键区分因素。作者建议有志的构建者在公开分享作品前，应优先培养自身的审美能力。"
  },
  {
    "id": "47085387",
    "title": "Raspberry Pi Pico 2 at 873.5MHz with 3.05V Core Abuse",
    "url": "https://learn.pimoroni.com/article/overclocking-the-pico-2",
    "summary": "This article details an extreme overclocking experiment on the Raspberry Pi Pico 2 (RP2350), pushing it to 873.5 MHz using dry ice cooling and an external voltage supply.\n\nThe initial tests with the onboard regulator showed the chip could reach 678 MHz at 2.2V. To go further, the team used an external power supply connected to a test point on the board, allowing them to increase the core voltage beyond the regulator's limit. With dry ice cooling to -80°C, they achieved stable operation at 861.6 MHz with 3.05V and briefly hit 873.5 MHz.\n\nKey findings include:\n*   The RP2350 proved remarkably resilient, surviving high voltages (up to 3.3V) and extreme cold.\n*   Performance gains diminished at higher voltages, with current draw reaching ~1A.\n*   The built-in \"automatic overclocking\" via the ring oscillator was less stable than using the crystal oscillator at extreme settings.\n*   The RISC-V cores on the RP2350 showed slightly better performance per MHz (~5%) on the CoreMark benchmark than the Arm cores for integer tasks.\n\nThe experiment demonstrated the significant overclocking headroom of the Pico 2, though it required extreme cooling and external power to achieve its maximum recorded speed.",
    "chinese_title": "树莓派Pico 2以873.5MHz频率与3.05V核心电压极限超频",
    "chinese_summary": "本文详细介绍了对树莓派Pico 2（RP2350）进行的极限超频实验：通过干冰冷却与外接电压供应，成功将其推至873.5 MHz。\n\n初期使用板载稳压器的测试显示，芯片在2.2V电压下可达678 MHz。为进一步突破，团队改用外接电源连接板载测试点，使核心电压突破稳压器限制。在干冰冷却至-80°C的条件下，系统以3.05V电压稳定运行于861.6 MHz，并短暂达到873.5 MHz。\n\n主要发现包括：\n*   RP2350展现出卓越的耐受性，可承受高达3.3V的电压与极端低温；\n*   电压越高性能增益越有限，电流消耗可达约1A；\n*   在极端设置下，通过环形振荡器实现的“自动超频”不如使用晶体振荡器稳定；\n*   在CoreMark整数任务测试中，RP2350的RISC-V核心每MHz性能比Arm核心约高5%。\n\n实验证明了Pico 2具备巨大的超频潜力，但需借助极端冷却与外接电源才能达到其最高记录速度。"
  },
  {
    "id": "47092006",
    "title": "Wikipedia bans Archive.today after site executed DDoS and altered web captures",
    "url": "https://arstechnica.com/tech-policy/2026/02/wikipedia-bans-archive-today-after-site-executed-ddos-and-altered-web-captures/",
    "summary": "The English-language Wikipedia has decided to ban and remove all links to the archive site Archive.today (and its related domains). This decision followed a community discussion that revealed two major issues: the site was used to launch a DDoS attack against a blogger, and its operators were found to have tampered with archived webpage content.\n\nThe DDoS targeted Jani Patokallio, who had written a blog post speculating about the identity of Archive.today's founder. In the ensuing dispute, the archive's maintainer, using the alias \"Nora,\" made threats against Patokallio. Wikipedia editors later discovered that Archive.today had altered archived pages, inserting Patokallio's name into captures to further the personal grudge.\n\nThis evidence of tampering directly undermined the core argument for keeping Archive.today—its utility for verifiability—as the archives could no longer be trusted as accurate snapshots. The Wikipedia community reached a consensus to deprecate the site, blacklist its domains, and begin the process of removing or replacing over 695,000 existing links with alternatives like the Internet Archive.\n\nThe Wikimedia Foundation had also indicated it might intervene due to the security risk posed by the DDoS code. Patokallio welcomed the decision, noting it highlights the need for a reliable archival service.",
    "chinese_title": "维基百科封禁Archive.today，因其发起DDoS攻击并篡改网页存档",
    "chinese_summary": "英文维基百科决定禁止并移除所有指向存档网站Archive.today（及其相关域名）的链接。这一决定源于社区讨论中揭露的两个主要问题：该网站曾被用于对一名博主发起DDoS攻击，且其运营者被发现篡改了已存档的网页内容。\n\n此次DDoS攻击针对的是曾撰写博文推测Archive.today创始人身份的贾尼·帕托卡利奥。在随后的争执中，该存档网站的维护者使用化名“诺拉”对帕托卡利奥发出威胁。维基百科编辑后来发现，Archive.today篡改了存档页面，在网页快照中插入帕托卡利奥的名字以延续私人恩怨。\n\n这种篡改证据直接动摇了保留Archive.today的核心理由——其可验证性价值——因为这些存档已无法再被信任为准确的网页快照。维基百科社区达成共识，决定弃用该网站，将其域名列入黑名单，并开始移除或替换超过69.5万个现有链接，转而使用互联网档案馆等替代服务。\n\n维基媒体基金会也曾表示，可能因DDoS代码带来的安全风险进行干预。帕托卡利奥对此决定表示欢迎，指出这凸显了对可靠存档服务的需求。"
  },
  {
    "id": "47030387",
    "title": "The Rediscovery of 103 Hokusai Lost Sketches (2021)",
    "url": "https://japan-forward.com/eternal-hokusai-the-rediscovery-of-103-hokusai-lost-sketches/",
    "summary": "In 2021, it was reported that 103 previously lost sketches by the renowned Japanese artist Hokusai, intended for an unpublished work titled *The Great Picture Book of Everything*, were rediscovered and acquired by the British Museum.\n\nCreated around 1824-1833, the ambitious project was abandoned, possibly due to personal hardships Hokusai faced in the 1820s. The sketches, which never returned to Japan, resurfaced in Europe in June 2019 at a Paris auction, where they were recognized by a collector. They were subsequently purchased by the British Museum with art fund assistance.\n\nThe drawings cover a vast range of subjects, including historical, mythological, and religious figures from Japan and beyond, as well as animals and landscapes. They showcase Hokusai's wide knowledge and inventive creativity, featuring figures like the Daoist Zhou Sheng attempting to seize the moon.\n\nThis acquisition brought the British Museum's Hokusai collection to over 1,000 works. The museum planned a 2021 exhibition for the sketches and has made high-resolution digital versions available online. The discovery is considered one of the significant art finds of the 21st century.",
    "chinese_title": "葛饰北斋103幅失传素描重见天日（2021）",
    "chinese_summary": "2021年，据报道，日本著名艺术家葛饰北斋为未出版作品《万物绘本大全图》绘制的103幅此前遗失的草图被重新发现，并由大英博物馆购得。\n\n这些创作于1824-1833年间的草图原属一项宏大计划，后因葛饰北斋在19世纪20年代遭遇的个人困境而被搁置。这批从未回归日本的画作于2019年6月在巴黎拍卖会上重现欧洲，被一位收藏家辨识后，由大英博物馆在艺术基金资助下购藏。\n\n草图题材包罗万象，涵盖日本及世界各地的历史、神话、宗教人物，以及动物与自然景观。作品展现了葛饰北斋广博的知识储备与非凡创造力，其中包含如道教人物周生试图摘月等生动场景。\n\n此次收购使大英博物馆的葛饰北斋藏品总数突破千件。馆方原计划于2021年举办专题展览，并已将高清数字版本发布于网络。此次发现被视为21世纪重要的艺术发现之一。"
  },
  {
    "id": "47083648",
    "title": "Consistency diffusion language models: Up to 14x faster, no quality loss",
    "url": "https://www.together.ai/blog/consistency-diffusion-language-models",
    "summary": "**Summary**\n\nResearchers have introduced Consistency Diffusion Language Models (CDLM), a new method that significantly accelerates the inference speed of Diffusion Language Models (DLMs) without compromising output quality. DLMs generate text by iteratively refining a masked sequence, offering potential for parallel generation but suffering from two key inefficiencies: expensive, non-cachable bidirectional attention and the need for many refinement steps.\n\nCDLM addresses these bottlenecks through a post-training distillation recipe. It trains a student model using trajectories collected from a teacher DLM. The student employs a block-wise causal attention mask, enabling exact Key-Value (KV) caching for finalized blocks—a major efficiency gain over standard DLMs. The training combines three objectives: a distillation loss to match the teacher's predictions, a consistency loss to ensure stable multi-step refinement within a block, and a standard denoising loss to preserve general capabilities.\n\nThe result is a model that can finalize multiple tokens per step reliably. Evaluations show CDLM reduces required refinement steps by 4.1x to 7.7x compared to baseline DLMs on math and coding tasks. This translates to latency speedups of up to 14.5x and higher throughput, while maintaining competitive accuracy. The block-wise design positions CDLM in a hardware-efficient \"sweet spot,\" offering better arithmetic intensity than autoregressive models at small batch sizes without the extreme compute demands of full bidirectional DLMs. The work demonstrates that with targeted training, diffusion-based text generation can become a highly efficient alternative to autoregressive models.",
    "chinese_title": "一致性扩散语言模型：速度提升高达14倍，质量无损",
    "chinese_summary": "**摘要**\n\n研究人员提出了一致性扩散语言模型（CDLM），这是一种新方法，能在不牺牲输出质量的前提下显著提升扩散语言模型（DLM）的推理速度。DLM通过迭代优化掩码序列生成文本，具备并行生成潜力，但存在两大低效问题：昂贵且无法缓存的全局双向注意力机制，以及需要大量优化步骤。\n\nCDLM通过一种后训练蒸馏方案解决了这些瓶颈。该方法利用从教师DLM收集的轨迹训练学生模型。学生模型采用分块因果注意力掩码，使得已生成块能够进行精确的键值（KV）缓存——这是相对于标准DLM的一项重大效率提升。训练结合了三个目标：匹配教师预测的蒸馏损失、确保块内多步优化稳定的一致性损失，以及保持通用能力的标准去噪损失。\n\n最终得到的模型能够可靠地在每一步生成多个已确定的词元。评估显示，在数学和编程任务上，CDLM相比基线DLM将所需优化步骤减少了4.1至7.7倍。这相当于延迟最高降低14.5倍，吞吐量更高，同时保持了有竞争力的准确性。分块设计使CDLM处于硬件高效的“最佳平衡点”，在小批量处理时比自回归模型具有更好的计算强度，又无需完全双向DLM的极端算力需求。这项工作表明，通过针对性训练，基于扩散的文本生成可以成为自回归模型的高效替代方案。"
  },
  {
    "id": "47078324",
    "title": "AI is not a coworker, it's an exoskeleton",
    "url": "https://www.kasava.dev/blog/ai-as-exoskeleton",
    "summary": "This article argues that the most effective way to use AI is not as an autonomous \"coworker\" but as an \"exoskeleton\" that amplifies human capability. It draws parallels to physical exoskeletons in manufacturing, military, and healthcare, which reduce injury and fatigue by augmenting human strength and endurance, not replacing the human.\n\nThe author contends that the push for fully autonomous \"AI agents\" often fails because AI lacks the implicit context and judgment that humans possess. Instead, the successful approach is to decompose complex jobs into discrete tasks and use focused \"micro-agents\" to handle repetitive, data-intensive work—like analyzing code commits or customer transcripts—while keeping humans firmly in the decision-making loop.\n\nThe article illustrates this with Kasava's \"product graph,\" which combines automated data analysis from codebases and workflows with human-provided strategic context. This symbiosis allows teams to make better-informed decisions by amplifying their capacity to process information.\n\nUltimately, the piece advises companies to stop seeking autonomous AI and start identifying points of friction in their workflows where AI can reduce cognitive load and error, preserving human creativity and judgment for the most critical decisions. The future of AI, it concludes, is integrated amplification, not replacement.",
    "chinese_title": "AI不是同事，它是外骨骼。",
    "chinese_summary": "本文主张，使用人工智能最有效的方式不是将其作为自主的“同事”，而是作为增强人类能力的“外骨骼”。文章将其与制造业、军事和医疗领域中的物理外骨骼相类比，这些外骨骼通过增强人的力量和耐力来减少伤害和疲劳，而非取代人类。\n\n作者认为，推动完全自主的“AI代理”往往失败，因为AI缺乏人类所拥有的隐含语境和判断力。相反，成功的方法是将复杂工作分解为独立任务，并利用专注的“微代理”来处理重复性、数据密集型的工作——比如分析代码提交或客户记录——同时确保人类牢牢掌握决策权。\n\n文章以Kasava的“产品图谱”为例进行说明，该图谱结合了来自代码库和工作流程的自动化数据分析与人类提供的战略背景。这种共生关系通过增强团队处理信息的能力，帮助他们做出更明智的决策。\n\n最后，文章建议企业停止追求自主AI，转而识别工作流程中的摩擦点，在这些地方利用AI减轻认知负担和错误，从而将人类的创造力和判断力保留给最关键的决定。文章总结道，AI的未来是集成式增强，而非替代。"
  },
  {
    "id": "47085370",
    "title": "Web Components: The Framework-Free Renaissance",
    "url": "https://www.caimito.net/en/blog/2026/02/17/web-components-the-framework-free-renaissance.html",
    "summary": "This article argues that modern web development is experiencing a \"renaissance\" through Web Components, which allow developers to build sophisticated, reactive user interfaces using native browser standards instead of frameworks like React or Vue.\n\nThe core benefits highlighted are **stability and freedom from churn**, as Web Components are built on long-term web standards, avoiding the constant upgrade cycles of frameworks. The article explains how **Custom Elements**, **Shadow DOM**, and the native **Custom Events** system work together to create modular, encapsulated, and loosely coupled components that communicate effectively.\n\nIt positions **AI assistants** as powerful tools for learning and building with these standards, making experimentation more accessible. While acknowledging that established frameworks still have their place for teams with deep expertise, the article makes a strong case for Web Components—especially for new projects or products requiring long-term maintainability—due to their simplicity, smaller bundle sizes, and direct use of the platform's built-in capabilities.\n\nThe conclusion is an invitation: the tools and browser support are now universal, offering a stable, elegant path for building modern web interfaces that are designed to last.",
    "chinese_title": "Web组件：无框架的复兴",
    "chinese_summary": "本文认为，现代Web开发正通过Web Components经历一场“复兴”。它使开发者能够基于原生浏览器标准（而非React或Vue等框架）构建复杂、响应式的用户界面。\n\n文章强调的核心优势在于**稳定性和避免频繁变动**，因为Web Components建立在长期的Web标准之上，规避了框架不断升级的循环。文中解释了**自定义元素**、**Shadow DOM**以及原生的**自定义事件**系统如何协同工作，以创建模块化、封装性高且松耦合的组件，并实现高效通信。\n\n文章将**AI助手**定位为学习和应用这些标准的有力工具，使实验探索更为便捷。尽管承认成熟框架在拥有深厚专业知识的团队中仍具价值，但文章为Web Components提出了有力论据——尤其适用于新项目或需要长期可维护性的产品——因其简洁性、更小的打包体积以及直接利用平台内置能力的特点。\n\n结论是一种邀请：相关工具和浏览器支持现已普及，为构建持久耐用的现代Web界面提供了一条稳定而优雅的路径。"
  },
  {
    "id": "47043345",
    "title": "Infrastructure decisions I endorse or regret after 4 years at a startup (2024)",
    "url": "https://cep.dev/posts/every-infrastructure-decision-i-endorse-or-regret-after-4-years-running-infrastructure-at-a-startup/",
    "summary": "This article shares infrastructure decisions from four years at a startup, categorized as endorsements, regrets, or mixed feelings.\n\n**Endorsements:** The author strongly recommends using AWS for its support and stability, and managed services like EKS, RDS, ElastiCache, and ECR for reliability. Key process wins include GitOps, automating post-mortems with a Slack bot, and regular cost and alert reviews. For SaaS tools, Notion, Slack, Linear (over JIRA), and PagerDuty are praised. Prioritizing team efficiency over external demands is also endorsed.\n\n**Regrets:** Major regrets include using EKS managed addons (too inflexible), AWS premium support (too expensive), and managing post-mortems in Datadog/PagerDuty (not customizable enough). Not adopting an identity platform (like Okta) sooner and allowing multiple applications to share a database created significant operational headaches. Datadog is regretted due to its cost model being unsuitable for dynamic Kubernetes and AI workloads.\n\n**Mixed Feelings:** GitHub Actions is endorsed but with caveats about buggy self-hosted runners. Schema migration by diff is seen as a good approach to a hard problem. The author has no regrets about not using Terraform Cloud, having successfully used Atlantis instead.\n\nThe overarching themes are to leverage managed services for critical components, invest in automation and clear processes early, and choose tools that balance power with simplicity and cost-effectiveness.",
    "chinese_title": "在一家初创公司工作四年后，我认可或后悔的基础设施决策（2024）",
    "chinese_summary": "本文分享了一家初创公司四年间的基础设施决策，分为推荐、遗憾和喜忧参半三类。\n\n**推荐：** 作者强烈推荐使用AWS，因其支持稳定；同时推荐EKS、RDS、ElastiCache和ECR等托管服务以确保可靠性。关键流程上的成功包括采用GitOps、用Slack机器人自动化事故复盘，以及定期进行成本与告警审查。在SaaS工具方面，Notion、Slack、Linear（优于JIRA）和PagerDuty备受好评。此外，优先考虑团队效率而非外部需求的做法也得到肯定。\n\n**遗憾：** 主要遗憾包括使用EKS托管插件（过于死板）、AWS高级支持（费用过高）以及在Datadog/PagerDuty中管理事故复盘（不够灵活）。未能尽早采用身份平台（如Okta）以及允许多个应用共享数据库，带来了巨大的运维负担。对于Datadog的遗憾主要源于其成本模型不适合动态Kubernetes和AI工作负载。\n\n**喜忧参半：** GitHub Actions受到推荐，但需注意自托管运行器的稳定性问题。通过差异进行数据库模式迁移被视为解决难题的好方法。作者对未使用Terraform Cloud并不后悔，因为已成功用Atlantis替代。\n\n核心主题是：关键组件采用托管服务，尽早投资自动化与清晰流程，并选择在功能、简洁性和成本效益之间取得平衡的工具。"
  },
  {
    "id": "47046981",
    "title": "Visible Spectra of the Elements",
    "url": "https://atomic-spectra.net/",
    "summary": "**Summary of \"Visible Spectra of the Elements\"**\n\nThe article from atomic-spectra.net serves as an educational resource detailing the characteristic visible light spectra emitted by the chemical elements. Its main purpose is to illustrate how each element produces a unique \"fingerprint\" of colored lines when its atoms are excited, typically by heat or electrical discharge.\n\nThe core scientific principle explained is that these spectral lines correspond to specific wavelengths of light released when electrons in an atom transition from a higher to a lower energy level. Since every element has a distinct atomic structure, the pattern of these lines is unique, allowing scientists to identify elements in distant stars, laboratory samples, and various light sources.\n\nThe article's key feature is a comprehensive, interactive periodic table. Clicking on an element displays its visible emission spectrum, usually presented as a series of colored lines against a dark background or a continuous plot of intensity versus wavelength. For many elements, the spectrum is shown alongside a photograph of the light emitted from a gas discharge tube containing that element, providing a direct visual connection.\n\nIt highlights that only some elements have strong lines in the *visible* portion of the electromagnetic spectrum (roughly 380-750 nanometers). Well-known examples featured include hydrogen (with its red, teal, and violet lines), neon (characteristic bright orange-red), and sodium (dominant double yellow line). The resource effectively demonstrates how spectroscopy is a fundamental tool in chemistry and astronomy for identifying composition.",
    "chinese_title": "元素的可见光谱",
    "chinese_summary": "**《元素可见光谱》摘要**\n\n本文源自atomic-spectra.net，是一份详细阐述化学元素特征可见光光谱的教育资源。其主要目的是说明当原子受热或放电激发时，每种元素如何产生独特的彩色谱线“指纹”。\n\n文中阐释的核心科学原理是：这些谱线对应原子中电子从高能级跃迁至低能级时释放的特定波长光。由于每种元素都具有独特的原子结构，其谱线图案也各不相同，从而使科学家能够识别遥远恒星、实验室样本及各种光源中的元素。\n\n该文章的核心特色是一个全面的交互式周期表。点击任一元素，即可显示其可见发射光谱，通常以暗背景下的彩色谱线序列或强度随波长变化的连续曲线图呈现。对于许多元素，光谱图会与含有该元素的气体放电管所发光线的实拍照片并列展示，建立起直观的视觉关联。\n\n文章强调，仅有部分元素在电磁波谱的*可见光*区（约380-750纳米）具有强谱线。其中突出的典型例子包括氢（具有红、青、紫谱线）、氖（特征性的亮橙红色）和钠（显著的双黄线）。该资源有效地展示了光谱学如何成为化学和天文学中鉴定物质成分的基本工具。"
  },
  {
    "id": "47056516",
    "title": "Lessons learned from `oapi-codegen`'s time in the GitHub Secure Open Source Fund",
    "url": "https://www.jvt.me/posts/2026/02/17/oapi-codegen-github-secure/",
    "summary": "In this article, the maintainer of **`oapi-codegen`** reflects on their project's participation in the **GitHub Secure Open Source Fund**. The primary motivation for joining the program was to strengthen the project's security posture, especially as the maintainer planned to expand the contributor pool. As a widely-used code generator that handles HTTP requests and sensitive data, ensuring its security is critical.\n\nThe program provided dedicated time and funding, allowing the maintainer to focus on security improvements without neglecting other responsibilities. Key outcomes included implementing a security policy, tightening branch protections, setting up automated vulnerability scanning with `govulncheck`, and beginning work on a threat model. These steps were crucial for safely onboarding new maintainers and protecting users from potential supply-chain risks.\n\nThe article highlights the value of the program's community aspect, offering a trusted space to discuss security challenges with other maintainers. It also notes the irony that reduced maintenance activity temporarily decreased the risk of merging vulnerable code, though the goal is to be both secure and actively maintained.\n\nOverall, the experience was highly positive, with the GitHub team providing excellent guidance through workshops and Q&A sessions. The maintainer concludes that the program was invaluable for proactively securing `oapi-codegen` and setting a foundation for its future growth.",
    "chinese_title": "从`oapi-codegen`在GitHub开源安全基金项目中汲取的经验教训",
    "chinese_summary": "本文中，**`oapi-codegen`** 的维护者回顾了其项目参与 **GitHub 开源安全基金** 的经历。加入该计划的主要动机是为了加强项目的安全状况，尤其是在维护者计划扩大贡献者群体之际。作为一个广泛使用的、处理 HTTP 请求和敏感数据的代码生成器，确保其安全性至关重要。\n\n该计划提供了专门的时间和资金，使维护者能够专注于安全改进，同时不忽视其他职责。主要成果包括实施安全政策、加强分支保护、使用 `govulncheck` 设置自动漏洞扫描，以及开始制定威胁模型。这些步骤对于安全地引入新的维护者并保护用户免受潜在的供应链风险至关重要。\n\n文章强调了该计划社区层面的价值，它提供了一个可信赖的空间，供维护者与其他项目维护者讨论安全挑战。文章还指出一个具有讽刺意味的现象：维护活动减少暂时降低了合并漏洞代码的风险，但目标始终是既保持安全又积极维护。\n\n总体而言，这次经历非常积极，GitHub 团队通过研讨会和问答环节提供了出色的指导。维护者总结认为，该计划对于主动保护 `oapi-codegen` 的安全并为其未来发展奠定基础具有不可估量的价值。"
  },
  {
    "id": "47091763",
    "title": "KFC, Nando's, and others ditch chicken welfare pledge",
    "url": "https://www.bbc.co.uk/news/articles/cm2r6jqm042o",
    "summary": "Eight major restaurant chains, including KFC, Burger King, and Nando's, have withdrawn from the Better Chicken Commitment (BCC), a pledge to stop using fast-growing chicken breeds. They have instead joined an industry-led alternative, the Sustainable Chicken Forum (SCF).\n\nThe BCC requires sourcing slower-growing breeds, which animal welfare groups argue are healthier, claiming fast-growing \"franken-chickens\" suffer higher rates of disease and premature death. The restaurant groups and UKHospitality, their trade body, state the SCF will focus on improving welfare while addressing environmental impact and meeting soaring consumer demand. They argue that farming slower-growing chickens produces more greenhouse gas emissions and that there is insufficient UK supply.\n\nCritics, including animal welfare organisations, condemn the move as a cost-cutting measure that prioritises profits over animal welfare, labelling the SCF a \"welfare-washing\" public relations stunt. They contend that supply would exist if the companies committed to contracts.\n\nWhile these restaurant brands have switched alliances, several major UK supermarkets and some cafe chains remain committed to the BCC.",
    "chinese_title": "肯德基、Nando's等品牌放弃鸡肉福利承诺。",
    "chinese_summary": "包括肯德基、汉堡王和Nando's在内的八大连锁餐饮品牌已退出\"更优鸡肉承诺\"倡议，该承诺要求停止使用速生鸡品种。这些企业转而加入了行业主导的替代方案——可持续鸡肉论坛。\n\n\"更优鸡肉承诺\"要求采购生长周期较长的鸡种，动物福利组织认为这类鸡更健康，并指出速生的\"弗兰肯鸡\"患病率和早亡率更高。餐饮集团及其行业组织英国酒店业协会表示，可持续鸡肉论坛将聚焦改善动物福利，同时解决环境影响问题并满足激增的消费需求。他们认为饲养慢生鸡会产生更多温室气体排放，且英国本土供应不足。\n\n包括动物福利组织在内的批评者谴责此举是削减成本的措施，将利润置于动物福利之上，称可持续鸡肉论坛是\"福利洗白\"的公关噱头。他们指出若企业愿意签订采购合同，慢生鸡供应本可得到保障。\n\n虽然这些餐饮品牌已转换阵营，但英国多家大型超市及部分咖啡连锁品牌仍坚守\"更优鸡肉承诺\"。"
  },
  {
    "id": "47065972",
    "title": "Notes on Clarifying Man Pages",
    "url": "https://jvns.ca/blog/2026/02/18/man-pages/",
    "summary": "This article explores ideas for improving the usability of man pages, the primary documentation for many command-line tools. The author, drawing from experience writing cheat sheets and contributing to Git documentation, identifies several effective patterns found in existing man pages.\n\nKey suggestions include adding an **OPTIONS SUMMARY** section (like in `rsync`) for a quick overview before the detailed descriptions, and organizing options by **category** (like `strace`) instead of alphabetically to aid discovery. The author highlights the value of **examples**, noting their popularity and suggesting they be placed prominently, even at the beginning of a page.\n\nThe article also advocates for better navigation within man pages, proposing a **table of contents** and **internal hyperlinks** in their HTML versions, as implemented on the Git website. It praises the use of **tables** (like in `man ascii`) for presenting reference data clearly and mentions the **`curl`** man page's approach of including an example for every option.\n\nFinally, the author acknowledges alternative documentation systems like GNU's **info manuals** and community tools like **tldr.sh**, which focus on practical examples. The core theme is enhancing the traditional, constrained man page format with clearer summaries, better organization, and practical examples to make information faster and easier to find.",
    "chinese_title": "关于澄清手册页的说明",
    "chinese_summary": "本文探讨了如何改进手册页（许多命令行工具的主要文档）的可用性。作者基于编写速查表及参与Git文档编写的经验，总结了现有手册页中几种有效的模式。\n\n主要建议包括：添加类似`rsync`中的**“选项概览”**部分，以便在详细描述前快速浏览；以及像`strace`那样按**类别**而非字母顺序组织选项，以帮助用户发现功能。作者强调了**示例**的价值，指出其受欢迎程度，并建议将其置于显眼位置，甚至可放在页面开头。\n\n文章还主张在手册页内提供更好的导航，提议在HTML版本中加入**目录**和**内部超链接**，正如Git网站已实现的那样。文中赞扬了使用**表格**（如`man ascii`）清晰呈现参考数据的方式，并提及**`curl`**手册页为每个选项提供示例的做法。\n\n最后，作者提及了替代文档系统，如GNU的**info手册**及社区工具**tldr.sh**，它们侧重于实用示例。核心主题是通过更清晰的摘要、更好的组织和实用的示例，来增强传统且受限的手册页格式，使信息查找更快捷、更轻松。"
  },
  {
    "id": "47084000",
    "title": "Reading the undocumented MEMS accelerometer on Apple Silicon MacBooks via iokit",
    "url": "https://github.com/olvvier/apple-silicon-accelerometer",
    "summary": "This article details a method for accessing the undocumented MEMS accelerometer embedded in Apple Silicon MacBooks (M1-M4). The sensor, managed by the Sensor Processing Unit (SPU), is not exposed through any public API. The author's project reads raw 3-axis acceleration data at approximately 800 Hz by directly interfacing with the `AppleSPUHIDDevice` via IOKit's HID functions.\n\nThe core process involves locating the device in the IOKit registry, opening it with `IOHIDDeviceCreate`, and registering an asynchronous callback to receive 22-byte HID reports. The acceleration values (in g-force) are extracted as little-endian integers from specific byte offsets and scaled by 65,536.\n\nThe project includes a demonstration that uses ballistocardiography to detect a user's heartbeat by analyzing vibrations transmitted through the laptop chassis when their wrists rest on it. The author emphasizes that this is experimental, not reliable for medical use, and requires root access due to Apple Silicon's security restrictions. The code has only been tested on a MacBook Pro M3 Pro and may break with future macOS updates. The project is released under an MIT license.",
    "chinese_title": "通过iokit读取Apple Silicon MacBook上未公开的MEMS加速度计",
    "chinese_summary": "本文详细介绍了一种访问苹果硅芯片MacBook（M1-M4）中未公开的MEMS加速度计的方法。该传感器由传感器处理单元（SPU）管理，未通过任何公共API公开。作者的项目通过IOKit的HID功能直接与`AppleSPUHIDDevice`交互，以约800赫兹的频率读取原始三轴加速度数据。\n\n核心流程包括在IOKit注册表中定位设备、使用`IOHIDDeviceCreate`打开设备，并注册异步回调以接收22字节的HID报告。加速度值（以重力加速度g为单位）从特定字节偏移量以小端整数形式提取，并通过65,536进行缩放。\n\n该项目包含一个演示，利用冲击心动描记术，通过分析用户手腕放在笔记本机身上时传递的振动来检测心跳。作者强调这是实验性项目，不适用于医疗用途，且由于苹果硅芯片的安全限制需要root权限。代码仅在MacBook Pro M3 Pro上测试过，可能随未来macOS更新而失效。项目采用MIT许可证发布。"
  }
]