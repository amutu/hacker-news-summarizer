[
  {
    "id": "46264492",
    "title": "Hashcards: A Plain-Text Spaced Repetition System",
    "url": "https://borretti.me/article/hashcards-plain-text-spaced-repetition",
    "summary": "Hashcards is a spaced repetition flashcard system that stores cards as plain-text Markdown files in a directory, rather than in a proprietary database. It uses the advanced FSRS scheduling algorithm, similar to Anki. Users study by running a command that opens a local web interface, with review history stored in a separate SQLite database.\n\nThe author created Hashcards due to dissatisfaction with existing tools. While Anki is powerful and uses FSRS, its interface is clunky and card creation is cumbersome. Mochi has a better, Markdown-based interface but previously used an inferior scheduling algorithm and has a verbose syntax for cloze deletions.\n\nHashcards prioritizes frictionless card creation. Its simple format uses `Q:`/`A:` for basic cards and square brackets `[...]` for cloze deletions, minimizing typing effort. Storing cards as plain text enables easy editing with any editor, version control with Git, sharing collections publicly, and generating or manipulating cards with scripts and standard Unix tools. This design gives users full ownership and flexibility over their flashcard data.",
    "chinese_title": "Hashcards：纯文本间隔重复系统",
    "chinese_summary": "Hashcards是一款间隔重复闪卡系统，它将卡片以纯文本Markdown文件的形式存储在目录中，而非专有数据库。它采用类似Anki的先进FSRS调度算法。用户通过运行命令打开本地网页界面进行学习，复习记录则存储在独立的SQLite数据库中。\n\n作者因对现有工具不满而创建了Hashcards。Anki虽然功能强大且采用FSRS算法，但其界面笨拙且卡片创建流程繁琐。Mochi拥有更优的Markdown界面，但曾采用低效的调度算法，且其完形填空语法冗长。\n\nHashcards致力于实现无摩擦的卡片创建。其简洁格式使用`Q:`/`A:`标记基础卡片，用方括号`[...]`标记完形填空，最大限度减少输入负担。卡片以纯文本形式存储，可使用任意编辑器轻松修改，通过Git进行版本控制，公开共享卡片集，还能用脚本和标准Unix工具生成或处理卡片。这种设计让用户能完全掌控自己的闪卡数据，并获得高度灵活性。"
  },
  {
    "id": "46265015",
    "title": "The Typeframe PX-88 Portable Computing System",
    "url": "https://www.typeframe.net/",
    "summary": "The Typeframe PX-88 is a portable, integrated computing system designed for professional users who prioritize a high-quality tactile typing experience and robust performance. Built around a Raspberry Pi 4 B core, it is powerful enough to handle demanding tasks like web-based editing and complex applications.\n\nIts key features include a high-quality mechanical keyboard for superior input, a compact and portable form factor, and a user-friendly design focused on ease of assembly and maintenance. The system requires minimal soldering to build, and its internal components are accessible via sliding panels for straightforward upkeep.\n\nPositioned as a versatile tool that blends the concepts of a cyberdeck and a writerdeck, the PX-88 is marketed as a professional-grade, DIY kit. It promises an \"uncompromising user experience\" where core computing power meets exceptional input quality, all in a portable package built by the end-user.",
    "chinese_title": "Typeframe PX-88便携式计算系统",
    "chinese_summary": "Typeframe PX-88是一款便携式集成计算系统，专为注重高品质触感打字体验与强劲性能的专业用户设计。该系统以树莓派4 B为核心构建，性能强大，足以应对网页编辑和复杂应用等高要求任务。\n\n其主要特点包括：提供卓越输入体验的高品质机械键盘、紧凑便携的外形，以及专注于便捷组装与维护的友好设计。系统组装仅需少量焊接，内部组件可通过滑动面板轻松触及，便于日常维护。\n\nPX-88定位为融合赛博甲板与写作甲板概念的多元工具，以专业级DIY套件形式推向市场。它承诺在终端用户亲手组装的便携设备中，实现核心计算性能与卓越输入品质的“不妥协用户体验”。"
  },
  {
    "id": "46262816",
    "title": "AI and the ironies of automation – Part 2",
    "url": "https://www.ufried.com/blog/ironies_of_ai_2/",
    "summary": "**Summary of \"AI and the ironies of automation – Part 2\"**\n\nThe article argues that the primary risk of advanced AI is not a sudden, conscious \"superintelligence\" takeover, but a more insidious erosion of human agency, competence, and understanding. It builds on classic \"ironies of automation\" theory, where automating a task can degrade the human operator's skills and situational awareness, making them less capable of handling failures.\n\nThe author contends that modern generative AI systems exacerbate these ironies in two key ways:\n\n1.  **The Delegation Irony:** We increasingly delegate cognitive and creative tasks (writing, coding, analysis) to AI to gain efficiency. However, this outsourcing can atrophy our own skills, critical thinking, and domain expertise. We become \"supervisors\" of a system we don't fully understand, losing the foundational knowledge needed to validate its outputs or intervene meaningfully.\n\n2.  **The Opacity Irony:** Unlike earlier deterministic software, large language models (LLMs) are probabilistic \"black boxes.\" Their outputs are not based on logical reasoning or accessible facts, but on complex pattern matching from training data. This makes it impossible for users to trace the \"why\" behind an AI's decision or piece of advice, undermining accountability and trust. We must accept answers without true comprehension.\n\nThe combined effect is a \"double degradation\": human capabilities diminish while the systems we rely on become less interpretable. The danger is a gradual slide into a state of **\"learned helplessness,\"** where society loses the collective competence to solve complex problems, judge AI outputs, or govern the technology itself. The core conclusion is that the pressing challenge is not making AI more intelligent, but designing human-AI interaction to **preserve and enhance human cognition, oversight, and ultimate responsibility.**",
    "chinese_title": "人工智能与自动化的讽刺——第二部分",
    "chinese_summary": "**《人工智能与自动化的讽刺——第二部分》摘要**\n\n本文认为，高级人工智能的主要风险并非一个突然的、有意识的“超级智能”接管，而是对人类能动性、能力和理解力更为隐蔽的侵蚀。文章基于经典的“自动化讽刺”理论展开论述，即自动化一项任务可能会削弱操作者的技能和情境意识，使其更难以应对故障。\n\n作者指出，现代生成式人工智能系统通过两种关键方式加剧了这些讽刺：\n\n1.  **委托讽刺：** 我们越来越多地将认知和创造性任务（写作、编程、分析）委托给人工智能以提高效率。然而，这种外包可能导致我们自身的技能、批判性思维和领域专业知识萎缩。我们变成了一个我们并不完全理解的系统的“监督者”，失去了验证其输出或进行有效干预所需的基础知识。\n\n2.  **不透明讽刺：** 与早期确定性软件不同，大语言模型是概率性的“黑箱”。它们的输出并非基于逻辑推理或可获取的事实，而是基于训练数据中的复杂模式匹配。这使得用户无法追溯人工智能决策或建议背后的“原因”，从而破坏了问责制和信任。我们必须在没有真正理解的情况下接受答案。\n\n综合效应是“双重退化”：人类能力减弱，而我们依赖的系统却变得更难以解释。其危险在于逐渐滑向一种**“习得性无助”** 的状态，即社会丧失解决复杂问题、判断人工智能输出或治理技术本身所需的集体能力。核心结论是，紧迫的挑战并非让人工智能变得更智能，而是设计人机交互以**保持并增强人类的认知、监督和最终责任。**"
  },
  {
    "id": "46265579",
    "title": "Stop crawling my HTML you dickheads – use the API",
    "url": "https://shkspr.mobi/blog/2025/12/stop-crawling-my-html-you-dickheads-use-the-api/",
    "summary": "The author expresses frustration with AI scrapers that inefficiently crawl and parse HTML from their websites, arguing that this brute-force approach ignores readily available, structured APIs.\n\nThey highlight that their WordPress site provides multiple machine-friendly data sources, all linked in the HTML `<head>`:\n*   A main JSON API endpoint (`wp-json/`) with a defined schema.\n*   Direct JSON links for individual posts.\n*   Alternative formats including oEmbed (JSON/XML), ActivityPub, and plain text versions.\n*   An XML sitemap to discover all pages without crawling.\n\nThe author notes that this problem also affects their OpenBenches project, where scrapers ignore GeoJSON data and APIs in favor of scraping HTML. Their core plea is for AI systems and developers to stop inefficient HTML scraping and instead use the provided, stable APIs for data access. They conclude by questioning if special headers or a proposed \"AI URL\" scheme are needed to direct automated agents to the correct resources.",
    "chinese_title": "别再爬我的HTML了，混蛋们——用API去。",
    "chinese_summary": "作者对低效抓取和解析其网站HTML的AI爬虫表示沮丧，认为这种蛮力方式忽视了现成可用的结构化API。\n\n他们指出自己的WordPress网站提供了多种机器友好的数据源，均链接在HTML的`<head>`中：\n*   具有定义模式的主JSON API端点（`wp-json/`）。\n*   单篇文章的直接JSON链接。\n*   包括oEmbed（JSON/XML）、ActivityPub和纯文本版本在内的替代格式。\n*   无需爬取即可发现所有页面的XML站点地图。\n\n作者提到这个问题也影响了他们的OpenBenches项目——爬虫无视GeoJSON数据和API，反而执着于抓取HTML。他们核心的呼吁是希望AI系统和开发者停止低效的HTML抓取，转而使用已提供的稳定API来获取数据。最后，他们质疑是否需要特殊标头或提议的“AI网址”方案来引导自动化代理访问正确的资源。"
  },
  {
    "id": "46224303",
    "title": "Developing a food-safe finish for my wooden spoons",
    "url": "https://alinpanaitiu.com/blog/developing-hardwax-oil/",
    "summary": "The author is a woodcarver seeking an ideal food-safe finish for wooden spoons and cups that cures quickly (under two days), is solvent-free, enhances wood grain, and creates a durable, hydrophobic surface without a plastic feel.\n\nThey evaluate and reject several common options: pure tung oil (cures too slowly), commercial hardwax oils (contain solvents), edible oils (don't cure), pure waxes (low melting point), and synthetic finishes (undesirable look/feel).\n\nTheir solution is a homemade, solvent-free blend of natural ingredients. The core recipe combines pure tung oil (for deep penetration and durability) with carnauba wax (for a hard top layer). To improve workability and sheen, they add beeswax, lanolin, damar resin, and a minuscule amount of metal driers to accelerate curing.\n\nThe resulting paste is melted, applied to the wood, and heated with a heat gun to aid penetration. It dries quickly to a water-resistant, satin finish. However, the underlying tung oil still requires 2-4 weeks to fully cure, limiting immediate use with very hot liquids. The finish successfully protects the wood, is pleasant to apply, and—most importantly—accentuates the natural color and grain of the unique woods used.",
    "chinese_title": "为我的木勺开发一种食品安全涂层",
    "chinese_summary": "作者是一位木雕师，正在为木勺和木杯寻找一种理想的食品级涂饰。这种涂饰需要固化迅速（两天内）、无溶剂、能凸显木纹，并能形成耐用、疏水且无塑料感的表面。\n\n他评估并排除了几种常见选项：纯桐油（固化太慢）、商用硬蜡油（含溶剂）、食用油（无法固化）、纯蜡（熔点低）以及合成涂饰剂（外观与手感不佳）。\n\n他的解决方案是一种自制的无溶剂天然原料混合剂。核心配方结合了纯桐油（用于深层渗透和耐久性）与巴西棕榈蜡（用于形成坚硬的表层）。为了提升可操作性和光泽度，他还添加了蜂蜡、羊毛脂、达玛树脂以及微量金属催干剂以加速固化。\n\n制成的膏体经熔化后涂抹于木材上，并用热风枪加热以促进渗透。它能迅速干燥为耐水的哑光表面。然而，底层的桐油仍需2-4周才能完全固化，因此涂饰后的器皿无法立即接触高温液体。这种涂饰能有效保护木材，施工过程愉悦，最重要的是——它能突出所用独特木材的自然色泽与纹理。"
  },
  {
    "id": "46262021",
    "title": "Shai-Hulud compromised a dev machine and raided GitHub org access: a post-mortem",
    "url": "https://trigger.dev/blog/shai-hulud-postmortem",
    "summary": "On November 25, 2025, Trigger.dev was compromised by the Shai-Hulud 2.0 npm supply chain worm. The attack began when an engineer unknowingly installed a malicious package, which ran a script that stole their GitHub credentials.\n\nThe attacker spent 17 hours cloning 669 private and public repositories while monitoring the engineer's legitimate work. They then launched a 10-minute destructive phase, force-pushing 199 branches and closing 42 pull requests across 16 repos, attributing vandalism to \"Linus Torvalds.\"\n\nThe team detected the attack via Slack notifications and revoked the compromised account's access within minutes, halting the attack. No production systems, databases, or published npm packages were breached, thanks to existing security measures like 2FA for publishing.\n\nDuring recovery, the team discovered the private key for their GitHub App in the engineer's trash, potentially exposing customer repository access. They rotated the key and notified affected customers, though no unauthorized access was found.\n\nThe incident highlights the risks of supply chain attacks and led Trigger.dev to strengthen branch protections, credential management, and monitoring to prevent future compromises.",
    "chinese_title": "沙虫入侵开发机并窃取GitHub组织权限：事件复盘报告",
    "chinese_summary": "2025年11月25日，Trigger.dev 遭受了 Shai-Hulud 2.0 npm 供应链蠕虫的攻击。事件始于一名工程师在不知情的情况下安装了恶意软件包，该软件包运行脚本窃取了其 GitHub 凭据。\n\n攻击者花费了 17 小时克隆了 669 个私有和公共仓库，同时监控该工程师的日常工作。随后，他们发起了持续 10 分钟的破坏性攻击，强制推送了 199 个分支，并在 16 个仓库中关闭了 42 个拉取请求，并将破坏行为归咎于“Linus Torvalds”。\n\n团队通过 Slack 通知检测到攻击，并在几分钟内撤销了受损账户的访问权限，从而阻止了攻击。得益于现有的安全措施（如发布时需进行双重认证），生产系统、数据库或已发布的 npm 软件包均未受到影响。\n\n在恢复过程中，团队发现工程师的垃圾桶中存有 GitHub 应用的私钥，这可能暴露客户仓库的访问权限。他们随即更换了密钥并通知了受影响的客户，但未发现任何未经授权的访问。\n\n此次事件凸显了供应链攻击的风险，促使 Trigger.dev 加强了分支保护、凭据管理和监控措施，以防止未来再次发生类似安全事件。"
  },
  {
    "id": "46264704",
    "title": "GraphQL: The enterprise honeymoon is over",
    "url": "https://johnjames.blog/posts/graphql-the-enterprise-honeymoon-is-over",
    "summary": "This article argues that GraphQL's benefits are often overstated for enterprise applications, where its main selling point—preventing overfetching—is already addressed by existing Backend-for-Frontend (BFF) architectures. While GraphQL excels at letting clients request specific data, the author notes that downstream services are typically REST APIs, meaning overfetching is merely shifted to a different layer rather than eliminated.\n\nThe piece details significant trade-offs: GraphQL requires more initial setup (schemas, resolvers) than REST, complicates observability by using HTTP 200 for both success and errors, and introduces fragile caching complexities. It also highlights practical shortcomings, such as Apollo's mandatory unique ID fields (a poor fit for many enterprise APIs) and awkward handling of file uploads.\n\nUltimately, the author concludes that GraphQL is a niche solution. For most enterprise environments, where teams prioritize production speed, operational simplicity, and reliability, the added complexity of GraphQL often outweighs its theoretical advantages, making a simpler REST-based BFF a more pragmatic choice.",
    "chinese_title": "GraphQL：企业蜜月期已结束",
    "chinese_summary": "本文认为，GraphQL的优势在企业应用中常被夸大，其主要卖点——防止过度获取数据——在现有的后端为前端（BFF）架构中已得到解决。尽管GraphQL在允许客户端请求特定数据方面表现出色，但作者指出，下游服务通常是REST API，这意味着过度获取数据只是被转移到了另一层，而非真正消除。\n\n文章详细阐述了重大权衡：GraphQL比REST需要更多的初始设置（模式、解析器），通过使用HTTP 200处理成功和错误使可观测性复杂化，并引入了脆弱的缓存复杂性。它还强调了实际缺陷，例如Apollo强制要求的唯一ID字段（对许多企业API并不适用）以及对文件上传的笨拙处理。\n\n最终，作者得出结论，GraphQL是一种小众解决方案。对于大多数企业环境，团队优先考虑生产速度、操作简便性和可靠性，GraphQL增加的复杂性往往超过其理论优势，使得基于REST的简单BFF成为更务实的选择。"
  },
  {
    "id": "46263530",
    "title": "Illuminating the processor core with LLVM-mca",
    "url": "https://abseil.io/fast/99",
    "summary": "This article introduces LLVM-MCA (Machine Code Analyzer), a tool for analyzing how assembly instructions are executed on a processor's backend. It explains that modern processors break down instructions into micro-ops and that LLVM-MCA simulates their flow through execution units, offering static performance insights (ignoring dynamic factors like cache misses).\n\nThe core example compares two implementations of a Protobuf function (`VarintSize64`): one using the `bsr` instruction and another using `lzcnt`. By analyzing their assembly with LLVM-MCA, the article shows how the tool's timeline view reveals that the `lzcnt` version has lower latency (9 vs. 10 cycles) due to better instruction-level parallelism and the absence of a data dependency caused by a bitwise OR.\n\nKey insights from using LLVM-MCA include:\n*   It helps distinguish between **latency** (critical path for single operations) and **throughput** (parallel execution in loops).\n*   Its timeline visualization clarifies **dependency chains**, showing which instructions create bottlenecks, even if a CPU profile might misleadingly highlight others.\n*   It can model different CPU architectures (e.g., AMD Zen3, Arm cores).\n\nThe article concludes that LLVM-MCA is valuable for understanding the processor's execution pipeline, identifying critical paths for optimization, and making informed trade-offs between latency and throughput.",
    "chinese_title": "使用LLVM-mca照亮处理器核心",
    "chinese_summary": "本文介绍了LLVM-MCA（机器代码分析器），这是一个用于分析汇编指令在处理器后端如何执行的工具。文章指出，现代处理器将指令分解为微操作，而LLVM-MCA通过模拟这些微操作在执行单元中的流动，提供静态性能分析（忽略缓存未命中等动态因素）。\n\n核心示例比较了Protobuf函数（`VarintSize64`）的两种实现：一种使用`bsr`指令，另一种使用`lzcnt`指令。通过使用LLVM-MCA分析它们的汇编代码，文章展示了该工具的时间线视图如何揭示`lzcnt`版本具有更低的延迟（9个周期对比10个周期），这得益于更好的指令级并行性以及避免了由按位或操作引起的数据依赖。\n\n使用LLVM-MCA的关键见解包括：\n*   它有助于区分**延迟**（单次操作的关键路径）和**吞吐量**（循环中的并行执行）。\n*   其时间线可视化清晰地展示了**依赖链**，揭示了哪些指令造成了瓶颈，即使CPU性能分析可能误导性地突出其他指令。\n*   它可以模拟不同的CPU架构（例如AMD Zen3、Arm核心）。\n\n文章总结道，LLVM-MCA对于理解处理器的执行流水线、识别优化的关键路径，以及在延迟和吞吐量之间做出明智权衡具有重要价值。"
  },
  {
    "id": "46259064",
    "title": "Linux Sandboxes and Fil-C",
    "url": "https://fil-c.org/seccomp",
    "summary": "This article explains how to combine memory safety (using Fil-C, a memory-safe C/C++ implementation) with Linux sandboxing techniques, using OpenSSH as a case study. It clarifies that memory safety and sandboxing are separate, complementary layers of defense.\n\nThe core challenge is adapting sandboxes designed for unsafe languages to work with Fil-C's runtime, which uses background threads and syscalls for garbage collection and synchronization. To prevent these runtime activities from violating sandbox rules (like blocking new threads), the author introduces a new Fil-C API, `zlock_runtime_threads()`. This forces the runtime to create all necessary threads upfront before the sandbox is activated.\n\nSpecific tweaks to OpenSSH's seccomp-BPF filter are also detailed, such as allowing `MAP_NORESERVE` and `sched_yield` for the runtime, and using `SECCOMP_RET_KILL_PROCESS` to terminate all threads on violation.\n\nCritically, the article describes how Fil-C's runtime securely implements the `prctl` syscalls used to install seccomp filters. It ensures that the `no_new_privs` bit and the syscall filter are applied to *all* runtime threads, not just the main one, closing a potential escape vector.\n\nThe conclusion reinforces that the strongest security posture comes from layering both memory safety and robust sandboxing, and demonstrates how Fil-C can be integrated with existing Linux sandboxing tools without compromising either layer's guarantees.",
    "chinese_title": "Linux沙盒与Fil-C",
    "chinese_summary": "本文以OpenSSH为例，阐述了如何将内存安全（通过使用内存安全的C/C++实现Fil-C）与Linux沙箱技术相结合。文中明确指出，内存安全与沙箱化是相互独立且互补的防御层次。\n\n核心挑战在于如何让为不安全语言设计的沙箱适配Fil-C运行时的机制——该运行时依赖后台线程和系统调用来进行垃圾回收与同步。为防止这些运行时活动违反沙箱规则（例如阻止新建线程），作者引入了新的Fil-C API `zlock_runtime_threads()`，强制运行时在沙箱激活前预先创建所有必需线程。\n\n文章还详细说明了针对OpenSSH的seccomp-BPF过滤器的具体调整，例如为运行时允许`MAP_NORESERVE`和`sched_yield`系统调用，并使用`SECCOMP_RET_KILL_PROCESS`在违规时终止所有线程。\n\n关键之处在于，文章描述了Fil-C运行时如何安全地实现用于安装seccomp过滤器的`prctl`系统调用。它确保`no_new_privs`标志位和系统调用过滤器应用于*所有*运行时线程（而不仅是主线程），从而封堵了潜在的逃逸途径。\n\n结论再次强调，最强的安全态势源于内存安全与健壮沙箱化的分层结合，并展示了如何在不损害任何一层安全保证的前提下，将Fil-C与现有Linux沙箱工具集成。"
  },
  {
    "id": "46202853",
    "title": "Standalone Meshtastic Command Center – One HTML File Offline",
    "url": "https://github.com/Jordan-Townsend/Standalone",
    "summary": "The Meshtastic Standalone Command Center is a self-contained, offline web interface for managing Meshtastic mesh networks, packaged in a single 51KB HTML file. It requires no installation, internet connection, or backend server, making it ideal for field operations, emergencies, and off-grid use.\n\nKey features include universal connectivity via native browser APIs (Web Bluetooth, Web Serial, and WiFi), real-time node mapping with metrics (RSSI, SNR, hops), message broadcasting, and node configuration. It is cross-platform, running on any modern browser across laptops, tablets, and smartphones.\n\nThe tool addresses the need for a reliable, dependency-free control interface in scenarios where traditional apps or cloud services are impractical. It supports a wide range of community-validated hardware like LilyGo and Heltec devices.\n\nDevelopment prioritizes simplicity and transparency—using no frameworks, analytics, or external dependencies—ensuring all data remains locally on the user's device. Future updates may include offline maps, fleet monitoring, and provisioning tools. The project is open for community contributions, testing, and feedback.",
    "chinese_title": "独立版Meshtastic指挥中心 – 单HTML文件离线运行",
    "chinese_summary": "Meshtastic独立指挥中心是一个自包含的离线网页界面，用于管理Meshtastic网状网络，封装在单个51KB的HTML文件中。它无需安装、互联网连接或后端服务器，非常适合现场操作、紧急情况和离网使用。\n\n主要功能包括通过原生浏览器API（Web蓝牙、Web串口和WiFi）实现通用连接、带指标（RSSI、SNR、跳数）的实时节点映射、消息广播和节点配置。它是跨平台的，可在笔记本电脑、平板电脑和智能手机上的任何现代浏览器中运行。\n\n该工具解决了在传统应用或云服务不实用的场景下对可靠、无依赖控制界面的需求。它支持多种社区验证的硬件，如LilyGo和Heltec设备。\n\n开发优先考虑简洁性和透明度——不使用任何框架、分析工具或外部依赖——确保所有数据都保留在用户的本地设备上。未来更新可能包括离线地图、车队监控和配置工具。该项目开放给社区贡献、测试和反馈。"
  },
  {
    "id": "46264329",
    "title": "Rust Coreutils 0.5.0 Release: 87.75% compatibility with GNU Coreutils",
    "url": "https://github.com/uutils/coreutils/releases/tag/0.5.0",
    "summary": "Rust Coreutils 0.5.0 marks a significant release, achieving 87.75% compatibility with GNU Coreutils (up 1.95%). This milestone includes 566 passing tests, a reduction in failures and skipped tests, and an update to the GNU 9.9 reference.\n\nKey improvements focus on **GNU compatibility**, **Unicode support**, and **platform expansion**. Major enhancements were made to utilities like `fold` (adding combining character support), `cksum` (merged with `hashsum`), `install` (improved mode parsing), and `numfmt`. The release also expands platform support, adding OpenBSD to CI and re-enabling Redox OS.\n\nOther highlights include **security and performance optimizations**, a new TTY helper for testing, reduced dependency bloat, and contributions from six new developers. The project encourages further community involvement through translation contributions and sponsorships.",
    "chinese_title": "Rust Coreutils 0.5.0 版本发布：与 GNU Coreutils 兼容性达 87.75%",
    "chinese_summary": "Rust Coreutils 0.5.0 是一个重要版本，实现了与 GNU Coreutils 87.75% 的兼容性（提升 1.95%）。这一里程碑包含 566 项通过测试，失败和跳过的测试有所减少，并更新至 GNU 9.9 参考标准。\n\n主要改进聚焦于 **GNU 兼容性**、**Unicode 支持**和**平台扩展**。对 `fold`（新增组合字符支持）、`cksum`（与 `hashsum` 合并）、`install`（改进模式解析）及 `numfmt` 等工具进行了重大优化。该版本还扩展了平台支持，在 CI 中新增 OpenBSD 并重新启用 Redox OS。\n\n其他亮点包括**安全与性能优化**、新的 TTY 测试辅助工具、依赖冗余的减少，以及六位新开发者的贡献。项目鼓励通过翻译贡献和赞助等方式进一步参与社区建设。"
  },
  {
    "id": "46262950",
    "title": "Apple Maps claims it's 29,905 miles away",
    "url": "https://mathstodon.xyz/@dpiponi/115651419771418748",
    "summary": "This post references a social media comment by Dan Piponi on Mathstodon regarding Apple Maps. The core issue is that Apple Maps displayed a significant and clearly incorrect distance for a location, claiming it was **29,905 miles away**. The specific context mentioned is \"It's moving around Guatemala City now,\" which suggests the user was tracking something (like a device or location pin) that was erroneously reported to be circling Guatemala City at that extreme distance.\n\nThe main point is to highlight a glaring and humorous error in Apple Maps' geolocation data or interface. The vast distance (equivalent to more than once around the Earth's circumference) underscores the absurdity of the bug. The additional note about Mastodon requiring JavaScript or a native app is a standard technical notice from the platform and not part of the article's substantive content.\n\n**Summary:** A user reports that Apple Maps displayed a drastic error, showing a tracked location as being 29,905 miles away while apparently circling Guatemala City. This serves as a critique or anecdote about the service's occasional reliability issues.",
    "chinese_title": "苹果地图声称它距离29,905英里远",
    "chinese_summary": "这篇帖子引用了丹·皮波尼在Mathstodon上关于苹果地图的一条社交媒体评论。核心问题是苹果地图显示了一个明显错误且极其夸张的距离，声称某地点**距离29,905英里**。具体提到的语境是“它现在正在危地马拉城附近移动”，这暗示用户当时正在追踪某个目标（如设备或位置标记），却被错误地报告为以这种极端距离环绕危地马拉城移动。\n\n重点在于突出苹果地图在地理定位数据或界面中存在的一个明显且滑稽的错误。如此巨大的距离（相当于绕地球赤道一周还多）凸显了该漏洞的荒谬性。关于Mastodon需要JavaScript或原生应用的技术提示是该平台的标准通知，并非文章实质内容的一部分。\n\n**摘要：** 用户报告苹果地图出现严重错误，将一个被追踪的位置显示为距离29,905英里，且看似在环绕危地马拉城移动。这则轶事揭示了该服务偶尔存在的可靠性问题。"
  },
  {
    "id": "46261452",
    "title": "Compiler Engineering in Practice",
    "url": "https://chisophugis.github.io/2025/12/08/compiler-engineering-in-practice-part-1-what-is-a-compiler.html",
    "summary": "This article introduces a blog series on practical compiler engineering, aiming to share essential, unwritten wisdom for developers. It defines a compiler as a translator between languages that must preserve the behavior of the described computation, emphasizing that compilers are fundamentally just programs that read and write files, making them straightforward to debug.\n\nThe core challenge of compiler engineering is ensuring reliability by avoiding *miscompiles*—bugs where the output program behaves incorrectly. These are catastrophic, leading to data loss, security flaws, or incorrect results, and are extremely time-consuming to debug. Therefore, a primary goal is to design compilers to fail safely before producing faulty output.\n\nThe article identifies the complexity of the Intermediate Representation (IR) data structure as the central difficulty. An IR is a graph representing program semantics, and it evolves through multiple abstraction levels (e.g., from a high-level multiplication operator to a specific machine instruction). Each transformation on this graph must preserve meaning, and the IR's schema and the complex interactions between operations (like those involving mutable state) make this exceptionally challenging. A single invalid transformation can cause a miscompile.\n\nFinally, the article notes that while compilers require specialized techniques for IR design and testing, they are ultimately large, long-lived software projects where standard software engineering best practices also apply.",
    "chinese_title": "编译器工程实践",
    "chinese_summary": "本文介绍了一个关于实用编译器工程的博客系列，旨在为开发者分享那些必要却未被书面记载的智慧。它将编译器定义为语言之间的翻译器，必须保持所描述计算行为的一致性，并强调编译器本质上只是读写文件的程序，这使得调试变得直接明了。\n\n编译器工程的核心挑战在于通过避免*误编译*来确保可靠性——即输出程序行为错误的缺陷。这些缺陷是灾难性的，会导致数据丢失、安全漏洞或错误结果，并且调试极其耗时。因此，一个主要目标是在产生错误输出之前，设计编译器使其能够安全地失败。\n\n文章指出中间表示数据结构是核心难点。中间表示是一种表示程序语义的图结构，它会经历多个抽象层次的演变（例如从高级乘法运算符到特定的机器指令）。对该图的每次转换都必须保持语义不变，而中间表示的模式以及操作之间复杂的交互（如涉及可变状态的操作）使得这一任务异常困难。一次无效的转换就可能导致误编译。\n\n最后，文章提到，尽管编译器在中间表示设计和测试方面需要专门的技术，但它们本质上是大型、长期存在的软件项目，标准的软件工程最佳实践同样适用。"
  },
  {
    "id": "46264101",
    "title": "iOS 26.2 fixes 20 security vulnerabilities, 2 actively exploited",
    "url": "https://www.macrumors.com/2025/12/12/ios-26-2-security-vulnerabilities/",
    "summary": "Apple has released iOS 26.2, iPadOS 26.2, and macOS 26.2, a critical security update addressing over 20 vulnerabilities. Most notably, it patches two WebKit flaws that were actively exploited in sophisticated, targeted attacks against individuals using iOS versions prior to iOS 26. These bugs could allow malicious web content to execute arbitrary code or corrupt memory.\n\nThe update also fixes several other security issues, including a bug allowing access to sensitive App Store payment tokens, an image processing flaw that could cause memory corruption, a vulnerability permitting unauthorized viewing of the Hidden Photo Album, and an issue where passwords could be accidentally removed during a FaceTime screen-sharing session.\n\nWith these vulnerabilities now publicly disclosed, Apple strongly urges all users to install the updates immediately to protect their devices from potential exploitation.",
    "chinese_title": "iOS 26.2修复20个安全漏洞，其中2个已被主动利用",
    "chinese_summary": "苹果已发布iOS 26.2、iPadOS 26.2和macOS 26.2，这是一项关键安全更新，修复了超过20个漏洞。其中最值得关注的是修补了两个WebKit漏洞，这些漏洞曾在针对iOS 26之前版本用户的复杂定向攻击中被主动利用。这些漏洞可能允许恶意网页内容执行任意代码或破坏内存。\n\n此次更新还修复了其他多个安全问题，包括一个可能泄露App Store支付令牌敏感信息的漏洞、一个可能导致内存损坏的图像处理缺陷、一个允许未经授权查看“隐藏相簿”的漏洞，以及一个在FaceTime屏幕共享期间可能意外删除密码的问题。\n\n随着这些漏洞的公开披露，苹果强烈建议所有用户立即安装更新，以保护设备免受潜在攻击。"
  },
  {
    "id": "46262777",
    "title": "Vacuum Is a Lie: About Your Indexes",
    "url": "https://boringsql.com/posts/vacuum-is-lie/",
    "summary": "This article challenges the common misconception that PostgreSQL's VACUUM command fully maintains database health, particularly regarding indexes. While VACUUM removes dead tuples from tables and marks space as reusable, it does not restructure B-tree indexes. This leaves \"hollow\" indexes—where pages contain many empty slots from deletions—causing them to occupy excessive disk space and perform inefficiently.\n\nThe author demonstrates this with an experiment: after deleting 80% of rows from a table, VACUUM shrinks the table data but leaves the index size unchanged. This index bloat misleads the query planner, which overestimates I/O costs based on physical file size rather than actual data density, potentially leading to poor performance.\n\nTo address index bloat, the article recommends using `REINDEX CONCURRENTLY` to rebuild indexes without significant downtime. For reclaiming space from both bloated tables and indexes, it suggests using the `pg_squeeze` extension, which operates online with minimal locking, unlike the disruptive `VACUUM FULL`. The key takeaway is to monitor for severe bloat—especially after large deletions—but not to overreact to normal, minor fluctuations in index density.",
    "chinese_title": "真空是个谎言：关于你的索引",
    "chinese_summary": "本文挑战了一个常见的误解，即PostgreSQL的VACUUM命令能完全维护数据库健康，尤其是在索引方面。虽然VACUUM会从表中移除死元组并标记空间为可重用，但它不会重组B树索引。这导致了“空洞”索引——索引页因删除操作留下大量空槽——使它们占用过多磁盘空间且性能低下。\n\n作者通过一个实验证明了这一点：在删除表中80%的行后，VACUUM缩小了表数据，但索引大小保持不变。这种索引膨胀会误导查询规划器，使其基于物理文件大小而非实际数据密度高估I/O成本，可能导致性能下降。\n\n为解决索引膨胀问题，文章建议使用`REINDEX CONCURRENTLY`在不造成显著停机的情况下重建索引。对于同时回收膨胀表和索引的空间，推荐使用`pg_squeeze`扩展，它能在线上操作且锁影响最小，不像破坏性的`VACUUM FULL`。关键要点是监控严重膨胀——尤其是在大规模删除后——但不要对索引密度的正常轻微波动反应过度。"
  },
  {
    "id": "46262734",
    "title": "Kimi K2 1T model runs on 2 512GB M3 Ultras",
    "url": "https://twitter.com/awnihannun/status/1943723599971443134",
    "summary": "This article is a technical announcement from X (formerly Twitter) stating that the Kimi K2 1T AI model can now run on a dual Apple M3 Ultra chip configuration.\n\nThe core information is that this large language model, which has a parameter size of 1 trillion (1T), is optimized to operate on two M3 Ultra processors, each equipped with 512GB of unified memory. This setup provides a total of 1 terabyte of high-bandwidth memory, which is crucial for running such massive AI models efficiently.\n\nThe rest of the content displayed is a standard browser notification informing the user that JavaScript is disabled and is required to use the X.com website. It prompts the user to enable JavaScript or switch to a supported browser, followed by generic footer links (Help Center, Terms of Service, etc.).\n\n**Summary:** The key takeaway is the technical achievement of running a 1-trillion-parameter AI model on consumer-grade Apple Silicon hardware (dual M3 Ultras). The JavaScript message is incidental, indicating the announcement was likely viewed on the X platform, which requires JavaScript to function.",
    "chinese_title": "Kimi K2 1T模型运行于2个512GB M3 Ultra芯片上。",
    "chinese_summary": "本文是X（原Twitter）发布的一则技术公告，宣布Kimi K2 1T AI模型现可在双Apple M3 Ultra芯片配置上运行。\n\n核心信息是，这个参数规模达1万亿（1T）的大型语言模型经过优化，可在两个M3 Ultra处理器上运行，每个处理器配备512GB统一内存。该配置提供了总计1TB的高带宽内存，这对高效运行如此庞大的AI模型至关重要。\n\n其余显示内容为标准的浏览器通知，提示用户JavaScript已禁用，而使用X.com网站需要启用JavaScript。通知建议用户启用JavaScript或切换至受支持的浏览器，随后附有通用页脚链接（帮助中心、服务条款等）。\n\n**总结：** 关键信息是在消费级Apple Silicon硬件（双M3 Ultra）上运行1万亿参数AI模型的技术成就。JavaScript提示信息属于附带内容，表明该公告很可能是在需要JavaScript才能正常运行的X平台上浏览的。"
  },
  {
    "id": "46265383",
    "title": "More atmospheric rivers coming for flooded Washington and the West Coast",
    "url": "https://www.cnn.com/2025/12/12/weather/washington-west-coast-flooding-atmospheric-rivers-climate",
    "summary": "This article details severe flooding in Washington state caused by a powerful atmospheric river, with more storms forecasted. Historic rainfall has led to dangerous river levels, widespread evacuations, and dozens of water rescues, particularly in areas like Sumas and Burlington. Infrastructure is heavily impacted, with numerous highway closures and isolated communities.\n\nThe remote town of Stehekin is especially cut off, dealing with debris slides over recent burn scars that have blocked roads and damaged utilities. While some residents are self-sufficient, others require emergency deliveries of fuel and water, and recovery is expected to take months.\n\nOfficials warn the crisis is ongoing and urge residents to heed road closures and evacuation orders. The ground is saturated, increasing the risk of renewed flooding as new atmospheric rivers are predicted to arrive early next week, bringing additional heavy rain to Washington, Oregon, and Northern California through Wednesday and possibly beyond.",
    "chinese_title": "更多大气河流将袭击已遭洪灾的华盛顿州及西海岸地区。",
    "chinese_summary": "本文详述了华盛顿州因强盛大气河流引发的严重洪灾，且预计将有更多风暴来袭。历史性降雨导致河流水位达到危险高度，引发大范围疏散和数十起水上救援，特别是在苏马斯和伯灵顿等地区。基础设施受到严重影响，多条高速公路关闭，多个社区陷入孤立。\n\n偏远的斯蒂金镇尤其与外界隔绝，近期山火过后的焦土上发生泥石流，阻塞道路并损坏公共设施。尽管部分居民能够自给自足，其他人仍需紧急燃料和饮用水补给，预计恢复工作将持续数月。\n\n官员警告危机仍在持续，敦促居民遵守道路封闭和疏散指令。目前土壤已完全饱和，随着新的大气河流预计将于下周初抵达，华盛顿州、俄勒冈州和北加州直至周三及之后可能再迎暴雨，洪水复发的风险正在增加。"
  },
  {
    "id": "46189905",
    "title": "In the Beginning Was the Command Line (1999)",
    "url": "https://web.stanford.edu/class/cs81n/command.txt",
    "summary": "Neal Stephenson's 1999 essay uses the history and metaphors of operating systems to critique the computer industry's evolution. He contrasts the tangible early personal computers with the initially abstract idea of selling an operating system (OS), which has since become a mainstream, fiercely debated product.\n\nHe employs an extended car dealership metaphor to explain the OS landscape: Microsoft (Windows) is the dominant seller of bulky, utilitarian \"station wagons\" and \"ORVs.\" Apple sells sleek, stylish, but expensive and sealed \"Euro-sedans.\" The newer BeOS is a superior but niche \"Batmobile.\" Most significantly, Linux represents a community-built, free \"tank\"—technically advanced and reliable, but intimidating to average users who prefer the familiar, commercial support of mainstream options.\n\nStephenson roots his analysis in his early programming experience, where the clean separation between human (meaning) and machine (bit-processing) was clear. He argues that modern OSs, in their quest for user-friendliness through desktop metaphors, have complicated this relationship. The essay ultimately questions the future of the OS business, highlighting the tension between corporate-controlled, metaphor-driven systems (Windows, Mac) and the emerging, robust, but less polished paradigm of open-source, community-developed software like Linux.",
    "chinese_title": "起初是命令行（1999）",
    "chinese_summary": "尼尔·斯蒂芬森在1999年的文章中，运用操作系统的发展史和隐喻来批判计算机行业的演变。他将早期实体化的个人电脑与最初抽象的操作系统（OS）销售理念进行对比——后者如今已成为主流且备受争议的产品。\n\n他通过一个延伸的汽车销售比喻来解释操作系统格局：微软（Windows）是笨重实用的“旅行车”和“越野车”的主导销售商；苹果销售时尚优雅但昂贵且封闭的“欧洲轿车”；较新的BeOS则是优越但小众的“蝙蝠车”。最重要的是，Linux代表着社区共建的免费“坦克”——技术先进且可靠，但对习惯于主流商业技术支持的用户而言显得令人生畏。\n\n斯蒂芬森的分析植根于他早期的编程经验，那时人类（意义）与机器（位处理）之间的界限清晰分明。他认为现代操作系统为追求用户友好性而采用桌面隐喻，反而使这种关系复杂化。文章最终质疑操作系统业务的未来，凸显了企业控制、隐喻驱动的系统（Windows、Mac）与新兴但欠打磨的开源社区开发模式（如Linux）之间的张力。"
  },
  {
    "id": "46264068",
    "title": "Price of a bot army revealed across online platforms",
    "url": "https://www.cam.ac.uk/stories/price-bot-army-global-index",
    "summary": "Researchers at the University of Cambridge have launched the Cambridge Online Trust and Safety Index (COTSI), the first tool to track the real-time global market for buying fake online accounts. By monitoring prices and stock across 500+ platforms in every country, it reveals the economics behind \"bot armies\" used for scams, artificial popularity, and political influence campaigns.\n\nThe data shows significant price variations, with SMS verification for a fake account costing an average of $4.93 in Japan but just $0.26 in the US and $0.08 in Russia, largely due to differences in SIM card costs and regulations. The analysis also found that prices for accounts on Telegram and WhatsApp spike in countries before national elections, suggesting increased demand for political influence operations.\n\nThe study highlights a thriving underground industry where vendors use farms of physical and virtual SIM cards to bypass platform security. Researchers argue that regulating SIM cards could disrupt this market. They also note that while some platforms like X have introduced country-of-origin labels, many vendors offer services to circumvent these measures.\n\nOverall, COTSI transforms a hidden shadow economy into measurable data, providing a tool to test policy interventions and understand the business model fueling online manipulation and misinformation.",
    "chinese_title": "在线平台机器人军团价格曝光",
    "chinese_summary": "剑桥大学的研究人员推出了剑桥在线信任与安全指数（COTSI），这是首个追踪全球虚假网络账号实时交易市场的工具。该工具通过监测各国500多个平台的价格和库存，揭示了用于诈骗、人为制造热度及政治影响活动的“机器人水军”背后的经济运作。\n\n数据显示，虚假账号的短信验证价格存在显著差异：日本平均需4.93美元，而美国仅0.26美元，俄罗斯低至0.08美元，这主要源于各国SIM卡成本与监管差异。分析还发现，在国家大选前夕，Telegram和WhatsApp账号价格会出现飙升，表明政治影响行动的需求有所增加。\n\n研究揭示了一个蓬勃发展的地下产业：供应商通过实体与虚拟SIM卡农场绕过平台安全机制。研究人员认为，加强对SIM卡的监管可能扰乱这一市场。他们同时指出，尽管X等平台已推出账号来源国标签，但许多供应商仍提供规避此类措施的服务。\n\n总体而言，COTSI将隐秘的灰色经济转化为可量化的数据，为测试政策干预效果、理解助长网络操纵与虚假信息的商业模式提供了有力工具。"
  },
  {
    "id": "46262480",
    "title": "Efficient Basic Coding for the ZX Spectrum",
    "url": "https://blog.jafma.net/2020/02/24/efficient-basic-coding-for-the-zx-spectrum/",
    "summary": "This article explains how to improve the efficiency of ZX Spectrum BASIC programs by optimizing line number usage. A key point is that the interpreter lacks an indexed table of line addresses. Instead, it performs a linear search from the program's start whenever it encounters a jump command (like GO TO, GO SUB, NEXT, or FN). This makes the execution time of these commands increase linearly with the number of lines preceding the target line.\n\nThe main recommendation is to position frequently executed code—such as the targets of loops, subroutines, and user-defined functions (DEF FN)—as close to the program's beginning as possible. This minimizes the interpreter's search time. Additionally, placing RETURN statements and the start of FOR loops at the beginning of their respective lines avoids extra linear searches within a line.\n\nThe article also mentions a trick using POKE to manipulate system variables (PROG, NEWPPC, NSPPC) to alter the interpreter's search starting point or force jumps to specific statements, though this requires caution. Finally, it suggests that for very tight loops, manual loop unrolling (repeating the loop body) can avoid the overhead of NEXT jumps, albeit at the cost of increased program size.",
    "chinese_title": "ZX Spectrum高效基础编程",
    "chinese_summary": "本文阐述了如何通过优化行号使用来提高ZX Spectrum BASIC程序的效率。关键点在于解释器缺乏行地址索引表，每当遇到跳转指令（如GO TO、GO SUB、NEXT或FN）时，它都会从程序开头开始线性搜索。这使得这些指令的执行时间随目标行之前的行数线性增加。\n\n主要建议是将频繁执行的代码（如循环、子程序和用户定义函数（DEF FN）的目标位置）尽可能置于程序开头，以最小化解释器的搜索时间。此外，将RETURN语句和FOR循环的起始点放在各自行的开头，可以避免在行内进行额外的线性搜索。\n\n文章还提到了一种使用POKE操作系统变量（PROG、NEWPPC、NSPPC）的技巧，可以改变解释器的搜索起点或强制跳转到特定语句，但需谨慎使用。最后，文章建议对于非常紧凑的循环，手动展开循环（重复循环体）可以避免NEXT跳转的开销，尽管这会增加程序体积。"
  },
  {
    "id": "46257607",
    "title": "I fed 24 years of my blog posts to a Markov model",
    "url": "https://susam.net/fed-24-years-of-posts-to-markov-model.html",
    "summary": "This article describes a personal project where the author fed 24 years of their blog posts into a simple Markov text generator called \"Mark V. Shaney Junior.\" The program, inspired by a 1980s Usenet bot, works by analyzing sequences of words (trigrams) to build a model that predicts the next word based on the previous two. This creates a \"memoryless\" Markov chain, where each new word depends only on the immediate context.\n\nThe author shares amusing, often incoherent, examples of the gibberish output, which blends phrases from different technical blog posts in surreal ways. They explain that increasing the model's \"order\" (the number of previous words considered) makes the text more coherent but risks simply reproducing large verbatim sections from the source material.\n\nWhile acknowledging that such simple models are unimpressive compared to modern Large Language Models (LLMs), the author highlights the project's value as a minimal, educational introduction to language model concepts. The core implementation is only about 30 lines of Python, emphasizing simplicity and recreational programming.",
    "chinese_title": "我将24年的博客文章输入马尔可夫模型。",
    "chinese_summary": "本文介绍了一个个人项目，作者将自己24年来的博客文章输入到一个名为“Mark V. Shaney Junior”的简单马尔可夫文本生成器中。该程序灵感源自1980年代的Usenet机器人，通过分析词序列（三元组）来构建模型，根据前两个词预测下一个词，从而形成一个“无记忆”的马尔可夫链——每个新词仅依赖于紧邻的上下文。\n\n作者分享了一些有趣但常常语无伦次的生成文本示例，这些输出以超现实的方式混合了不同技术博客中的短语。他们解释道，增加模型的“阶数”（即考虑的前文词数）会使文本更连贯，但也可能直接大段复制原文。\n\n尽管承认这种简单模型与现代大语言模型相比并不出众，但作者强调了该项目作为语言模型概念的极简教育性入门价值。核心实现仅需约30行Python代码，突显了简洁性与趣味编程的理念。"
  },
  {
    "id": "46216008",
    "title": "Getting into Public Speaking",
    "url": "https://james.brooks.page/blog/getting-into-public-speaking",
    "summary": "This article shares practical advice for aspiring public speakers, based on the author's rapid journey from local meetups to large international conferences.\n\nThe guidance is divided into three key areas. For **preparation**, the author stresses starting small at local meetups to build confidence, practicing relentlessly out of respect for the audience, structuring every talk as a clear story, and using extremely large fonts for any live-coding or slides.\n\nFor the **on-stage experience**, tips include removing distracting lanyards, opening with a joke to connect with the audience, owning the stage by moving around, and embracing inevitable deviations from the script. The author emphasizes being a performer—a more energetic, amplified version of yourself.\n\nThe most important lesson is that **the audience is on your side**; no one wants to see you fail. A final bonus tip is to always have water on stage, both to combat dry mouth and to use as a tactical pause.",
    "chinese_title": "开始公开演讲",
    "chinese_summary": "本文分享了作者从本地聚会快速走向大型国际会议的历程中，为有抱负的公共演讲者提供的实用建议。\n\n指导内容分为三个关键领域。在**准备阶段**，作者强调从本地小规模聚会开始以建立自信，出于对听众的尊重而不断练习，将每次演讲构建为清晰的故事线，并在现场编程或幻灯片中使用超大字体。\n\n关于**台上表现**，建议包括取下分散注意力的挂绳，以笑话开场来拉近与听众的距离，通过走动掌控舞台，并坦然接受对讲稿的即兴调整。作者强调要成为一名表演者——展现一个更富活力、更放大的自我。\n\n最重要的经验是**听众是站在你这边的**；没有人希望你失败。最后一个额外建议是：台上务必备水，既缓解口干，也可用作战术性停顿。"
  },
  {
    "id": "46205089",
    "title": "Using e-ink tablet as monitor for Linux",
    "url": "https://alavi.me/blog/e-ink-tablet-as-monitor-linux/",
    "summary": "This article details the author's process for using an Android e-ink tablet as a secondary, mirrored monitor for a Linux system to reduce eye strain during long reading and writing sessions.\n\nThe primary solution involves setting up a VNC server (specifically TigerVNC's `x0vncserver`) on the Linux machine and connecting to it from the tablet using a VNC client like AVNC. This method was chosen over alternatives like Deskreen due to its lower latency and better text quality, which are critical for e-ink displays.\n\nKey steps include installing TigerVNC, setting a password with `vncpasswd`, and running the server with specific parameters like `-Geometry` to match the tablet's resolution and `-FrameRate` for performance. The author provides a script to automate switching the primary monitor to the tablet's resolution and launching the VNC server.\n\nThe intended use is for distraction-free reading and light text editing, not for coding or web browsing, due to the inherent latency and refresh rate limitations of e-ink technology. The setup also allows the tablet to function as an input device for tasks like drawing or presentations.",
    "chinese_title": "使用电子墨水屏作为Linux显示器",
    "chinese_summary": "本文详细介绍了作者如何将安卓电子墨水屏平板作为Linux系统的辅助镜像显示器，以缓解长时间读写带来的视觉疲劳。\n\n核心方案是在Linux主机上搭建VNC服务器（特别是TigerVNC的`x0vncserver`），并通过平板上的AVNC等VNC客户端进行连接。相比Deskreen等替代方案，该方法因延迟更低、文字显示更清晰而被选用，这对电子墨水屏至关重要。\n\n关键步骤包括安装TigerVNC、使用`vncpasswd`设置密码，以及运行服务器时指定`-Geometry`参数匹配平板分辨率、`-FrameRate`参数优化性能。作者还提供了自动化脚本，可一键切换主显示器分辨率并启动VNC服务器。\n\n由于电子墨水屏固有的延迟和刷新率限制，该方案主要用于无干扰阅读和轻量文本编辑，不适用于编程或网页浏览。此设置还支持将平板作为绘图、演示等任务的输入设备。"
  },
  {
    "id": "46223617",
    "title": "Show HN: Cargo-rail: graph-aware monorepo tooling for Rust; 11 deps",
    "url": "https://github.com/loadingalias/cargo-rail",
    "summary": "**Summary: cargo-rail is a monorepo management tool for Rust that unifies and automates several key tasks with minimal dependencies.**\n\nIts core command, `cargo rail unify`, consolidates multiple existing tools by:\n*   **Unifying dependency versions** across the workspace (replacing `cargo-hakari`).\n*   **Detecting and removing unused dependencies and dead features.**\n*   **Computing the Minimum Supported Rust Version (MSRV)** from the dependency graph.\n*   **Fixing \"undeclared features\"** to prevent brittle builds.\n\nOther major features include:\n*   **`cargo rail affected` / `test`:** Graph-aware change detection to run tests only for crates impacted by a change, significantly reducing CI time.\n*   **`cargo rail split` / `sync`:** Extracts crates into separate repositories with full git history and enables bidirectional synchronization.\n*   **`cargo rail release`:** Orchestrates dependency-order publishing with changelog generation.\n\nThe tool is designed to be lightweight (11 dependencies), uses Cargo's actual resolver output for accuracy, and works with existing Cargo workspace features. It aims to provide the benefits of complex build systems like Bazel for pure Rust monorepos while staying within the Cargo ecosystem.",
    "chinese_title": "展示 HN：Cargo-rail：面向 Rust 的图形感知型单仓库工具；仅需 11 个依赖项",
    "chinese_summary": "**摘要：cargo-rail 是一个用于 Rust 的单体仓库管理工具，它以最少的依赖项统一并自动化了多项关键任务。**\n\n其核心命令 `cargo rail unify` 通过以下方式整合了多个现有工具：\n*   **统一工作空间内的依赖版本**（替代 `cargo-hakari`）。\n*   **检测并移除未使用的依赖项和无效特性。**\n*   **根据依赖图计算最低支持的 Rust 版本（MSRV）。**\n*   **修复“未声明的特性”**，以防止脆弱的构建。\n\n其他主要功能包括：\n*   **`cargo rail affected` / `test`：** 基于图的变更检测，仅运行受变更影响的 crate 的测试，显著减少 CI 时间。\n*   **`cargo rail split` / `sync`：** 将 crate 提取到独立的仓库中并保留完整的 git 历史，支持双向同步。\n*   **`cargo rail release`：** 按照依赖顺序编排发布流程，并生成变更日志。\n\n该工具设计轻量（11 个依赖项），使用 Cargo 的实际解析器输出以确保准确性，并与现有的 Cargo 工作空间功能兼容。其目标是为纯 Rust 单体仓库提供类似 Bazel 等复杂构建系统的优势，同时保持在 Cargo 生态系统内。"
  },
  {
    "id": "46174735",
    "title": "Science Communications on YouTube",
    "url": "https://blogs.memphis.edu/awindsor/2025/02/25/science-communication-on-youtube/",
    "summary": "This article highlights popular science communication channels on YouTube, focusing on those run by individuals or small teams. It lists eleven key channels, including Veritasium, SmarterEveryDay, and Numberphile, which use engaging formats like experiments, animations, and expert interviews to explore scientific concepts and debunk misconceptions.\n\nThe author contrasts the high subscriber counts of these independent channels (e.g., Numberphile with 4.62 million) with the typically lower reach of official channels from national STEM societies, such as the American Mathematical Society. A notable exception is the American Chemical Society's \"ACS Reactions\" channel, which is praised as an excellent model for translating academic research for a general audience, boasting 546,000 subscribers.\n\nIn summary, the piece underscores the significant public engagement achieved by independent science communicators on YouTube, while suggesting that larger scientific organizations could learn from their successful, accessible approach to content creation.",
    "chinese_title": "YouTube上的科学传播",
    "chinese_summary": "本文重点介绍了YouTube上由个人或小型团队运营的热门科学传播频道，列举了包括Veritasium、SmarterEveryDay和Numberphile在内的十一个代表性频道。这些频道通过实验演示、动画解说和专家访谈等生动形式，深入浅出地阐释科学概念并破除常见误解。\n\n作者对比了这些独立频道的高订阅量（如Numberphile拥有462万订阅者）与国家级科学机构官方频道普遍较低的影响力，例如美国数学学会的频道。值得关注的是美国化学学会旗下“ACS Reactions”频道作为例外，因其将学术研究转化为大众内容的卓越模式获得赞誉，该频道已积累54.6万订阅者。\n\n总之，文章强调了独立科学传播者在YouTube上实现的广泛公众影响力，同时指出大型科学组织可借鉴其成功的内容创作模式，以更贴近大众的方式开展科学传播。"
  },
  {
    "id": "46213985",
    "title": "Cat Gap",
    "url": "https://en.wikipedia.org/wiki/Cat_gap",
    "summary": "The \"cat gap\" refers to a period in the fossil record from about 25 to 18.5 million years ago when few cat-like species (feliforms) are found in North America. This began with the extinction of the nimravids, saber-toothed predators that were not true cats. The gap ended when true cats (felids) arrived from Asia via the Bering land bridge.\n\nThe cause of the gap is debated. One leading theory is that the nimravids became extinct due to **hypercarnivory**—an over-specialization in eating only meat, which made them vulnerable. Another major theory points to **climate change**, specifically global cooling that transformed forests into open savannas, eliminating the preferred hunting habitats of cat-like predators. Other possible factors include massive volcanic eruptions and the onset of the Late Cenozoic Ice Age.\n\nDuring this period, some scientists suggest that dog-like species (caniforms) evolved to fill the vacant hypercarnivore niches, though this is disputed. Evidence shows that while some caniforms developed more cat-like teeth, they did not fully occupy the same ecological space, and their hypercarnivorous forms declined before true cats arrived.\n\nIn summary, the cat gap represents a significant turnover in North American predators, likely driven by ecological specialization and environmental change, which temporarily left a niche unfilled until modern cat ancestors migrated from Eurasia.",
    "chinese_title": "猫断层",
    "chinese_summary": "\"猫科断层\"指的是距今约2500万至1850万年前的化石记录时期，当时在北美很少发现猫形类物种。这一断层始于伪剑齿虎（并非真正猫科动物的剑齿类掠食者）的灭绝，随着真正的猫科动物通过白令陆桥从亚洲抵达而结束。\n\n断层成因存在争议。主流理论之一是伪剑齿虎因**极端肉食性特化**而灭绝——过度专食肉类的习性使其生存脆弱。另一重要理论指向**气候变化**，特别是全球变冷使森林转变为开阔草原，消除了猫形掠食者偏好的狩猎栖息地。其他可能因素包括大规模火山喷发和晚新生代冰期的开始。\n\n有科学家认为，在此时期犬形类物种进化填补了空缺的极端肉食动物生态位，但这存在争议。证据表明，虽然部分犬形类演化出更类似猫科的牙齿，但并未完全占据相同生态空间，且其极端肉食形态在真猫到来前就已衰退。\n\n总之，猫科断层代表了北美掠食动物的重大更替，很可能是生态特化和环境变化共同驱动的结果，这一生态位在现生猫科祖先从欧亚大陆迁入前曾暂时空缺。"
  },
  {
    "id": "46265636",
    "title": "Six Big Bets",
    "url": "https://www.jerry.wtf/posts/six-big-bets/",
    "summary": "This article argues that individuals have only a few key windows in life to take major career or entrepreneurial risks, as the necessary resources—risk tolerance, energy, capital, and conviction—rarely align. It outlines six distinct phases for these \"big bets,\" each leveraging different advantages:\n\n1.  **Age 18: Naïve Conviction** – Leverages ignorance, energy, and a high tolerance for failure, often insulated by youth or background.\n2.  **Age 23: Facing Reality** – Combines early real-world experience with energy to identify and tackle obvious inefficiencies.\n3.  **Age 28: Informed Speed** – Pairs deep tacit knowledge, a growing network, and high energy for lethal execution.\n4.  **Age 36: Lateral Leap** – Uses deep domain expertise to solve mispriced problems in adjacent industries, trading speed for experience.\n5.  **Age 42: Capitalized Execution** – Applies capital, relationships, and institutional trust to make deliberate, hypothesis-driven ventures.\n6.  **Age 51: Durable Craft** – Focuses on building durable, cash-flow-positive businesses or scaling impact through ideas, teaching, or investing.\n\nThe core takeaway, inspired by Nassim Taleb, is to structure your life to be exposed to upside potential at the right moments. Success requires understanding which advantages (e.g., energy vs. experience) you possess at each phase and not squandering resources between these finite opportunities.",
    "chinese_title": "六大赌注",
    "chinese_summary": "本文认为，个人一生中仅有少数几个关键窗口期适合承担重大的职业或创业风险，因为所需的资源——风险承受力、精力、资本和信念——很少能同时具备。文章将这些“重大抉择”划分为六个不同阶段，每个阶段都利用了不同的优势：\n\n1.  **18岁：天真的信念**——利用无知、精力和对失败的高容忍度，常因年轻或背景而受到保护。\n2.  **23岁：面对现实**——结合早期的现实世界经验和精力，识别并解决明显的低效问题。\n3.  **28岁：有见识的速度**——将深刻的隐性知识、不断扩展的人脉和高能量结合，实现致命执行力。\n4.  **36岁：横向跨越**——利用深厚的领域专业知识，解决相邻行业中价值被低估的问题，以经验换取速度。\n5.  **42岁：资本化执行**——运用资本、人脉和机构信任，进行深思熟虑、假设驱动的创业。\n6.  **51岁：持久的事业**——专注于建立持久、现金流为正的企业，或通过思想、教学或投资来扩大影响力。\n\n核心启示（受纳西姆·塔勒布启发）是：构建自己的生活，以便在正确时刻迎接上行潜力。成功需要理解你在每个阶段拥有哪些优势（例如精力 vs. 经验），并且不在这些有限的机会之间浪费资源。"
  },
  {
    "id": "46255991",
    "title": "I tried Gleam for Advent of Code",
    "url": "https://blog.tymscar.com/posts/gleamaoc2025/",
    "summary": "The author recounts using Gleam, a functional programming language, for the 2024 Advent of Code (AoC), a 12-day programming challenge. They found Gleam well-suited to AoC's puzzle-solving style, praising its clean syntax, helpful compiler, and powerful list manipulation functions like `transpose` and `combination_pairs`. The `fold_until` function was a particular highlight for enabling clean early exits in algorithms.\n\nThe language's use of Options for safe handling of missing values (like out-of-bounds grid checks) and its pipeline operator (`|>`) for readable data transformations were significant advantages. However, the author noted some friction points: basic file I/O and regex support require external dependencies, list pattern matching has limitations, and using big integers on the JavaScript target adds complexity.\n\nSpecific puzzle solutions highlighted Gleam's strengths, such as using bitwise XOR elegantly for a toggling puzzle. The author's least satisfying moment involved a workaround—shelling out to an external solver for a linear programming problem. Overall, despite some rough edges in the standard library, the author was impressed with Gleam's functional approach and plans to use it for future projects like a webserver.",
    "chinese_title": "我尝试用Gleam语言完成Advent of Code挑战。",
    "chinese_summary": "作者回顾了在2024年“代码降临节”（Advent of Code，简称AoC）这一为期12天的编程挑战中使用Gleam这一函数式编程语言的经历。他们发现Gleam非常适合AoC的解谜风格，称赞其简洁的语法、实用的编译器以及强大的列表处理函数，如`transpose`和`combination_pairs`。其中`fold_until`函数尤其突出，能够优雅地实现算法中的提前退出。\n\n该语言使用Option类型安全处理缺失值（如越界网格检查），并通过管道运算符（`|>`）实现可读的数据转换，这些都是显著优势。然而，作者也指出了一些不足之处：基础的文件I/O和正则表达式支持需要依赖外部库，列表模式匹配功能有限，且在JavaScript目标平台上使用大整数会增加复杂度。\n\n具体谜题的解决方案突显了Gleam的优势，例如巧妙利用按位异或处理开关类谜题。作者最不满意的时刻涉及一个变通方案——需调用外部求解器处理线性规划问题。总体而言，尽管标准库存在一些不完善之处，作者仍对Gleam的函数式编程方法印象深刻，并计划在未来项目（如网络服务器）中继续使用它。"
  },
  {
    "id": "46258163",
    "title": "Recovering Anthony Bourdain's Li.st's",
    "url": "https://sandyuraz.com/blogs/bourdain/",
    "summary": "This article details an effort to recover Anthony Bourdain's lost lists from the defunct platform Li.st by using the Common Crawl web archive. The author, a security and crawling expert, wrote a script to search for and retrieve the HTML of Bourdain's lists from publicly available crawl data.\n\nThe project successfully recovered the text content of 15 lists, including titles like \"Things I No Longer Have Time or Patience For,\" \"Objects of Desire,\" and \"Great Dead Bars of New York.\" However, all the original images that accompanied the lists were lost and could not be restored. Only one list, \"David Bowie Related,\" was completely unrecoverable from the archive.\n\nThe author presents the recovered lists with minimal formatting, preserving Bourdain's original text and noting where images are missing. The work is shared as an open-source project, inviting others to contribute to similar digital preservation efforts. The article concludes by celebrating the successful textual recovery while acknowledging the permanent loss of the visual elements.",
    "chinese_title": "恢复安东尼·波登的Li.st列表",
    "chinese_summary": "本文详细介绍了利用Common Crawl网络存档，从已关闭的平台Li.st中恢复安东尼·波登遗失清单的努力。作者作为一名安全与爬虫专家，编写了脚本从公开的爬取数据中搜索并提取波登清单的HTML内容。\n\n该项目成功恢复了15份清单的文本内容，包括《我不再有时间或耐心去做的事》《欲望之物》《纽约已逝的伟大酒吧》等标题。然而，所有清单附带的原始图片均已丢失且无法恢复。只有一份名为《与大卫·鲍伊相关》的清单在存档中完全无法找回。\n\n作者以极简的格式呈现了恢复的清单，保留了波登的原始文本，并标注了图片缺失的位置。这项工作作为开源项目分享，邀请他人为类似的数字保存工作贡献力量。文章最后庆祝了文本内容的成功恢复，同时也承认了视觉元素的永久缺失。"
  },
  {
    "id": "46203477",
    "title": "Building a Modern C64 Assembly AI Toolchain",
    "url": "https://medium.com/@gianlucabailo/building-a-modern-c64-assembly-ai-toolchain-using-google-gemini-3-1a36464c9458",
    "summary": "**Summary of \"Building a Modern C64 Assembly AI Toolchain\"**\n\nThe article details a project to create a contemporary development workflow for Commodore 64 (C64) assembly programming by integrating Google's Gemini AI model. The author, Gianluca Bailo, aims to bridge the gap between modern AI tools and the vintage 6502 assembly language.\n\nThe core of the toolchain is a custom script that acts as an intermediary. A developer describes a desired C64 program feature or function in plain English. This prompt is then sent to the Gemini API with specific context and instructions, framing the AI as a \"6502 Assembly Language Programming Expert.\" Gemini generates the corresponding assembly code, which is automatically formatted and saved to a file.\n\nThe workflow is designed to be iterative. The generated code can be assembled and tested immediately using the author's preferred tools (like the `64tass` assembler and the `VICE` emulator). If the code doesn't work, the error output can be fed back to Gemini with a request for a fix, creating a feedback loop.\n\nThe author acknowledges the AI's limitations, noting it can produce non-functional or inefficient code and sometimes \"hallucinates\" incorrect syntax or non-existent commands. Therefore, the tool is positioned as a powerful assistant for brainstorming, prototyping, and explaining concepts, but not as a replacement for the programmer's own knowledge and final debugging. The conclusion highlights this hybrid approach, combining AI-powered code generation with traditional assembly programming skills to create a more efficient and accessible modern development environment for the classic C64.",
    "chinese_title": "构建现代C64汇编AI工具链",
    "chinese_summary": "**《构建现代C64汇编AI工具链》概要**\n\n本文详述了一个通过集成谷歌Gemini AI模型，为Commodore 64（C64）汇编编程创建现代化开发工作流的项目。作者Gianluca Bailo旨在弥合现代AI工具与经典6502汇编语言之间的鸿沟。\n\n该工具链的核心是一个充当中间人的自定义脚本。开发者用简单英语描述所需的C64程序功能，该提示随后被发送至Gemini API，并附有特定上下文和指令——将AI定位为“6502汇编语言编程专家”。Gemini生成相应的汇编代码，代码会被自动格式化并保存到文件中。\n\n该工作流被设计为迭代式。生成的代码可以立即使用作者偏好的工具（如`64tass`汇编器和`VICE`模拟器）进行汇编和测试。如果代码无法运行，错误输出可反馈给Gemini并请求修复，从而形成一个反馈循环。\n\n作者承认AI存在局限性，指出它可能生成无效或低效的代码，有时甚至会“幻觉”出错误的语法或不存在的指令。因此，该工具被定位为一个用于头脑风暴、原型设计和概念解释的强大助手，而非替代程序员自身知识和最终调试工作。结论强调了这种混合方法：将AI驱动的代码生成与传统的汇编编程技能相结合，从而为经典的C64创建一个更高效、更易访问的现代开发环境。"
  }
]