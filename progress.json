[
  {
    "id": "46290916",
    "title": "alpr.watch",
    "url": "https://alpr.watch/",
    "summary": "**Summary of alpr.watch**\n\nalpr.watch is a website and mapping tool designed to help citizens track and oppose the local adoption of mass surveillance technologies, primarily Automated License Plate Readers (ALPRs) like those from Flock Safety.\n\nThe core problem it addresses is the rapid, often quiet, deployment of these systems by municipalities across the U.S., which capture and store data on vehicle movements, creating detailed records of people's daily lives. The site argues this represents a dangerous expansion of surveillance with risks of mission creep and insufficient oversight.\n\nIts primary function is to scan local government meeting agendas for keywords related to surveillance (e.g., \"Flock,\" \"ALPR\") and plot upcoming discussions on an interactive map. This allows users to identify where these technologies are being proposed so they can attend meetings and take action.\n\nThe site also provides educational resources explaining how ALPR and Flock systems work, their societal risks, and lists national organizations like the EFF and ACLU that are fighting surveillance overreach. Additionally, it offers a service for users to sign up for email alerts about relevant meetings in their area.\n\nIn essence, alpr.watch is a grassroots transparency and mobilization tool aimed at equipping the public with information to participate in and challenge local decisions about pervasive surveillance infrastructure.",
    "chinese_title": "车牌识别监控",
    "chinese_summary": "**alpr.watch 简介**\n\nalpr.watch 是一个网站和地图工具，旨在帮助公民追踪并反对地方采用大规模监控技术，主要是像 Flock Safety 那样的自动车牌识别系统。\n\n其解决的核心问题是美国各地市政当局快速且常常悄无声息地部署这些系统，这些系统捕获并存储车辆移动数据，从而创建人们日常生活的详细记录。该网站认为，这代表着监控的危险扩张，存在任务蔓延和监督不足的风险。\n\n其主要功能是扫描地方政府会议议程中与监控相关的关键词（如“Flock”、“ALPR”），并将即将进行的讨论标注在交互式地图上。这使用户能够识别这些技术正在被提议的地点，从而可以参加会议并采取行动。\n\n该网站还提供教育资源，解释 ALPR 和 Flock 系统的工作原理及其社会风险，并列出如电子前沿基金会和美国公民自由联盟等正在对抗监控越权的全国性组织。此外，它还提供一项服务，让用户可以注册接收关于其所在地区相关会议的电子邮件提醒。\n\n本质上，alpr.watch 是一个草根透明化和动员工具，旨在为公众提供信息，使其能够参与并挑战地方关于普遍性监控基础设施的决策。"
  },
  {
    "id": "46293062",
    "title": "No Graphics API",
    "url": "https://www.sebastianaaltonen.com/blog/no-graphics-api",
    "summary": "This article argues that modern low-level graphics APIs (DirectX 12, Vulkan, Metal) are outdated and overly complex. They were designed a decade ago for older GPU hardware that required extensive pre-bundling of state into persistent objects to reduce driver overhead.\n\nThe author, a veteran graphics programmer, explains that today's GPUs have evolved significantly. They now feature coherent cache hierarchies, support for 64-bit GPU pointers, and bindless resources, making much of the API's retained-mode complexity unnecessary. The biggest flaw highlighted is the \"PSO permutation explosion,\" where pre-compiled pipeline state objects lead to massive caches, slow load times, and stuttering in games.\n\nThe post traces the historical reasons for API design, from early fixed-function hardware (like the 3dfx Voodoo 2) through to the introduction of programmable shaders and compute. It notes that while APIs like DirectX 11 added flexibility, they also introduced a zoo of complex, opaque buffer types and descriptors that persist for backward compatibility.\n\nThe core conclusion is that a new API designed for today's hardware could be drastically simpler, eliminating redundant persistent objects and leveraging modern GPU capabilities like direct memory access and bindless resources, ultimately solving the performance and complexity issues plaguing current \"modern\" APIs.",
    "chinese_title": "无图形API",
    "chinese_summary": "本文认为，现代低级图形API（DirectX 12、Vulkan、Metal）已经过时且过于复杂。这些API设计于十年前，针对当时需要将大量状态预打包成持久对象以减少驱动开销的老旧GPU硬件。\n\n作者作为资深图形程序员解释道，当今的GPU已显著进化。它们现在具备一致的缓存层次结构、支持64位GPU指针以及无绑定资源，这使得API中许多保留模式的复杂性变得不再必要。文章强调的最大缺陷是“PSO排列爆炸”——预编译的管线状态对象导致庞大的缓存、缓慢的加载时间以及游戏中的卡顿现象。\n\n文章追溯了API设计的历史原因，从早期的固定功能硬件（如3dfx Voodoo 2）到可编程着色器和计算单元的引入。文中指出，尽管DirectX 11等API增加了灵活性，但也引入了大量复杂且不透明的缓冲区类型和描述符，这些设计因向后兼容性而得以保留。\n\n核心结论是，为当今硬件设计的新API可以大幅简化，消除冗余的持久对象，并充分利用现代GPU的直接内存访问和无绑定资源等能力，最终解决当前“现代”API所困扰的性能与复杂度问题。"
  },
  {
    "id": "46288415",
    "title": "40 percent of fMRI signals do not correspond to actual brain activity",
    "url": "https://www.tum.de/en/news-and-events/all-news/press-releases/details/40-percent-of-mri-signals-do-not-correspond-to-actual-brain-activity",
    "summary": "A new study published in *Nature Neuroscience* challenges a foundational assumption of functional magnetic resonance imaging (fMRI), suggesting that up to 40% of its signals may not reliably indicate brain activity.\n\nFor decades, fMRI has interpreted increased blood flow (the BOLD signal) as a proxy for increased neuronal activity and oxygen demand. However, researchers from TUM and FAU, measuring actual oxygen consumption in over 40 participants, found this coupling is not universal. They observed that during tasks like mental arithmetic, brain regions with increased activity often showed *decreased* fMRI signals, while reduced activity could coincide with *increased* signals.\n\nThe key finding is that active brain regions can meet higher energy needs by extracting more oxygen from existing blood flow, rather than requiring increased perfusion. This means the standard fMRI signal can be misleading, potentially leading to opposite interpretations of brain activation in thousands of existing studies.\n\nThe implications are significant for neuroscience and clinical research. Findings in conditions like depression or Alzheimer’s, often based on blood flow changes, may reflect vascular differences rather than true neuronal deficits, especially in older patients. The authors advocate for complementing traditional fMRI with quantitative oxygen metabolism measurements to create more accurate, energy-based models of brain function.",
    "chinese_title": "40%的功能磁共振成像信号与实际大脑活动不符",
    "chinese_summary": "《自然·神经科学》发表的一项新研究挑战了功能性磁共振成像（fMRI）的基础假设，指出其高达40%的信号可能无法可靠反映大脑活动。\n\n数十年来，fMRI一直将血流量增加（BOLD信号）解读为神经元活动增强和需氧量上升的标志。然而，慕尼黑工业大学和埃尔朗根-纽伦堡大学的研究人员通过对40多名参与者实际耗氧量的测量，发现这种关联并非普遍存在。他们观察到，在心算等任务期间，活动增强的脑区常出现fMRI信号减弱的现象，而活动减弱时信号反而可能增强。\n\n关键发现在于：活跃脑区可以通过从现有血流中提取更多氧气来满足更高的能量需求，而非必须依赖灌注量增加。这意味着标准fMRI信号可能产生误导，导致对现有数千项研究中大脑激活状态的解读出现反向偏差。\n\n这对神经科学和临床研究具有重大意义。针对抑郁症或阿尔茨海默症等疾病的研究结论常基于血流变化，但这些发现可能反映的是血管差异而非真实的神经元功能缺损，在老年患者中尤为明显。作者主张在传统fMRI基础上结合定量氧代谢测量，以建立更精准、基于能量代谢的大脑功能模型。"
  },
  {
    "id": "46288491",
    "title": "Mozilla appoints new CEO Anthony Enzor-Demeo",
    "url": "https://blog.mozilla.org/en/mozilla/leadership/mozillas-next-chapter-anthony-enzor-demeo-new-ceo/",
    "summary": "Mozilla has appointed **Anthony Enzor-DeMeo** as its new CEO, effective December 16, 2025. He succeeds interim CEO **Laura Chambers**, who is returning to Mozilla’s board of directors after leading the organization through a period of significant change, including AI integration and growth for Firefox.\n\nEnzor-DeMeo outlines a clear vision for Mozilla’s future: to become **\"the world’s most trusted software company.\"** He argues that trust is the defining issue in technology, particularly in the browser, where decisions about privacy, data, and AI transparency are made.\n\nThis vision is built on three core pillars:\n1.  **User Agency:** Products must offer clear controls, understandable data practices, and the ability to easily opt out of AI features.\n2.  **Trust-Aligned Business:** Revenue growth will come from transparent monetization that users value.\n3.  **Expanded Ecosystem:** Firefox will evolve into a modern AI browser at the center of a broader portfolio of trusted software.\n\nThe strategy includes a \"double bottom line,\" measuring success by both advancing Mozilla’s mission and achieving market growth. Key goals for the next three years are investing in AI aligned with Mozilla’s principles, diversifying revenue beyond search, and expanding Firefox’s user base.\n\nEnzor-DeMeo believes current shifts in AI, regulation, and the browser’s role as a digital control point play to Mozilla’s strengths, positioning the company for increased relevance and resilience.",
    "chinese_title": "Mozilla任命安东尼·恩佐尔-德梅奥为新任首席执行官",
    "chinese_summary": "Mozilla任命**安东尼·恩佐尔-德梅奥**为新任首席执行官，自2025年12月16日起生效。他将接替临时首席执行官**劳拉·钱伯斯**。钱伯斯在领导Mozilla度过人工智能整合与Firefox增长等重大变革期后，将重返Mozilla董事会。\n\n恩佐尔-德梅奥为Mozilla的未来描绘了清晰愿景：成为 **“全球最受信赖的软件公司”** 。他认为信任是科技领域的核心议题，尤其在浏览器这一关乎隐私、数据和人工智能透明度的决策平台。\n\n这一愿景建立在三大核心支柱之上：\n1.  **用户自主权：** 产品须提供清晰的控制选项、易于理解的数据实践，并允许用户轻松退出人工智能功能。\n2.  **信任导向型业务：** 营收增长将来自用户认可的透明盈利模式。\n3.  **扩展生态系统：** Firefox将发展为现代人工智能浏览器，并成为更广泛可信软件生态的核心。\n\n该战略包含“双重底线”原则，即同时以推进Mozilla使命和实现市场增长来衡量成功。未来三年的关键目标包括：投资符合Mozilla原则的人工智能技术、拓展搜索以外的多元化收入来源，以及扩大Firefox用户基数。\n\n恩佐尔-德梅奥认为，当前人工智能发展、监管环境变化以及浏览器作为数字控制点的角色演变，正发挥Mozilla的优势，使公司能在未来提升行业影响力并增强发展韧性。"
  },
  {
    "id": "46282874",
    "title": "The World Happiness Report is beset with methodological problems",
    "url": "https://yaschamounk.substack.com/p/the-world-happiness-report-is-a-sham",
    "summary": "This article argues that the widely cited World Happiness Report is methodologically flawed and misleading. It notes that the report's ranking is based solely on responses to the \"Cantril Ladder\" question, which measures life satisfaction rather than moment-to-moment happiness and may prime respondents to think about wealth and status.\n\nThe author contends that this single metric does not correlate well with other indicators of well-being, pointing out that top-ranked Scandinavian nations like Finland and Sweden have high rates of antidepressant use and suicide. Citing alternative research by economists Blanchflower and Bryson, which incorporates measures of both positive and negative daily emotions, the article shows that the global happiness ranking changes dramatically. For example, Finland falls to 51st place, while the United States appears much happier when analyzed by state, with several states outperforming all countries.\n\nThe piece concludes that the report is a form of \"elite misinformation\" and criticizes media outlets for uncritically promoting its findings. It warns against abandoning established metrics like GDP for unreliable happiness rankings and calls for greater journalistic scrutiny of such studies.",
    "chinese_title": "《世界幸福报告》存在方法论上的问题。",
    "chinese_summary": "本文认为，被广泛引用的《世界幸福报告》在方法论上存在缺陷且具有误导性。文章指出，该报告的排名仅基于对“坎特里尔阶梯”问题的回答——该问题测量的是生活满意度而非即时幸福感，并可能引导受访者联想到财富与地位。\n\n作者主张，这一单一指标与其它福祉衡量标准关联性较弱，并指出排名靠前的斯堪的纳维亚国家（如芬兰和瑞典）抗抑郁药物使用率和自杀率居高不下。通过引用经济学家布兰奇弗劳尔与布赖森提出的综合测量每日正负情绪的研究，文章显示全球幸福排名会发生显著变化：例如芬兰跌至第51位，而美国各州数据则呈现更高幸福感，多个州的表现甚至超越所有国家。\n\n文章最终指出该报告实为一种“精英阶层的信息误导”，并批评媒体对其结论不加甄别的传播。作者警告不应以不可靠的幸福排名取代GDP等成熟指标，同时呼吁新闻界对此类研究加强审查力度。"
  },
  {
    "id": "46291941",
    "title": "GPT Image 1.5",
    "url": "https://openai.com/index/new-chatgpt-images-is-here/",
    "summary": "I am unable to access the article link. My browsing functionality is currently disabled, which prevents me from retrieving and reading the content at the provided URL (https://openai.com/index/new-chatgpt-images-is-here/).\n\nTo get a summary, you could:\n1. Visit the link directly and share the text with me.\n2. Use a web browser or a tool with active internet access to read the article.\n\nPlease provide the article's text, and I will be happy to summarize it for you.",
    "chinese_title": "GPT图像1.5",
    "chinese_summary": "我无法访问文章链接。我的浏览功能目前处于禁用状态，因此无法检索和阅读所提供网址（https://openai.com/index/new-chatgpt-images-is-here/）的内容。\n\n要获取摘要，您可以：\n1. 直接访问链接并与我分享文本。\n2. 使用具有活跃网络访问权限的网页浏览器或工具来阅读文章。\n\n请提供文章文本，我将很乐意为您进行摘要。"
  },
  {
    "id": "46291172",
    "title": "FVWM-95",
    "url": "https://fvwm95.sourceforge.net/",
    "summary": "**Summary of \"FVWM-95\"**\n\nFVWM-95 is a highly configurable window manager for the X Window System, designed to emulate the look and feel of the Windows 95 desktop environment on Unix-like operating systems. It is a derivative of the popular FVWM (F? Virtual Window Manager).\n\nThe project's primary goal is to provide a familiar and productive desktop for users transitioning from Windows 95 or those who prefer its classic interface paradigm. Key features highlighted include:\n\n*   **Windows 95 Aesthetics:** It replicates core visual elements such as the Start menu, taskbar, desktop icons, window decorations, and control panels.\n*   **Customizability:** Staying true to its FVWM roots, it offers extensive configuration options. Users can modify menus, functions, and behaviors by editing plain text configuration files.\n*   **Lightweight and Efficient:** As a window manager (not a full desktop environment), it is designed to be resource-efficient, making it suitable for older or less powerful systems.\n*   **Functionality:** It supports virtual desktops, window shading, iconification, and other standard window management operations within the Windows 95-style framework.\n\nThe website serves as the official project page, hosting documentation, configuration examples, screenshots, and source code for download. FVWM-95 is presented as a nostalgic and practical solution for creating a Windows 95-like workspace on Linux or other Unix-based systems, emphasizing user control and a low system footprint.",
    "chinese_title": "FVWM-95",
    "chinese_summary": "**《FVWM-95》概述**\n\nFVWM-95 是一款高度可配置的 X 窗口系统窗口管理器，旨在在类 Unix 操作系统上模拟 Windows 95 桌面环境的外观和体验。它是流行的 FVWM（F? 虚拟窗口管理器）的一个衍生版本。\n\n该项目的主要目标是为从 Windows 95 过渡的用户或偏爱其经典界面范式的用户提供一个熟悉且高效的工作桌面。其强调的主要特性包括：\n\n*   **Windows 95 美学：** 它复制了核心视觉元素，如开始菜单、任务栏、桌面图标、窗口装饰和控制面板。\n*   **高度可定制：** 秉承其 FVWM 的传统，它提供了广泛的配置选项。用户可以通过编辑纯文本配置文件来修改菜单、功能和行为。\n*   **轻量高效：** 作为一个窗口管理器（而非完整的桌面环境），它设计为资源高效型，适用于老旧或性能较低的系统。\n*   **功能性：** 在 Windows 95 风格的框架内，它支持虚拟桌面、窗口卷起、图标化以及其他标准的窗口管理操作。\n\n该网站作为官方项目页面，托管了文档、配置示例、屏幕截图和可供下载的源代码。FVWM-95 被呈现为一种怀旧且实用的解决方案，用于在 Linux 或其他基于 Unix 的系统上创建类似 Windows 95 的工作空间，并强调用户控制权和较低的系统资源占用。"
  },
  {
    "id": "46289918",
    "title": "Writing a blatant Telegram clone using Qt, QML and Rust. And C++",
    "url": "https://kemble.net/blog/provoke/",
    "summary": "The author describes a short-term project to create a Telegram-like desktop app using Qt, QML, and Rust (with some C++). The primary motivation was to revisit QML for UI development and explore integrating it with Rust. After initial struggles with build times in `cxx-qt`, they switched to `qmetaobject-rs` for faster iteration and implemented a basic hot-reload system for QML files.\n\nThe article details several UI components they successfully cloned from Telegram, including a custom splitter, a collapsible sidebar with animations, chat bubbles with directional tails, and an elaborate emoji-reaction popup. They also implemented window minimization to the system tray with a dynamic notification badge, leveraging Qt's experimental `SystemTrayIcon` and `ShaderEffectSource` to generate the icon.\n\nThe project served as a technical exploration, allowing the author to re-learn QML techniques like synchronized animations using `NumberAnimation` and property bindings. While they achieved a visually convincing prototype of Telegram's interface, the work remains incomplete, shelved in favor of other projects. The experience highlighted both the strengths of QML for rapid UI prototyping and the practical challenges of combining it with Rust.",
    "chinese_title": "使用Qt、QML、Rust以及C++编写一个明目张胆的Telegram克隆版。",
    "chinese_summary": "作者描述了一个短期项目：使用Qt、QML和Rust（辅以少量C++）开发类似Telegram的桌面应用。主要动机是重新探索QML进行界面开发，并尝试将其与Rust集成。在初期因`cxx-qt`编译耗时过长遇到困难后，他们转而采用`qmetaobject-rs`以加速迭代，并为QML文件实现了基础的热重载系统。\n\n文章详细介绍了他们成功复刻的多个Telegram界面组件，包括自定义分割器、带动画的可折叠侧边栏、带方向性尾部的聊天气泡，以及精致的表情反应弹窗。他们还利用Qt实验性的`SystemTrayIcon`和`ShaderEffectSource`功能，实现了窗口最小化到系统托盘并显示动态通知徽标。\n\n该项目是一次技术探索，让作者重新掌握了使用`NumberAnimation`和属性绑定实现同步动画等QML技巧。虽然他们完成了视觉上高度还原的Telegram界面原型，但项目尚未完结，因其他工作优先级而被搁置。此次实践既展现了QML在快速界面原型开发中的优势，也揭示了将其与Rust结合时面临的实际挑战。"
  },
  {
    "id": "46291414",
    "title": "GitHub will begin charging for self-hosted action runners on March 2026",
    "url": "https://github.blog/changelog/2025-12-16-coming-soon-simpler-pricing-and-a-better-experience-for-github-actions/",
    "summary": "**Summary of GitHub Actions Pricing Changes (2026)**\n\nOn **March 1, 2026**, GitHub will begin charging for **self-hosted runner** usage in private repositories at a rate of **$0.002 per minute**. This new \"cloud platform charge\" will count toward the existing minute quotas included in user plans. Usage in public repositories remains free.\n\nThis change coincides with a separate price reduction for **GitHub-hosted runners**, effective **January 1, 2026**, with cuts of up to **39%** depending on machine type. Free usage minute allowances are unchanged.\n\nGitHub states the new fee will fund a **deeper investment in the self-hosted runner experience**, including enhanced autoscaling for scenarios beyond Linux containers, new scaling approaches, and expanded platform support (like Windows).\n\n**Key Exceptions:**\n*   No changes for **GitHub Enterprise Server** customers.\n*   No charges for runner usage in **public repositories**.\n\nGitHub has provided several resources for users, including an FAQ, updated pricing documentation, a pricing calculator, and a migration guide for moving from self-hosted to GitHub-hosted runners.",
    "chinese_title": "GitHub将于2026年3月开始对自托管运行器收费。",
    "chinese_summary": "**GitHub Actions 定价变更摘要（2026年）**\n\n自 **2026年3月1日** 起，GitHub 将对私有仓库中的 **自托管运行器** 使用按 **每分钟 0.002 美元** 收费。这项新的“云平台费用”将计入用户计划中已有的分钟配额。公共仓库中的使用仍保持免费。\n\n此项变更与 **GitHub 托管运行器** 的单独降价措施同步，后者将于 **2026年1月1日** 生效，根据机器类型不同，降幅最高可达 **39%**。免费使用分钟额度保持不变。\n\nGitHub 表示，新收费将用于 **加大对自托管运行器体验的投入**，包括增强对 Linux 容器以外场景的自动扩缩容、新的扩缩容方法以及扩展的平台支持（如 Windows）。\n\n**主要例外情况：**\n*   **GitHub Enterprise Server** 客户不受影响。\n*   **公共仓库** 中的运行器使用不收费。\n\nGitHub 已为用户提供了多项资源，包括常见问题解答、更新的定价文档、定价计算器以及从自托管运行器迁移到 GitHub 托管运行器的指南。"
  },
  {
    "id": "46288024",
    "title": "Sega Channel: VGHF Recovers over 100 Sega Channel ROMs (and More)",
    "url": "https://gamehistory.org/segachannel/",
    "summary": "The Video Game History Foundation (VGHF) has recovered and preserved over 100 previously lost ROMs from the Sega Channel, the 1990s cable-based game service. This major preservation effort, conducted in collaboration with former Sega Channel vice president Michael Shorrock and a community member, unearthed 144 unique system and game ROMs.\n\nThe haul includes nearly 100 system software versions, prototypes, and exclusive games like *Garfield: Caught in the Act – The Lost Levels* and *The Flintstones*, which were thought to be permanently lost. It also contains special \"limited edition\" variants of retail games that were cut down or split to fit the service's file size limits.\n\nAlongside the ROMs, VGHF has archived Shorrock's personal collection of internal documents, revealing details about the service's operations and an unannounced successor called Express Games. The recovered data has been donated to Gaming Alexandria for public access.\n\nThe project clarifies a long-standing mystery, confirming that the advertised exclusive *Ozone Kid* was never actually released due to development issues. This recovery is believed to account for almost all outstanding Sega Channel games, creating a near-complete digital record of every unique Sega Genesis game released in the United States.",
    "chinese_title": "世嘉频道：VGHF成功恢复超过100款世嘉频道ROM（及更多内容）",
    "chinese_summary": "电子游戏历史基金会（VGHF）成功复原并保存了超过100款曾被认为失传的世嘉频道ROM文件。世嘉频道是上世纪90年代基于有线电视网络的游戏服务。这项重要的保存工作由前世嘉频道副总裁迈克尔·肖洛克与一位社区成员合作完成，共发掘出144个独特的系统与游戏ROM。\n\n这批资料包含近100个系统软件版本、原型游戏以及《加菲猫：现场捉贼——失落的关卡》《摩登原始人》等独家游戏，这些作品此前被认为已永久失传。其中还收录了零售游戏的特别“限量版”变体，这些版本曾为适应服务文件大小限制而被删减或拆分。\n\n除ROM文件外，VGHF还归档了肖洛克个人收藏的内部文件，揭示了该服务的运营细节以及一个名为“快速游戏”的未公开后续项目。所有复原数据已捐赠给Gaming Alexandria平台向公众开放。\n\n该项目解开了长期存在的谜团，证实宣传中的独占游戏《臭氧小子》因开发问题从未实际发行。此次复原被认为涵盖了几乎所有未被发现的世嘉频道游戏，几乎完整构建了美国地区所有独特世嘉Genesis游戏的数字档案。"
  },
  {
    "id": "46291156",
    "title": "Pricing Changes for GitHub Actions",
    "url": "https://resources.github.com/actions/2026-pricing-changes-for-github-actions/",
    "summary": "GitHub is announcing significant pricing and product updates for GitHub Actions, driven by a backend re-architecture that has tripled daily job capacity.\n\nThe key changes are:\n1.  **Lower Prices for GitHub-Hosted Runners:** Effective January 1, 2026, prices will be reduced by up to 39%, making high-performance compute more accessible.\n2.  **New Platform Charge:** A $0.002 per-minute \"Actions cloud platform charge\" will be introduced for all workflows on private repositories using GitHub-hosted or self-hosted runners. This charge is already included in the new, lower GitHub-hosted runner rates. For self-hosted runners, it takes effect March 1, 2026.\n3.  **Free Usage Unchanged:** Usage on public repositories remains free, and GitHub Enterprise Server pricing is unaffected.\n4.  **Enhanced Self-Hosted Tools:** GitHub is deepening investment in the self-hosted runner experience, previewing a new Scale Set Client for custom autoscaling, multi-label support, an updated Actions Runner Controller, and an Actions Data Stream for better observability.\n\nGitHub states that 85% of impacted users will see their bill decrease, with a median increase of $13 for the 15% who see a cost rise. For individual developers on free/Pro plans, only 0.09% are expected to see a price increase, with a median under $2 per month.",
    "chinese_title": "GitHub Actions 定价变更",
    "chinese_summary": "GitHub宣布对GitHub Actions进行重大的定价和产品更新，这得益于后端架构重构，使每日任务处理能力提升至三倍。\n\n主要变更如下：\n1.  **GitHub托管运行器降价：** 自2026年1月1日起，价格最高降低39%，使高性能计算更易获取。\n2.  **新增平台费用：** 对使用GitHub托管或自托管运行器的私有仓库工作流，将引入每分钟0.002美元的\"Actions云平台费用\"。此费用已包含在新的、更低的GitHub托管运行器费率中。对于自托管运行器，该费用将于2026年3月1日生效。\n3.  **免费使用不变：** 公共仓库的使用仍免费，GitHub Enterprise Server定价不受影响。\n4.  **增强自托管工具：** GitHub正加大对自托管运行器体验的投入，预览新版Scale Set Client以支持自定义自动扩缩、多标签功能，更新Actions Runner Controller，并推出Actions Data Stream以提升可观测性。\n\nGitHub表示，85%受影响的用户账单将减少，而15%面临费用上涨的用户中位数增加额为13美元。对于使用免费/Pro计划的个人开发者，仅0.09%预计会面临价格上涨，每月中位数增加额低于2美元。"
  },
  {
    "id": "46291011",
    "title": "Artie (YC S23) Is Hiring Senior Enterprise AES",
    "url": "https://www.ycombinator.com/companies/artie/jobs/HyaHWUs-senior-enterprise-ae",
    "summary": "Artie (YC S23), a real-time data replication platform, is hiring its first Senior Enterprise Account Executives in San Francisco. This founding GTM role requires full-cycle ownership of 6-12 month sales cycles for deals with $100-300K+ ACV, targeting technical buyers in engineering and data teams.\n\nThe ideal candidate has 5+ years of enterprise AE experience selling technical products (like dev tools or data infrastructure) and can independently source 80%+ of their pipeline through outbound efforts. Deep technical fluency is essential, including the ability to discuss concepts like CDC, Kafka, and cloud architectures with engineers.\n\nThe role offers significant influence on company strategy, a compensation package of $300-350K OTE (with a $150-175K base salary), approximately 0.1% equity, and benefits including visa sponsorship. The position is fully in-person, five days a week.",
    "chinese_title": "Artie（YC S23）正在招聘高级企业AES工程师",
    "chinese_summary": "Artie（YC S23）是一家实时数据复制平台，现于旧金山招聘首批高级企业客户经理。作为创始市场推广团队成员，该职位需全周期负责6-12个月销售流程，订单年均合同价值10-30万美元以上，目标客户为工程与数据团队的技术决策者。\n\n理想候选人需拥有5年以上企业客户经理经验，曾销售技术产品（如开发工具或数据基础设施），并能通过自主开拓完成80%以上销售线索储备。必须具备深厚技术素养，包括能与工程师深入探讨变更数据捕获、Kafka及云架构等技术概念。\n\n该职位将深度参与公司战略制定，薪酬包为30-35万美元（含15-17.5万美元底薪），配套约0.1%股权及工作签证等福利。工作模式为每周五天全职现场办公。"
  },
  {
    "id": "46276002",
    "title": "Show HN: Sqlit – A lazygit-style TUI for SQL databases",
    "url": "https://github.com/Maxteabag/sqlit",
    "summary": "**Sqlit** is a lightweight, terminal-based TUI (text user interface) for SQL databases, designed for quick and easy database interaction without the overhead of heavy GUI applications. Inspired by `lazygit`, it emphasizes intuitive, keyboard-driven navigation with on-screen keybindings, requiring no CLI configuration to start.\n\nThe tool supports a wide range of databases—including PostgreSQL, MySQL, SQL Server, SQLite, MariaDB, Oracle, DuckDB, CockroachDB, Supabase, and Turso—without needing separate adapters. It features a built-in connection manager, SSH tunneling, Vim-style modal editing, query history, and SQL autocomplete. Users can run it interactively with `sqlit` or use CLI commands for scripting.\n\nKey differentiators from similar tools are its focus on simplicity and immediate usability: it installs required Python packages automatically, stores connections in `~/.sqlit/`, and aims to eliminate the need for external documentation. It is built with the Textual framework and is available via `pip install sqlit-tui`.",
    "chinese_title": "展示 HN：Sqlit – 类似 lazygit 风格的 SQL 数据库 TUI 界面",
    "chinese_summary": "**Sqlit** 是一款轻量级、基于终端的 SQL 数据库 TUI（文本用户界面），专为快速便捷的数据库交互而设计，无需臃肿的图形界面应用。受 `lazygit` 启发，它强调直观的键盘驱动导航，并配有屏幕键位提示，无需 CLI 配置即可启动。\n\n该工具支持多种数据库——包括 PostgreSQL、MySQL、SQL Server、SQLite、MariaDB、Oracle、DuckDB、CockroachDB、Supabase 和 Turso——无需单独的适配器。它内置连接管理器、SSH 隧道、Vim 风格的模式编辑、查询历史和 SQL 自动补全功能。用户可通过 `sqlit` 交互式运行，或使用 CLI 命令进行脚本操作。\n\n与同类工具相比，其主要区别在于注重简洁性和即用性：自动安装所需的 Python 包，将连接信息存储在 `~/.sqlit/` 目录中，旨在减少对外部文档的依赖。该工具基于 Textual 框架构建，可通过 `pip install sqlit-tui` 安装。"
  },
  {
    "id": "46288291",
    "title": "Rust GCC back end: Why and how",
    "url": "https://blog.guillaume-gomez.fr/articles/2025-12-15+Rust+GCC+backend%3A+Why+and+how",
    "summary": "This article explains the role and implementation of the Rust GCC backend. It begins by outlining the Rust compiler's multi-pass structure (AST, HIR, MIR, codegen), distinguishing the front-end (parsing, type-checking) from the back-end (binary code generation). The default backend is LLVM, but alternatives like GCC exist.\n\nThe primary motivation for a GCC backend is to support older processor architectures that LLVM does not, such as the Dreamcast. The article clarifies that this GCC backend (`rustc_codegen_gcc`) is a bridge from Rust's internal AST to GCC's code generation API (via `libgccjit`), distinct from the separate `gccrs` front-end project.\n\nThe implementation involves creating a backend crate that implements traits from `rustc_codegen_ssa` (like `CodegenBackend`). A concrete example shows how the backend declares a constant string: it caches the string, uses the GCC API to create a literal, and returns a pointer and length. The article also highlights how Rust-specific semantics, like non-null references, are communicated to GCC as attributes (e.g., `nonnull`), enabling crucial optimizations that simpler C equivalents cannot perform.\n\nIn summary, the GCC backend extends Rust's portability to legacy hardware while leveraging GCC's mature optimization pipeline, all by translating Rust's final intermediate representation into GCC's internal formats.",
    "chinese_title": "Rust GCC后端：缘由与实现方式",
    "chinese_summary": "本文阐述了Rust GCC后端的角色与实现方式。文章首先概述了Rust编译器的多阶段结构（AST、HIR、MIR、代码生成），区分了前端（解析、类型检查）与后端（二进制代码生成）。默认后端是LLVM，但也存在GCC等替代方案。\n\n开发GCC后端的主要动机是为了支持LLVM未涵盖的旧处理器架构，例如Dreamcast。文章澄清了这个GCC后端（`rustc_codegen_gcc`）是连接Rust内部AST与GCC代码生成API（通过`libgccjit`）的桥梁，与独立的`gccrs`前端项目有本质区别。\n\n实现过程涉及创建实现`rustc_codegen_ssa`特征（如`CodegenBackend`）的后端crate。具体示例展示了后端如何声明常量字符串：缓存字符串后，通过GCC API创建字面量，并返回指针和长度。文章还重点说明如何将Rust特有语义（如非空引用）通过属性（例如`nonnull`）传递给GCC，从而实现简单C语言等效代码无法完成的关键优化。\n\n总之，GCC后端通过将Rust的最终中间表示转换为GCC内部格式，既将Rust的可移植性扩展到传统硬件，又充分利用了GCC成熟的优化流程。"
  },
  {
    "id": "46275111",
    "title": "Nvidia Nemotron 3 Family of Models",
    "url": "https://research.nvidia.com/labs/nemotron/Nemotron-3/",
    "summary": "NVIDIA has announced the Nemotron 3 family, a new series of open models designed for agentic AI applications. The family includes three models: **Nano** (3.2B active parameters), **Super**, and **Ultra**, with Nano being released first.\n\nKey innovations in the architecture include a **hybrid Mamba-Transformer Mixture-of-Experts (MoE)** design for high throughput and accuracy, support for **up to 1 million tokens** of context, and **multi-token prediction** for efficient long-form generation. The models also feature **inference-time reasoning budget control** and were refined using multi-environment reinforcement learning.\n\nThe **Nemotron 3 Nano** model is highlighted for its efficiency, reportedly outperforming larger models like GPT-OSS-20B and Qwen3-30B on popular benchmarks while offering significantly higher inference throughput. It also excels in long-context evaluations.\n\nIn line with its open approach, NVIDIA is releasing the **Nemotron 3 Nano model weights** (in FP8 and BF16 formats), its **training recipe**, and extensive datasets. These include refreshed pre-training data (Nemotron-CC-v2.1, Nemotron-CC-Code-v1) and new synthetic datasets for specialized tasks, SFT, and RL training.",
    "chinese_title": "英伟达Nemotron 3系列模型",
    "chinese_summary": "英伟达宣布推出Nemotron 3系列，这是一组专为智能体AI应用设计的新型开源模型。该系列包含三款模型：**Nano**（32亿活跃参数）、**Super**和**Ultra**，其中Nano率先发布。\n\n架构的核心创新包括采用**混合Mamba-Transformer专家混合模型（MoE）**设计以实现高吞吐量与精度、支持**高达100万token的上下文长度**，以及通过**多token预测**实现高效长文本生成。这些模型还具备**推理时计算预算控制**功能，并采用多环境强化学习进行优化。\n\n**Nemotron 3 Nano**模型凭借其高效性备受关注，据报告在主流基准测试中超越了GPT-OSS-200亿参数和Qwen3-300亿参数等更大规模模型，同时提供显著更高的推理吞吐量，在长上下文评估中也表现优异。\n\n秉承开源理念，英伟达将公开**Nemotron 3 Nano模型权重**（FP8与BF16格式）、**完整训练方案**及丰富数据集，包括更新的预训练数据（Nemotron-CC-v2.1、Nemotron-CC-Code-v1）以及面向专项任务、SFT与RL训练的全新合成数据集。"
  },
  {
    "id": "46235750",
    "title": "Confuse some SSH bots and make botters block you",
    "url": "https://mirror.newsdump.org/confuse-some-ssh-bots.html",
    "summary": "This article appears to be a placeholder or a conceptual title rather than a completed piece of content. The title suggests a topic about using a blank or deceptive webpage to confuse automated SSH (Secure Shell) bots—likely those scanning for vulnerabilities—with the goal of getting the bot operators to block your server's IP address, thus reducing malicious traffic.\n\nHowever, the body of the article is explicitly stated as \"blank page.\" Therefore, there is no substantive content, analysis, or instructions to summarize. The core \"information\" is simply the ironic premise presented in the title: that a blank page could serve as a tool to waste the resources of bots and annoy their operators into blacklisting you.",
    "chinese_title": "迷惑一些SSH机器人，让机器人操作者屏蔽你",
    "chinese_summary": "这篇文章似乎是一个占位符或概念性标题，而非完整内容。标题暗示的主题是关于利用空白或欺骗性网页来迷惑自动化SSH（安全外壳协议）机器人——可能是那些扫描漏洞的机器人——目的是让机器人操作者封锁你的服务器IP地址，从而减少恶意流量。\n\n然而，文章正文明确标注为“空白页”。因此，没有实质性的内容、分析或说明可供总结。核心“信息”仅仅是标题中提出的讽刺性前提：空白页可以作为一种工具，浪费机器人的资源，并惹恼其操作者将你列入黑名单。"
  },
  {
    "id": "46256504",
    "title": "Purrtran – ᓚᘏᗢ – A Programming Language for Cat People",
    "url": "https://github.com/cmontella/purrtran",
    "summary": "PURRTRAN is a satirical programming language designed to mimic the experience of coding with a cat. It is based on a modernized FORTRAN syntax but is distinguished by its unique tooling, centered around an \"Artificial Catelligence\" (AC) assistant named Hexadecimal Purrington (Hex).\n\nHex is a terminal-based virtual cat that assists with coding by offering suggestions, writing code, and providing linting feedback in the form of cat-themed ASCII art. However, Hex requires constant care: users must feed, play with, and clean up after him via REPL commands to keep his \"needs\" meters high. If neglected, Hex becomes unhelpful or even \"dies.\"\n\nThe language includes quirky features like a \"Litterbox\" memory arena that must be manually managed, a \"Catgentic\" mode where Hex autonomously edits code, and a \"ZoomiesJIT\" compiler that activates under specific, cat-like conditions (e.g., after being fed or at 4:30 AM). The article humorously details Hex's limitations, including his laziness, unpredictable availability, tendency to invent features from other dimensions, and the fact that he must personally \"choose\" the programmer to help them.\n\nUltimately, PURRTRAN is a fictional, joke project celebrating cat behavior, not a serious tool for development.",
    "chinese_title": "Purrtran – ᓚᘏᗢ – 为猫奴设计的编程语言",
    "chinese_summary": "PURRTRAN是一种讽刺性编程语言，旨在模拟与猫一起编程的体验。它基于现代化的FORTRAN语法，但以其独特的工具链为特色，核心是一个名为Hexadecimal Purrington（简称Hex）的“人工猫智”（AC）助手。\n\nHex是一只基于终端的虚拟猫，通过提供建议、编写代码以及以猫主题ASCII艺术形式提供代码检查反馈来协助编程。然而，Hex需要持续照料：用户必须通过REPL命令喂食、玩耍和清理他的“需求”计量条以保持高位。如果疏于照顾，Hex会变得不配合，甚至“死亡”。\n\n该语言包含许多古怪功能，例如必须手动管理的“猫砂盆”内存区域、“猫主自张”模式（Hex自主编辑代码），以及“疯跑JIT”编译器（在特定猫式条件下激活，例如喂食后或凌晨4:30）。文章幽默地详述了Hex的局限性，包括他的懒惰、不可预测的可用性、倾向于从其他维度编造功能，以及他必须亲自“选择”程序员才愿意提供帮助。\n\n最终，PURRTRAN是一个虚构的玩笑项目，旨在调侃猫咪行为，并非用于开发的严肃工具。"
  },
  {
    "id": "46271405",
    "title": "AI URI Scheme – Internet-Draft",
    "url": "https://www.ietf.org/archive/id/draft-sogomonian-ai-uri-scheme-01.html",
    "summary": "This document proposes a new **`ai://` URI scheme** to provide a dedicated addressing system for AI resources like agents, models, and tasks. It is intended for direct use by autonomous systems and robots via a protocol called the **Artificial Intelligence Internet Protocol (AIIP)**.\n\nTo ensure compatibility with the existing web, the specification allows `ai://` URIs to be accessed through **HTTPS gateways**. Websites can advertise their AI endpoints using HTTP headers, HTML links, or well-known resources, enabling server-side resolution while users remain on conventional HTTPS websites. These gateways must handle authentication, preserve security, and maintain result integrity.\n\nThe proposal includes a governance model where the **Artificial Intelligence Internet Foundation (AIIF)** would administer the global namespace to ensure uniqueness and safe operation. Key considerations are highlighted for **security** (endpoint authentication, authorization), **privacy** (minimizing metadata exposure), and **internationalization** (following standard URI encoding rules).\n\nFinally, the document formally requests IANA to register the `ai` URI scheme with a **Provisional** status.",
    "chinese_title": "AI URI方案——互联网草案",
    "chinese_summary": "本文档提出一种新的**`ai://` URI方案**，旨在为智能体、模型和任务等AI资源建立专用寻址系统。该方案计划通过**人工智能互联网协议（AIIP）** 供自主系统和机器人直接使用。\n\n为保障与现有网络的兼容性，规范允许通过**HTTPS网关**访问`ai://` URI。网站可通过HTTP标头、HTML链接或知名资源声明其AI端点，在用户停留在传统HTTPS网站的同时实现服务端解析。此类网关需处理身份验证、保障安全性并维持结果完整性。\n\n提案包含由**人工智能互联网基金会（AIIF）** 管理的治理模型，该机构将负责维护全球命名空间以确保唯一性与安全运行。方案重点强调了**安全性**（端点认证与授权）、**隐私保护**（最小化元数据暴露）及**国际化**（遵循标准URI编码规则）等关键考量。\n\n最后，本文档正式请求IANA以**临时状态**注册`ai` URI方案。"
  },
  {
    "id": "46260852",
    "title": "Pizlix: Memory Safe Linux from Scratch",
    "url": "https://fil-c.org/pizlix",
    "summary": "**Pizlix** is a memory-safe Linux distribution based on **Linux From Scratch (LFS) 12.2**. Its key innovation is compiling the **entire userland** (all non-kernel software) with **Fil-C**, a memory-safe C/C++ compiler, making it one of the most memory-safe Linux-like operating systems available.\n\n**Key Details:**\n*   **Kernel & Compiler:** The Linux kernel is compiled with the standard, non-memory-safe **Yolo-C** compiler (GCC), retained in `/yolo/bin/gcc`. The main system compiler (`clang-20`) is also built with Yolo-C++ for practical reasons, but all other build tools (like `make`, `ld`) are memory-safe.\n*   **Build Process:** The installation is a multi-stage process that carefully injects Fil-C into the LFS build:\n    1.  **Pre-LC:** Bootstraps a temporary toolchain with Yolo-C, installed under `/yolo`.\n    2.  **LC (Core Injection):** Swaps the toolchain to Fil-C. This involves building a special \"yolo\" version of glibc for the runtime, binary-dropping the Fil-C compiler and its runtime library (`libpizlo.so`), and then building the final user glibc with Fil-C.\n    3.  **Post-LC:** Completes the LFS system build using the new Fil-C toolchain, followed by additional stages to add packages like OpenSSH, Weston (for a GUI), and GTK 4.\n*   **Usage:** The default system includes a running SSH daemon, network setup, and a Wayland/Weston-based graphical environment. It comes with a `root` user and a `pizlo` user with sudo privileges.\n*   **Compatibility:** Pizlix is possible because Fil-C is highly compatible with standard C/C++, requiring only minor changes to most LFS packages.\n\nIn summary, Pizlix is a proof-of-concept, memory-safe OS that modifies the LFS build process to replace the standard C toolchain with the Fil-C compiler for userland software, while keeping the kernel and the compiler itself as pragmatic exceptions.",
    "chinese_title": "Pizlix：从零开始构建内存安全的Linux系统",
    "chinese_summary": "**Pizlix** 是一款基于 **Linux From Scratch (LFS) 12.2** 的内存安全 Linux 发行版。其核心创新在于使用 **Fil-C**（一种内存安全的 C/C++ 编译器）编译**整个用户空间**（所有非内核软件），使其成为目前最内存安全的类 Linux 操作系统之一。\n\n**关键细节：**\n*   **内核与编译器：** Linux 内核使用标准的非内存安全编译器 **Yolo-C**（GCC）编译，保留在 `/yolo/bin/gcc` 中。出于实际考虑，主系统编译器（`clang-20`）也由 Yolo-C++ 构建，但所有其他构建工具（如 `make`、`ld`）均为内存安全。\n*   **构建过程：** 安装是一个多阶段过程，将 Fil-C 谨慎注入 LFS 构建：\n    1.  **预 LC 阶段：** 使用 Yolo-C 引导一个临时工具链，安装在 `/yolo` 下。\n    2.  **LC 阶段（核心注入）：** 将工具链切换为 Fil-C。这包括为运行时构建特殊的 \"yolo\" 版 glibc、二进制部署 Fil-C 编译器及其运行时库（`libpizlo.so`），然后使用 Fil-C 构建最终的用户 glibc。\n    3.  **后 LC 阶段：** 使用新的 Fil-C 工具链完成 LFS 系统构建，随后通过额外阶段添加 OpenSSH、Weston（用于 GUI）和 GTK 4 等软件包。\n*   **使用方式：** 默认系统包含运行的 SSH 守护进程、网络设置以及基于 Wayland/Weston 的图形环境。系统提供 `root` 用户和具有 sudo 权限的 `pizlo` 用户。\n*   **兼容性：** Pizlix 之所以可行，是因为 Fil-C 与标准 C/C++ 高度兼容，仅需对大多数 LFS 软件包进行微小修改。\n\n总之，Pizlix 是一个概念验证型内存安全操作系统，它修改了 LFS 构建流程，将用户空间软件的标准 C 工具链替换为 Fil-C 编译器，同时将内核和编译器本身作为务实的例外保留。"
  },
  {
    "id": "46276826",
    "title": "Full Unicode Search at 50× ICU Speed with AVX‑512",
    "url": "https://ashvardanian.com/posts/search-utf8/",
    "summary": "This article introduces StringZilla, a high-performance open-source library that accelerates common Unicode text operations—specifically tokenization, case-folding, and case-insensitive substring search—by leveraging AVX-512 SIMD instructions on modern CPUs. It achieves significant speedups (10–150× faster than ICU, and up to 20,000× faster than PCRE2 regex) while maintaining full Unicode 17 compliance, tested against synthetic and real-world data.\n\nThe core challenge is UTF-8's variable-length encoding and Unicode's complex case-folding rules, where characters like German \"ß\" expand to \"ss\" or ligatures like \"ﬃ\" become \"ffi.\" Instead of folding entire strings (which is slow and breaks offsets), StringZilla identifies a \"safe window\" in the needle—a substring that folds predictably into ≤16 bytes—and uses it as a SIMD filter. Hits are then verified with a slower, correct path.\n\nThe library categorizes scripts (e.g., ASCII, Cyrillic, Greek) into separate SIMD kernels with tailored \"alarm\" logic to detect problematic expansions. For platforms without SIMD or difficult cases, it falls back to serial algorithms. This approach balances raw speed with correctness, addressing a key gap where many fast text-processing tools sacrifice Unicode handling for performance.",
    "chinese_title": "全Unicode搜索以AVX‑512实现ICU速度的50倍提升",
    "chinese_summary": "本文介绍了StringZilla，这是一个高性能开源库，通过在现代CPU上利用AVX-512 SIMD指令，加速常见的Unicode文本操作——特别是分词、大小写折叠和不区分大小写的子串搜索。该库在保持完全符合Unicode 17标准的同时，实现了显著的加速（比ICU快10-150倍，比PCRE2正则表达式快高达20,000倍），并已通过合成数据和实际数据测试验证。\n\n核心挑战在于UTF-8的可变长编码和Unicode复杂的大小写折叠规则，例如德语\"ß\"会扩展为\"ss\"，连字\"ﬃ\"会变为\"ffi\"。StringZilla没有采用折叠整个字符串（速度慢且会破坏偏移量）的方法，而是在搜索串中识别一个\"安全窗口\"——即能可靠折叠为≤16字节的子串——并将其用作SIMD过滤器。匹配结果随后通过较慢但正确的路径进行验证。\n\n该库将不同文字体系（如ASCII、西里尔文、希腊文）分类到独立的SIMD内核中，并配备定制的\"警报\"逻辑以检测有问题的扩展。对于不支持SIMD的平台或复杂情况，它会回退到串行算法。这种方法在原始速度与正确性之间取得平衡，解决了当前许多快速文本处理工具为追求性能而牺牲Unicode处理能力的关键缺陷。"
  },
  {
    "id": "46281119",
    "title": "Liskell – Haskell Semantics with Lisp Syntax [pdf]",
    "url": "http://clemens.endorphin.org/ILC07-Liskell-draft.pdf",
    "summary": "**Liskell: Haskell Semantics with Lisp Syntax** is a research paper proposing a programming language that combines the strong, static typing and purely functional semantics of Haskell with the flexible, S-expression-based syntax of Lisp.\n\nThe core idea is to preserve Haskell's powerful type system, lazy evaluation, and advanced features (like type classes and monads) while adopting Lisp's uniform, parenthesized prefix syntax. This aims to offer the best of both worlds: the safety and expressiveness of Haskell with the syntactic simplicity and meta-programming advantages of Lisp.\n\nA major focus of the paper is **meta-programming**. Liskell's Lisp-like syntax makes its own abstract syntax tree (AST) directly manipulable as a standard data structure within the language. The paper describes built-in mechanisms—such as **Parse Tree Transformers (PTTs)** and **Environment Transformers**—that allow programmers to write macros and perform compile-time code generation and transformation easily, a task that is more complex in standard Haskell.\n\nThe language design includes specific syntactic forms for Haskell constructs (like pattern matching, bindings, and type signatures) within the S-expression framework. The paper also details components of a proposed standard library (the Prelude) that support this meta-programming system, including quasi-quotation and utilities for creating domain-specific embedded languages (DSELs).\n\nIn summary, Liskell is presented as a functional language that uses Lisp syntax not just for superficial readability, but to enable powerful and convenient compile-time meta-programming, extending the capabilities of Haskell in a principled way.",
    "chinese_title": "Liskell – 采用Lisp语法的Haskell语义 [pdf]",
    "chinese_summary": "**Liskell：采用Lisp语法的Haskell语义**是一篇研究论文，提出了一种编程语言，它将Haskell强大的静态类型系统和纯函数式语义与Lisp基于S表达式的灵活语法相结合。\n\n其核心思想是在保留Haskell强大的类型系统、惰性求值和高级特性（如类型类和单子）的同时，采用Lisp统一、括号化的前缀语法。这旨在融合两者的优势：既拥有Haskell的安全性与表达力，又具备Lisp的语法简洁性和元编程便利性。\n\n论文的一个主要焦点是**元编程**。Liskell类Lisp的语法使其自身的抽象语法树（AST）可直接作为语言内的标准数据结构进行操作。论文描述了内置机制——如**解析树转换器（PTT）**和**环境转换器**——允许程序员轻松编写宏，并执行编译时代码生成与转换，而这在标准Haskell中更为复杂。\n\n该语言设计在S表达式框架内为Haskell的构造（如模式匹配、绑定和类型签名）提供了特定的语法形式。论文还详细介绍了支持此元编程系统的拟议标准库（Prelude）组件，包括准引用和用于创建领域特定嵌入式语言（DSEL）的工具。\n\n总之，Liskell被呈现为一种函数式语言，它使用Lisp语法不仅是为了表面的可读性，更是为了实现强大而便捷的编译时元编程，从而以系统化的方式扩展Haskell的能力。"
  },
  {
    "id": "46290113",
    "title": "AIsbom – open-source CLI to detect \"Pickle Bombs\" in PyTorch models",
    "url": "https://github.com/Lab700xOrg/aisbom",
    "summary": "**AIsbom** is an open-source CLI tool designed to secure AI supply chains by scanning machine learning model files for hidden security and legal risks. Unlike generic SBOM tools, it performs deep binary introspection on formats like PyTorch (.pt) and Safetensors to detect threats without loading the full weights into memory.\n\nIts core functions are:\n1.  **Security Scanning**: It disassembles PyTorch's Pickle bytecode to detect \"Pickle bombs\"—malicious code that can execute arbitrary commands (RCE) upon loading.\n2.  **License Compliance**: It extracts metadata from files like .safetensors to flag restrictive licenses (e.g., CC-BY-NC) that could violate commercial use.\n\nKey features include fast, header-only scanning of large files, generation of standard CycloneDX SBOM reports, and a client-side web viewer for visualizing risks. To build trust, the tool includes a command to generate safe test artifacts for verification.\n\nAIsbom is easily installed via PyPI (`pip install aisbom-cli`) and can be integrated into CI/CD pipelines (e.g., GitHub Actions) to automatically block risky models before deployment.",
    "chinese_title": "AIsbom – 开源命令行工具，用于检测PyTorch模型中的“Pickle炸弹”",
    "chinese_summary": "**AIsbom** 是一款开源命令行工具，专为保障人工智能供应链安全而设计，通过扫描机器学习模型文件来检测潜在的安全与法律风险。与通用型SBOM工具不同，它能够对PyTorch（.pt）和Safetensors等格式进行深度二进制解析，无需将完整权重加载到内存即可识别威胁。\n\n其核心功能包括：\n1.  **安全扫描**：通过反汇编PyTorch的Pickle字节码，检测“Pickle炸弹”——即加载时可能执行任意命令（远程代码执行）的恶意代码。\n2.  **许可证合规检查**：从.safetensors等文件中提取元数据，标记可能违反商业使用限制的许可证（如CC-BY-NC）。\n\n主要特性涵盖：针对大文件的快速仅头部扫描、生成标准CycloneDX SBOM报告，以及用于可视化风险分析的客户端网页查看器。为建立信任，该工具还提供生成安全测试样本的命令，以便进行验证。\n\nAIsbom可通过PyPI快速安装（`pip install aisbom-cli`），并能集成到CI/CD流水线（如GitHub Actions）中，在部署前自动拦截高风险模型。"
  },
  {
    "id": "46291500",
    "title": "The GitHub Actions control plane is no longer free",
    "url": "https://www.blacksmith.sh/blog/actions-pricing",
    "summary": "GitHub is introducing a $0.002 per-minute platform fee for all GitHub Actions usage, effective March 1, 2026. This ends the era of a free control plane for users who self-host or use third-party runners.\n\nPreviously, companies could avoid paying GitHub by moving workloads off its hosted runners. The new fee means GitHub now monetizes the orchestration and scheduling service itself, creating a baseline revenue stream regardless of where jobs execute. Concurrently, GitHub has lowered the price of its own hosted runners, making them more competitive.\n\nThe article argues this is a strategic shift for GitHub: it trades lower-margin compute revenue from hosted runners for higher-margin platform revenue that scales with usage without proportional infrastructure costs. For users, self-hosting now incurs both operational overhead and this new unavoidable GitHub fee.\n\nA key consequence is that reducing total CI minutes becomes crucial for cost control. The author's company, Blacksmith, positions its service as a solution by focusing on performance—using faster hardware and implementing caching strategies—to minimize job runtimes and, therefore, the new platform fees.",
    "chinese_title": "GitHub Actions控制平面不再免费",
    "chinese_summary": "GitHub将于2026年3月1日起对所有GitHub Actions使用量收取每分钟0.002美元的平台费用，这标志着自托管或使用第三方运行器的用户免费控制平面时代的终结。\n\n此前，企业可通过将工作负载移出GitHub托管运行器来避免付费。新费用意味着GitHub开始对其编排与调度服务本身进行货币化，无论任务在何处执行，都能形成稳定的基础收入流。与此同时，GitHub降低了其托管运行器的价格，使其更具竞争力。\n\n文章指出这是GitHub的战略转型：用托管运行器低利润的计算收入，换取随使用量增长而无需等比增加基础设施成本的高利润平台收入。对用户而言，自托管如今既需承担运维成本，又无法避免这项新的GitHub费用。\n\n关键影响在于控制CI总时长对成本管理变得至关重要。作者所在公司Blacksmith将其服务定位为解决方案——通过采用更快的硬件和实施缓存策略来提升性能，从而缩短任务运行时间，最终降低新平台费用。"
  },
  {
    "id": "46288414",
    "title": "A brief history of Times New Roman",
    "url": "https://typographyforlawyers.com/a-brief-history-of-times-new-roman.html",
    "summary": "Times New Roman was created in 1929 for *The Times* of London newspaper by typographer Stanley Morison, who supervised artist Victor Lardent. Designed to be space-efficient for newsprint, it is narrower than typical text fonts.\n\nIts popularity grew rapidly due to its newspaper use and its inclusion as a default font on nearly every new typesetting device, including personal computers. While objectively functional—a \"workhorse\" font—its italic style is considered mediocre, and its bold is notably narrow.\n\nThe article argues that the font's longevity stems more from its ubiquity than its quality, contrasting it with beloved fonts like Helvetica. It has accrued a reputation as the \"font of least resistance,\" connoting apathy rather than intentional design choice. This perception is especially strong in the legal profession, where it is mistakenly assumed to be a court requirement; no court mandates it, and at least one forbids it.\n\nThe author's conclusion is a direct plea: if you have a choice, stop using Times New Roman. Many better professional alternatives exist, and its continued use often reflects mere habit rather than necessity or merit.",
    "chinese_title": "Times New Roman简史",
    "chinese_summary": "Times New Roman字体由印刷专家斯坦利·莫里森于1929年为伦敦《泰晤士报》设计，并由其指导艺术家维克多·拉登特完成。该字体专为节省新闻纸版面设计，比常规文本字体更为窄瘦。\n\n因其在报纸上的广泛应用，并成为几乎所有新型排版设备（包括个人电脑）的默认字体，其普及度迅速提升。虽然客观而言它是一款功能性强的“实用型”字体，但其斜体样式被认为平庸，粗体则明显偏窄。\n\n文章指出，该字体的经久不衰更多源于其普遍性而非卓越品质，并与Helvetica等备受喜爱的字体形成对比。它被冠以“最小阻力字体”之名，暗含随意将就而非刻意设计之意。这种认知在法律界尤为强烈——许多人误以为法院要求使用该字体；实际上并无法庭作此规定，至少有一家法院明确禁止使用。\n\n作者最终直陈呼吁：若你有选择余地，请停止使用Times New Roman。如今存在许多更优质的专业替代字体，继续使用它往往只是出于习惯，而非必要或因其优点。"
  },
  {
    "id": "46284658",
    "title": "SHARP, an approach to photorealistic view synthesis from a single image",
    "url": "https://apple.github.io/ml-sharp/",
    "summary": "**Summary of SHARP**\n\nSHARP is a new method for generating photorealistic 3D scene representations from just a single input photograph. Its core innovation is using a neural network to predict, in a single feedforward pass (under one second on a standard GPU), the parameters for a **3D Gaussian Splatting** representation of the scene.\n\nThis learned 3D representation is **metric** (preserving real-world scale) and can be rendered in **real time** at over 100 frames per second, producing high-resolution novel views with sharp details. This represents a synthesis speed improvement of **three orders of magnitude** compared to prior state-of-the-art models.\n\nIn benchmarks, SHARP demonstrates strong **zero-shot generalization** across diverse datasets. It significantly outperforms previous best models, reducing perceptual error metrics (LPIPS by 25–34% and DISTS by 21–43%) while being vastly faster.\n\n**Key Points:**\n*   **Input:** A single RGB image.\n*   **Output:** A metric 3D Gaussian Splatting scene representation.\n*   **Speed:** <1 second to generate, >100 FPS to render.\n*   **Performance:** Sets new state-of-the-art in quality and speed for monocular view synthesis.",
    "chinese_title": "SHARP：一种基于单张图像实现照片级真实感视图合成的方法",
    "chinese_summary": "**SHARP 方法概述**\n\nSHARP 是一种仅需单张输入照片即可生成逼真三维场景表示的新方法。其核心创新在于利用神经网络，通过单次前向传播（在标准 GPU 上耗时不到一秒），预测出用于构建场景**三维高斯溅射**表示的参数。\n\n这种学习得到的三维表示具有**度量性**（保持真实世界尺度），并能以超过每秒 100 帧的**实时**速度进行渲染，生成细节清晰的高分辨率新视角图像。与先前的最先进模型相比，其合成速度提升了**三个数量级**。\n\n在基准测试中，SHARP 在多种数据集上展现出强大的**零样本泛化**能力。它显著超越了之前的最佳模型，在极大提升速度的同时，显著降低了感知误差指标（LPIPS 降低 25–34%，DISTS 降低 21–43%）。\n\n**核心要点：**\n*   **输入：** 单张 RGB 图像。\n*   **输出：** 具有度量尺度的三维高斯溅射场景表示。\n*   **速度：** 生成时间 <1 秒，渲染速度 >100 FPS。\n*   **性能：** 在单目视图合成的质量和速度上均确立了新的最先进水平。"
  },
  {
    "id": "46279616",
    "title": "Context: Odin’s Most Misunderstood Feature",
    "url": "https://www.gingerbill.org/article/2025/12/15/odins-most-misunderstood-feature-context/",
    "summary": "The Odin language's implicit `context` system is primarily designed to intercept and modify the behavior of third-party or unmodifiable code, such as libraries. It is not intended for minimizing parameter passing or as a form of dynamic scoping. The `context` is an implicit value in each scope, passed by pointer to procedures, and contains fields like allocators, a logger, an assertion handler, and a random number generator.\n\nThis design allows users to override default behaviors—like memory allocation or logging—without altering the original source code, addressing a common limitation in languages like C where such interception is often impossible. The system is especially useful for working around poorly designed APIs that lack proper callback mechanisms or configuration options.\n\nKey features include a fixed ABI layout for stability across library boundaries, copy-on-write semantics to prevent unwanted back-propagation of changes, and default implementations for core utilities. The author emphasizes that while explicit parameter passing is sometimes preferable, the `context` provides a necessary, generic solution for intercepting third-party code, which is a unique and critical problem in software engineering.",
    "chinese_title": "背景：奥丁最被误解的功能",
    "chinese_summary": "Odin语言的隐式`context`系统主要设计用于拦截和修改第三方或不可修改代码（如库）的行为，而非用于减少参数传递或作为动态作用域的实现方式。`context`是每个作用域中的隐式值，通过指针传递给过程，包含分配器、日志器、断言处理器和随机数生成器等字段。\n\n该设计允许用户在不修改原始源代码的情况下覆盖默认行为（如内存分配或日志记录），解决了C等语言中通常无法实现此类拦截的常见限制。该系统尤其适用于处理缺乏适当回调机制或配置选项的设计不良API。\n\n关键特性包括：为跨库稳定性而设计的固定ABI布局、防止意外反向传播更改的写时复制语义，以及核心工具的默认实现。作者强调，虽然显式参数传递有时更可取，但`context`为拦截第三方代码提供了必要且通用的解决方案，这是软件工程中独特而关键的问题。"
  },
  {
    "id": "46242838",
    "title": "Debug Mode for LLMs in vLLora",
    "url": "https://vllora.dev/blog/debug-mode/",
    "summary": "**Summary:**\n\nvLLora has introduced a Debug Mode for LLM requests to address the lack of visibility and control in complex AI workflows like agents, RAG pipelines, and multi-step tasks. This feature acts like a breakpoint, pausing requests before they are sent to the model.\n\nWhen paused, developers can inspect the exact, full request payload—including messages, parameters, tool definitions, and any injected metadata. Crucially, they can also edit any part of this payload (e.g., prompt content, model parameters) in real time. These changes are temporary and only affect the current request, allowing for rapid testing and validation without altering the underlying application code.\n\nAfter editing, clicking \"Continue\" sends the modified request to the model, receives the response, and seamlessly resumes the workflow. This is particularly valuable for debugging long-running agents, where it helps identify and fix issues like silent tool-call failures, context corruption, or state drift early on, without needing to re-run entire workflows.\n\nIn essence, Debug Mode brings a familiar software engineering \"inspect-edit-continue\" workflow to LLM development, significantly improving observability and speeding up debugging.",
    "chinese_title": "vLLora中的LLM调试模式",
    "chinese_summary": "**摘要：**\n\nvLLora 为LLM请求引入了调试模式，旨在解决复杂AI工作流（如智能体、RAG流水线和多步骤任务）中缺乏可见性和控制的问题。该功能类似于断点机制，可在请求发送至模型前将其暂停。\n\n暂停期间，开发者能够检查完整且精确的请求载荷——包括消息、参数、工具定义及任何注入的元数据。更重要的是，他们还能实时编辑该载荷的任何部分（例如提示内容、模型参数）。这些修改是临时的，仅影响当前请求，从而无需更改底层应用代码即可实现快速测试与验证。\n\n编辑完成后，点击“继续”即可将修改后的请求发送至模型，接收响应并无缝恢复工作流。这对于调试长时间运行的智能体尤为宝贵，能帮助及早识别和修复诸如静默工具调用失败、上下文损坏或状态漂移等问题，而无需重新运行整个工作流。\n\n本质上，调试模式为LLM开发引入了软件工程中熟悉的“检查-编辑-继续”工作流，显著提升了可观测性并加速了调试过程。"
  },
  {
    "id": "46259671",
    "title": "Show HN: Interactive Common Lisp: An Enhanced REPL",
    "url": "https://github.com/atgreen/icl",
    "summary": "ICL (Interactive Common Lisp) is an enhanced, terminal-based REPL for Common Lisp designed to improve the development experience. It offers modern features like syntax highlighting, parenthesis matching, and Paredit mode for structural editing. It supports multi-line input, persistent history, and tab completion.\n\nA key feature is its extensible command system, prefixed with a comma, which provides tools for navigation, documentation lookup, object inspection, macro expansion, debugging, and profiling. It also includes AI integration for explaining code and errors. ICL works with multiple Lisp implementations (SBCL, CCL, ECL, etc.) by acting as a frontend that communicates with a backend Lisp process via the Slynk protocol.\n\nInstallation is available via pre-built binaries for Linux and Windows or from source. It is highly configurable through a `~/.iclrc` file and supports various keyboard shortcuts for efficient editing and navigation.",
    "chinese_title": "展示HN：交互式Common Lisp：增强版REPL",
    "chinese_summary": "ICL（交互式Common Lisp）是一款增强型、基于终端的Common Lisp REPL，旨在提升开发体验。它提供现代功能，如语法高亮、括号匹配以及用于结构化编辑的Paredit模式，并支持多行输入、持久历史记录和Tab补全。\n\n其核心特性是可扩展的逗号前缀命令系统，提供导航、文档查询、对象检查、宏展开、调试和性能分析等工具。它还集成了AI功能，用于解释代码和错误信息。ICL通过Slynk协议作为前端与后端Lisp进程通信，支持多种Lisp实现（如SBCL、CCL、ECL等）。\n\n可通过预构建的Linux/Windows二进制文件或源码安装。它高度可配置，支持通过`~/.iclrc`文件进行设置，并提供多种键盘快捷键以实现高效编辑与导航。"
  },
  {
    "id": "46292365",
    "title": "Vibe coding creates fatigue?",
    "url": "https://www.tabulamag.com/p/too-fast-to-think-the-hidden-fatigue",
    "summary": "**Summary of \"Too Fast to Think: The Hidden Fatigue\"**\n\nThe article examines \"vibe coding\" or \"flow state coding,\" where developers enter a hyper-focused, immersive zone to program rapidly. While this state boosts short-term productivity, it argues that the practice leads to a significant and often overlooked form of mental fatigue.\n\nThe core issue is that this intense focus comes at the expense of higher-order cognitive functions like critical thinking, long-term planning, and considering architectural implications. Developers become excellent at executing tasks but poor at evaluating whether they are building the right thing or creating sustainable code. This results in \"hidden fatigue\"—a mental exhaustion that isn't immediately felt as sleepiness but manifests as burnout, decreased creativity, and an accumulation of technical debt from short-sighted decisions.\n\nThe piece contrasts this with the slower, more deliberate thinking required for complex problem-solving and design. It suggests that the tech industry's culture, which often glorifies marathon coding sessions and rapid output, inadvertently discourages the necessary downtime for reflection and recovery.\n\nUltimately, the article advocates for a more balanced approach. It recommends intentionally scheduling time for deep, uninterrupted work (like vibe coding) but equally protecting time for slower thinking, collaboration, and rest to mitigate fatigue and ensure higher-quality, more sustainable software development.",
    "chinese_title": "氛围编程会导致疲劳吗？",
    "chinese_summary": "**《“快思”之弊：被忽视的隐性疲劳》摘要**\n\n本文探讨了“氛围编程”或“心流编程”，即开发者进入一种高度专注、沉浸的状态以快速编写代码。文章指出，这种状态虽能提升短期效率，却会导致一种重要却常被忽视的精神疲劳。\n\n核心问题在于，这种高强度专注是以牺牲高阶认知功能为代价的，例如批判性思维、长远规划及架构考量。开发者变得擅长执行任务，却不善于评估所构建的是否正确，或代码是否具有可持续性。这导致了“隐性疲劳”——一种不会立即表现为困倦，却以倦怠感、创造力下降以及因短视决策累积的技术债务等形式显现的精神耗竭。\n\n文章将此与解决复杂问题和设计所需的、更缓慢审慎的思考方式进行了对比。它指出，科技行业文化常推崇马拉松式的编程和快速产出，这无意中阻碍了必要的反思与恢复时间。\n\n最终，文章倡导一种更平衡的方式。建议有意安排时间进行深度、无干扰的工作（如氛围编程），同时同样保护用于慢思考、协作和休息的时间，以缓解疲劳，确保更高质量、更具可持续性的软件开发。"
  },
  {
    "id": "46289073",
    "title": "Show HN: Solving the ~95% legislative coverage gap using LLM's",
    "url": "https://lustra.news/",
    "summary": "**Lustra is a new platform that uses large language models (LLMs) to analyze and summarize complex U.S. federal legislation, aiming to close a significant \"legislative coverage gap.\"**\n\nThe core problem it addresses is that traditional news media only has the resources to cover about 5% of the thousands of bills introduced in Congress each year. This leaves citizens uninformed about the vast majority of proposed laws that could impact them.\n\nLustra's AI-powered system automatically processes every new bill, generating:\n*   A plain-English summary of what the bill does.\n*   An analysis of its potential pros and cons.\n*   A breakdown of its key provisions.\n\nThe platform is designed to be non-partisan and transparent. It clearly cites the original bill text as its source and presents factual analysis without political spin. The goal is to empower citizens with direct, understandable access to legislative information, moving beyond reliance on filtered media reports or political messaging.\n\nBy making the full scope of legislative activity more accessible, Lustra seeks to foster a better-informed public and strengthen democratic engagement.",
    "chinese_title": "展示 HN：利用大语言模型解决约95%的立法覆盖缺口",
    "chinese_summary": "**Lustra是一个新平台，它利用大型语言模型（LLM）来分析和总结复杂的美国联邦立法，旨在弥合一个显著的“立法报道缺口”。**\n\n其解决的核心问题是：传统新闻媒体每年仅能投入资源报道国会提出的数千项法案中的约5%。这使得公民对可能影响他们的大多数拟议法律一无所知。\n\nLustra的AI驱动系统自动处理每一项新法案，生成：\n*   法案内容的简明英语摘要。\n*   对其潜在利弊的分析。\n*   其关键条款的细分说明。\n\n该平台被设计为无党派且透明。它明确引用原始法案文本作为来源，并提供不带政治倾向的事实分析。其目标是让公民能够直接、易懂地获取立法信息，超越对过滤后的媒体报道或政治宣传的依赖。\n\n通过使立法活动的全貌更易于获取，Lustra力求培养一个信息更灵通的公众，并加强民主参与。"
  }
]