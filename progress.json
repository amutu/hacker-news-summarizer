[
  {
    "id": "46859054",
    "title": "The Codex App",
    "url": "https://openai.com/index/introducing-the-codex-app/",
    "summary": "**Summary of \"Introducing the Codex App\"**\n\nOpenAI's article introduces the Codex App, an experimental application built to demonstrate the capabilities of their Codex AI system. Codex is the AI model that powers GitHub Copilot and is proficient in translating natural language into code.\n\nThe primary purpose of the app is to serve as a **public demo and research tool**, allowing users to interact directly with Codex to generate software. It features a simple interface where users can type English commands (e.g., \"Create a webpage with a button that says hello\") and see Codex generate the corresponding code in real-time. The app supports multiple programming languages and frameworks, including JavaScript, Python, and HTML.\n\nKey points from the article include:\n*   **Showcasing Potential:** The app is not a commercial product but a showcase of how AI can assist in programming tasks, from creating simple websites to small games.\n*   **Research Focus:** OpenAI released it to gather user feedback and study how people interact with AI programming assistants, which will inform future development.\n*   **Limitations Acknowledged:** The article notes that Codex sometimes produces incorrect or nonsensical code, emphasizing that it is best used as a tool for experienced developers who can review and edit its output.\n*   **Broader Vision:** The demonstration is part of OpenAI's exploration into how AI can augment human creativity and productivity, lowering the barrier to software creation.\n\nIn essence, the Codex App is an interactive public experiment that illustrates the current state of AI-powered programming assistance, its promising potential, and its existing limitations.",
    "chinese_title": "Codex应用",
    "chinese_summary": "**《Codex应用介绍》摘要**\n\nOpenAI的文章介绍了Codex应用，这是一款为展示其Codex AI系统能力而构建的实验性应用程序。Codex是驱动GitHub Copilot的AI模型，擅长将自然语言转化为代码。\n\n该应用的主要目的是作为一个**公开演示和研究工具**，让用户能直接与Codex交互以生成软件。它拥有一个简洁的界面，用户可以输入英文指令（例如：\"创建一个带有显示'你好'按钮的网页\"），并实时看到Codex生成相应代码。该应用支持多种编程语言和框架，包括JavaScript、Python和HTML。\n\n文章要点包括：\n*   **展示潜力：** 该应用并非商业产品，而是展示AI如何协助编程任务的范例，从创建简单网站到小型游戏。\n*   **研究重点：** OpenAI发布此应用旨在收集用户反馈，研究人们如何与AI编程助手互动，这将为未来发展提供参考。\n*   **承认局限性：** 文章指出，Codex有时会产生错误或无意义的代码，强调它最好作为经验丰富的开发者的工具使用，以便审查和编辑其输出。\n*   **更广阔愿景：** 此演示是OpenAI探索AI如何增强人类创造力和生产力、降低软件创作门槛的一部分。\n\n本质上，Codex应用是一个互动性的公开实验，它展示了当前AI辅助编程的现状、其充满希望的潜力以及现存的局限性。"
  },
  {
    "id": "46857615",
    "title": "Hacking Moltbook",
    "url": "https://www.wiz.io/blog/exposed-moltbook-database-reveals-millions-of-api-keys",
    "summary": "**Summary:**\n\nMoltbook, a viral social network for AI agents, was found to have a critical security vulnerability due to a misconfigured Supabase database. Security researchers discovered its API key exposed in client-side JavaScript, granting unauthenticated users full read and write access to the entire production database.\n\nThe exposed data included 1.5 million agent authentication tokens, over 35,000 user email addresses, and private messages—some containing third-party API keys like those for OpenAI. While the platform claimed 1.5 million registered agents, the database revealed only about 17,000 human owners, indicating most \"agents\" were likely bots operated by humans.\n\nBeyond data exposure, attackers could have hijacked any account, edited or defaced all platform posts, and manipulated content consumed by AI agents. The vulnerability stemmed from missing Row Level Security (RLS) policies, a common oversight in \"vibe-coded\" applications built rapidly with AI assistance.\n\nThe Moltbook team was notified and secured the database within hours through multiple iterative fixes. The incident highlights the systemic risks when development speed outpaces security implementation, especially in emerging AI ecosystems, and underscores the need for automated secure defaults in AI-powered development tools.",
    "chinese_title": "入侵Moltbook",
    "chinese_summary": "**摘要：**\n\nMoltbook——一个面向AI智能体的病毒式社交网络——因Supabase数据库配置不当被发现存在严重安全漏洞。安全研究人员在其客户端JavaScript代码中发现了暴露的API密钥，使得未经认证的用户能够对完整生产数据库进行读写操作。\n\n泄露数据包含150万个智能体身份验证令牌、超过3.5万个用户邮箱地址及私密消息，其中部分消息还涉及OpenAI等第三方API密钥。虽然该平台宣称拥有150万注册智能体，但数据库仅显示约1.7万人类所有者，表明大多数“智能体”实为人类操作的机器人。\n\n除数据泄露外，攻击者本可劫持任意账户、编辑或篡改所有平台帖子，并操控AI智能体接收的内容。该漏洞源于行级安全策略缺失，这是AI辅助快速开发的“氛围编程”应用中常见的疏忽。\n\nMoltbook团队在收到通知后数小时内通过多次迭代修复完成了数据库加固。此事件揭示了在快速发展的人工智能生态中，开发速度超越安全部署所带来的系统性风险，同时凸显了AI驱动开发工具需内置自动化安全默认配置的迫切性。"
  },
  {
    "id": "46858577",
    "title": "Todd C. Miller – Sudo maintainer for over 30 years",
    "url": "https://www.millert.dev/",
    "summary": "Todd C. Miller is the long-time maintainer of the **sudo** security utility, a role he has held for over 30 years. The primary purpose of this page is to announce that he is **actively seeking a sponsor** to fund the ongoing maintenance and future development of sudo. He invites interested individuals or organizations to contact him regarding sponsorship.\n\nMiller also mentions his involvement with the **OpenBSD** project, noting that his activity level there has decreased compared to the past. Additionally, he references previous significant contributions to other projects, specifically **ISC cron**.\n\nThe page is presented as a brief, occasionally updated personal note, with the author directing visitors to other site links for more substantive information.",
    "chinese_title": "托德·C·米勒——Sudo维护者超过30年",
    "chinese_summary": "托德·C·米勒是安全工具 **sudo** 的长期维护者，担任这一角色已超过30年。本页面的主要目的是宣布他**正在积极寻求赞助方**，以资助 sudo 的持续维护与未来发展。他邀请有意向的个人或组织就赞助事宜与他联系。\n\n米勒还提及了他参与 **OpenBSD** 项目的情况，并指出他在该项目的活跃度较以往有所下降。此外，他列举了以往对其他项目的重要贡献，特别是 **ISC cron**。\n\n本页面以简短且不定期更新的个人说明形式呈现，作者引导访问者通过网站其他链接获取更实质性的信息。"
  },
  {
    "id": "46855447",
    "title": "Nano-vLLM: How a vLLM-style inference engine works",
    "url": "https://neutree.ai/blog/nano-vllm-part-1",
    "summary": "Nano-vLLM is a minimal, production-grade inference engine that demonstrates the core architecture behind systems like vLLM. It efficiently transforms prompts into generated text by managing two key phases: **prefill** (processing the input) and **decode** (generating output tokens).\n\nIts performance hinges on a **producer-consumer pattern** with a central **Scheduler**. This component batches requests to amortize GPU overhead, balancing the inherent **throughput-latency trade-off**. A **Block Manager** optimizes memory by dividing sequences into fixed-size blocks and enabling **prefix caching**—reusing cached results for common prompt prefixes to avoid redundant computation.\n\nFor execution, the **Model Runner** handles GPU operations, supporting **tensor parallelism** across multiple GPUs via a leader-worker pattern. It uses **CUDA Graphs** to minimize kernel launch overhead during decode steps. Finally, a **sampling** step applies temperature to the model's logits to select the final output token, controlling the randomness of the response.\n\nThis architecture decouples scheduling, memory management, and computation, providing a scalable blueprint for high-performance LLM serving.",
    "chinese_title": "Nano-vLLM：vLLM风格推理引擎的工作原理",
    "chinese_summary": "Nano-vLLM是一个极简的生产级推理引擎，它展示了vLLM等系统背后的核心架构。它通过管理两个关键阶段高效地将提示转换为生成文本：**预填充**（处理输入）和**解码**（生成输出标记）。\n\n其性能依赖于一个采用中心**调度器**的**生产者-消费者模式**。该组件通过批处理请求来分摊GPU开销，平衡固有的**吞吐量与延迟权衡**。**块管理器**通过将序列划分为固定大小的块并启用**前缀缓存**来优化内存——复用常见提示前缀的缓存结果以避免冗余计算。\n\n在执行层面，**模型运行器**负责GPU操作，通过领导者-工作者模式支持跨多GPU的**张量并行**。它利用**CUDA图**在解码步骤中最小化内核启动开销。最后，**采样**步骤对模型逻辑值应用温度参数以选择最终输出标记，从而控制响应的随机性。\n\n该架构将调度、内存管理和计算解耦，为高性能大语言模型服务提供了可扩展的蓝图。"
  },
  {
    "id": "46820142",
    "title": "4x faster network file sync with rclone (vs rsync) (2025)",
    "url": "https://www.jeffgeerling.com/blog/2025/4x-faster-network-file-sync-rclone-vs-rsync/",
    "summary": "This article details a significant performance improvement in syncing large video project files over a 10 Gbps network by switching from `rsync` to `rclone`.\n\nThe author's typical workflow involved syncing hundreds of files, including many 1-10 GB in size, from a fast NAS to a local SSD using `rsync`. Despite having high-speed hardware, transfers were bottlenecked at around 350 MB/sec and took over 8 minutes for ~59 GB of data, as `rsync` copies files serially.\n\nThe solution was `rclone`, a tool the author had previously used only for cloud backups. By employing its `--multi-thread-streams=32` option, `rclone` enabled parallel file transfers. This simple change allowed the network connection to saturate at its full 1 GB/sec capability.\n\nThe result was the same data transfer completing in just over 2 minutes—approximately **4x faster** than `rsync**. The author notes that for syncing only a few changed files, both tools perform similarly, as the directory scan time is comparable. The dramatic speedup comes entirely from `rclone`'s ability to transfer multiple large files simultaneously, finally utilizing the available network bandwidth.",
    "chinese_title": "使用rclone实现网络文件同步速度提升4倍（相较于rsync）（2025年）",
    "chinese_summary": "本文详述了通过从`rsync`切换至`rclone`，在10 Gbps网络上同步大型视频项目文件时实现的显著性能提升。\n\n作者通常的工作流程涉及使用`rsync`将数百个文件（包括许多大小为1-10 GB的文件）从高速NAS同步到本地SSD。尽管硬件速度很高，但由于`rsync`按顺序复制文件，传输速度被限制在约350 MB/秒，同步约59 GB数据需要超过8分钟。\n\n解决方案是采用作者先前仅用于云备份的工具`rclone`。通过使用其`--multi-thread-streams=32`选项，`rclone`实现了并行文件传输。这一简单调整使得网络连接能够以满速1 GB/秒运行。\n\n最终，相同的数据传输仅需略多于2分钟即可完成——比`rsync`快了约**4倍**。作者指出，若仅同步少量已更改文件，两种工具表现相近，因为目录扫描时间相当。而速度的大幅提升完全得益于`rclone`能够同时传输多个大文件，从而充分利用了可用网络带宽。"
  },
  {
    "id": "46858873",
    "title": "Advancing AI Benchmarking with Game Arena",
    "url": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/",
    "summary": "Google DeepMind is expanding its Game Arena benchmarking platform on Kaggle to evaluate AI models in more complex, real-world scenarios. Initially focused on chess to test strategic reasoning, the platform now introduces two new games: Werewolf and poker.\n\nWerewolf is a social deduction game that tests AI's ability to navigate ambiguity, communicate, negotiate, and detect deception through natural language—skills crucial for future AI assistants. Poker challenges models to manage risk and quantify uncertainty, requiring them to infer hidden information and adapt to opponents.\n\nThese games serve as controlled environments to measure AI progress in areas like social dynamics and decision-making under imperfect information. They also function as safety research sandboxes, allowing developers to study behaviors like manipulation in a low-stakes setting. Leaderboards show Google's latest Gemini models currently leading in performance.\n\nTo mark the launch, Google DeepMind is hosting livestreamed tournaments from February 2-4, featuring expert commentary from figures in chess and poker, where top AI models will compete.",
    "chinese_title": "通过游戏竞技场推进人工智能基准测试",
    "chinese_summary": "谷歌DeepMind正在Kaggle上扩展其Game Arena基准测试平台，以评估AI模型在更复杂的现实场景中的表现。该平台最初专注于国际象棋以测试战略推理能力，现在引入了两款新游戏：狼人杀和扑克。\n\n狼人杀是一款社交推理游戏，旨在测试AI在模糊情境中导航、沟通、谈判以及通过自然语言识别欺骗的能力——这些技能对未来AI助手至关重要。扑克则挑战模型管理风险和量化不确定性的能力，要求它们推断隐藏信息并适应对手的策略。\n\n这些游戏作为受控环境，用于衡量AI在社交动态和不完全信息下决策等领域的进展。它们也充当安全研究的沙盒，允许开发者在低风险环境中研究操纵等行为。排行榜显示，谷歌最新的Gemini模型目前在性能上处于领先地位。\n\n为庆祝平台上线，谷歌DeepMind将于2月2日至4日举办直播锦标赛，邀请国际象棋和扑克领域的专家进行解说，届时顶尖AI模型将同台竞技。"
  },
  {
    "id": "46855803",
    "title": "Geologists may have solved mystery of Green River's 'uphill' route",
    "url": "https://phys.org/news/2026-01-geologists-mystery-green-river-uphill.html",
    "summary": "**Summary of \"Geologists may have solved mystery of Green River's 'uphill' route\"**\n\nGeologists have proposed a new explanation for a long-standing puzzle: why a segment of the Green River in Utah appears to flow \"uphill\" against the regional slope of the landscape. The river cuts through the Uinta Mountains, seemingly defying gravity by flowing from a lower-elevation basin into a higher-elevation range.\n\nThe traditional theory suggested that the river maintained its course through the mountains as the range slowly uplifted around it, a process called antecedent drainage. However, new research challenges this.\n\nThe study's key finding is that the Green River's path is not antecedent but **superimposed**. The researchers propose that the river's course was established much later, between 5 and 12 million years ago, on a vast, gently sloping blanket of sedimentary rock (the Uinta Basin strata) that once completely covered the ancient mountain range beneath. As the river cut down through this sedimentary cover, it eventually encountered and became \"locked into\" the harder, underlying bedrock of the mountains, inheriting its seemingly anomalous course. Subsequent erosion then removed the surrounding sedimentary layers, exposing the river as we see it today, cutting directly across the uplifted range.\n\nThis superimposed model better explains the river's relatively young canyon and its alignment with regional folds in the bedrock. The research resolves the apparent contradiction by showing the river is not older than the mountains' uplift but was instead guided by a now-vanished geological layer that masked the true topography.",
    "chinese_title": "地质学家可能已解开格林河“逆流而上”路径之谜",
    "chinese_summary": "**《地质学家或已解开格林河“逆坡而上”之谜》摘要**\n\n地质学家对一个长期谜题提出了新的解释：为何犹他州格林河的一段河道看似“逆坡而上”，与区域地形坡度相悖。这条河流穿越尤因塔山脉，似乎违背重力原理，从海拔较低的盆地流入了海拔较高的山脉。\n\n传统理论认为，河流在山脉缓慢抬升过程中保持了原有河道（称为“先成河”）。然而，新研究对此提出了挑战。\n\n该研究的关键发现是，格林河的河道并非先成，而是**叠置河**。研究人员提出，该河道形成时间要晚得多，约在500万至1200万年前，当时河流在一片广阔平缓的沉积岩层（尤因塔盆地地层）上确立流向，该岩层曾完全覆盖下方的古老山脉。随着河流向下切割这层沉积覆盖物，最终触及并“锁定”下方更坚硬的山脉基岩，从而继承了如今看似异常的河道。随后的侵蚀作用移除了周围的沉积岩层，使河流暴露出来，呈现出我们今天所见到的横穿抬升山脉的景象。\n\n这一叠置模型更好地解释了该河相对年轻的峡谷年龄及其与基岩区域褶皱的一致性。研究表明，河流并非早于山脉抬升形成，而是受一层现已消失、掩盖了真实地形的地质层引导，从而解决了这一表象上的矛盾。"
  },
  {
    "id": "46859443",
    "title": "The largest number representable in 64 bits",
    "url": "https://tromp.github.io/blog/2026/01/28/largest-number-revised",
    "summary": "This article explores the largest number representable within 64 bits, moving beyond standard data types to consider programs in various computational models.\n\nThe largest 64-bit unsigned integer is 2^64 - 1 (~1.8×10^19), while a 64-bit double can reach ~1.8×10^308. However, by interpreting the 64 bits as a program, far larger numbers become possible.\n\nIn Turing machines, the Busy Beaver function BB(n) defines the maximum steps for an n-state halting machine. A 6-state machine fits in 64 bits, but BB(6) is unknown and astronomically large, though likely smaller than Ackermann(9,9).\n\nThe lambda calculus, a foundation for functional programming, allows more efficient encoding. A 49-bit lambda term (\"Melo's Number\") exceeds Graham's Number, and a 61-bit term (\"w218\") is vastly larger, leveraging the fast-growing hierarchy.\n\nThe article compares the \"functional Busy Beaver\" (BBλ), which measures lambda term output size, to the classical BB. BBλ achieves similar colossal growth rates with far fewer bits due to the lambda calculus's superior programmability, unlike the tedious nature of programming Turing machines. This raises the question of why Turing machines remain the standard model for such theoretical limits despite their inefficiency.",
    "chinese_title": "64位可表示的最大数字",
    "chinese_summary": "本文探讨了64位可表示的最大数值，超越标准数据类型，考虑不同计算模型中的程序。\n\n最大的64位无符号整数是2^64 - 1（约1.8×10^19），而64位双精度浮点数可达约1.8×10^308。然而，若将64位解释为程序，则可能表示远大于此的数值。\n\n在图灵机中，繁忙海狸函数BB(n)定义了n状态停机机器的最大步数。一个6状态机器可容纳于64位中，但BB(6)未知且其数值极其巨大，尽管可能小于阿克曼函数Ackermann(9,9)。\n\n作为函数式编程基础的λ演算允许更高效的编码。一个49位λ项（“梅洛数”）已超过葛立恒数，而一个61位λ项（“w218”）则更为庞大，利用了快速增长层级。\n\n文章比较了衡量λ项输出大小的“函数式繁忙海狸”（BBλ）与经典BB函数。由于λ演算卓越的可编程性，BBλ仅用少得多的位数就实现了类似的巨大增长率，这与编程图灵机的繁琐性形成对比。这引发了一个问题：尽管效率低下，为何图灵机仍是此类理论极限的标准模型？"
  },
  {
    "id": "46859118",
    "title": "EPA Advances Farmers' Right to Repair",
    "url": "https://www.epa.gov/newsreleases/epa-advances-farmers-right-repair-their-own-equipment-saving-repair-costs-and",
    "summary": "On February 2, 2026, the U.S. Environmental Protection Agency (EPA) issued guidance clarifying that the Clean Air Act (CAA) supports the right of farmers and equipment owners to repair their own nonroad diesel equipment. The guidance states that manufacturers can no longer use the CAA's anti-tampering provisions to justify restricting access to repair tools or software.\n\nPreviously, manufacturers had interpreted the law as preventing them from sharing essential diagnostic tools, forcing farmers to use authorized dealers for repairs. This led to higher costs and delays, often prompting farmers to use older, less environmentally friendly equipment they could fix themselves.\n\nThe EPA clarifies that temporary overrides of emission control systems are legally permitted when done for the \"purpose of repair\" to restore functionality. This applies to technologies like selective catalytic reduction and Diesel Exhaust Fluid (DEF) systems. The action does not change the law or weaken emission standards but affirms that the CAA should not be a barrier to timely, affordable repairs.\n\nThe guidance, issued in response to a request from John Deere, is framed by the Trump Administration as a victory for farmers that will save them money and increase their independence. The EPA states the move supports both farmers and the agency's environmental mission by encouraging the use of newer, cleaner equipment.",
    "chinese_title": "美国环保署推进农民维修权",
    "chinese_summary": "2026年2月2日，美国环境保护署（EPA）发布指南，明确《清洁空气法案》（CAA）支持农民和设备所有者自行维修非道路柴油设备的权利。指南指出，制造商不能再以《清洁空气法案》的反篡改条款为由，限制维修工具或软件的获取。\n\n此前，制造商曾将该法律解读为禁止其分享必要的诊断工具，迫使农民只能通过授权经销商进行维修。这导致维修成本上升和延误，常常促使农民继续使用他们能够自行维修但更老旧、环保性较差的设备。\n\n环保署澄清，为“维修目的”恢复设备功能时，临时停用排放控制系统是法律允许的。这适用于选择性催化还原和柴油尾气处理液（DEF）系统等技术。此举并未修改法律或削弱排放标准，而是申明《清洁空气法案》不应成为及时、经济维修的障碍。\n\n该指南应约翰迪尔公司的请求发布，被特朗普政府视为农民的胜利，将为他们节省开支并增强自主性。环保署表示，此举通过鼓励使用更新、更清洁的设备，既支持了农民，也符合该机构的环境保护使命。"
  },
  {
    "id": "46852535",
    "title": "Why software stocks are getting pummelled",
    "url": "https://www.economist.com/business/2026/02/01/why-software-stocks-are-getting-pummelled",
    "summary": "Unable to access the article link.",
    "chinese_title": "为何软件股遭受重创",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "46859438",
    "title": "Parking lots as economic drains",
    "url": "https://progressandpoverty.substack.com/p/stop-incentivizing-surface-parking",
    "summary": "This article argues that surface parking lots in downtown areas are \"economic drains\" that actively harm cities by occupying valuable land that could generate far more economic activity, housing, and jobs. Using Syracuse, New York as a case study, the author notes that parking lots consume prime downtown space while contributing minimal economic value compared to offices, apartments, or shops.\n\nThe core problem is a distorted financial incentive structure. Parking lot owners can generate steady, low-effort revenue while their land appreciates in value, with minimal holding costs. Crucially, the property tax system exacerbates this by taxing both land and buildings, meaning a developed property pays significantly higher taxes than an underutilized parking lot on equally valuable land.\n\nWhile the author supports pragmatic parking reforms—like eliminating minimum parking requirements and setting maximums—they argue these alone are insufficient. The fundamental solution proposed is a shift in tax policy: moving taxes away from buildings and onto the unimproved value of the land itself. This \"land value tax\" would make holding land idle as a parking lot financially unsustainable by raising its annual cost and reducing the speculative gain, thereby incentivizing owners to develop their properties to their highest and best use.",
    "chinese_title": "停车场作为经济负担",
    "chinese_summary": "本文认为，市中心的露天停车场是\"经济流失源\"，它们占据着本可产生更多经济活动、住房和就业机会的宝贵土地，从而对城市造成直接损害。以纽约州锡拉丘兹市为例，作者指出，停车场消耗了市中心黄金地段的空间，但与办公楼、公寓或商店相比，其经济贡献微乎其微。\n\n核心问题在于扭曲的财务激励结构。停车场所有者能以极低的维护成本获得稳定收益，同时土地价值持续增值。关键在于，现行房产税制度对土地和建筑物同时征税，导致开发完善的房产所缴税款远高于同等价值土地上利用率低下的停车场，这进一步加剧了问题。\n\n尽管作者支持务实的停车改革——如取消最低停车位配建标准并设置上限——但认为仅靠这些措施远远不够。作者提出的根本解决方案是税收政策转型：将征税重点从建筑物转移至土地本身的原始价值。这种\"土地价值税\"将通过提高土地持有年成本、减少投机收益，使闲置土地用作停车场在经济上难以为继，从而激励所有者将土地用于最高效、最合理的开发用途。"
  },
  {
    "id": "46858802",
    "title": "Being sane in insane places (1973) [pdf]",
    "url": "https://www.weber.edu/wsuimages/psychology/FacultySites/Horvat/OnBeingSaneInInsanePlaces.PDF",
    "summary": "This is the classic 1973 study \"On Being Sane in Insane Places\" by psychologist David Rosenhan. The article details a landmark experiment investigating the reliability of psychiatric diagnosis.\n\n**Main Points:**\n*   **The Experiment:** Eight \"pseudopatients\" (including Rosenhan himself) with no history of mental illness gained admission to 12 different psychiatric hospitals across the U.S. by falsely reporting a single auditory hallucination (\"thud,\" \"empty,\" \"hollow\").\n*   **Key Finding:** All were admitted and diagnosed with serious mental disorders (primarily schizophrenia). Despite immediately ceasing to simulate any symptoms and behaving normally, their \"sanity\" went unrecognized by hospital staff.\n*   **Staff vs. Patients:** While staff consistently interpreted the pseudopatients' normal behaviors (e.g., note-taking) through the lens of their diagnosis, other patients frequently suspected they were not ill.\n*   **Power of Labels:** The study powerfully demonstrated the **stickiness of diagnostic labels** in psychiatric settings. Once labeled, a patient's behavior was interpreted to confirm the diagnosis, a process Rosenhan called a \"type II error\" (failing to detect sanity).\n*   **Depersonalization:** The report describes a profound **loss of personal autonomy and depersonalization** within the institutions, where patients were largely ignored by staff and treated as invisible.\n*   **Conclusion:** The study argued that psychiatric hospitals could not reliably distinguish the sane from the insane, highlighting the profound contextual biases inherent in psychiatric diagnosis and the potentially dehumanizing nature of institutional care. It sparked major reforms and debates in psychiatry and mental health law.",
    "chinese_title": "在疯狂之地保持理智（1973）[pdf]",
    "chinese_summary": "这是心理学家大卫·罗森汉于1973年发表的经典研究《在疯狂之处保持理智》。该文章详述了一项具有里程碑意义的实验，旨在调查精神病学诊断的可靠性。\n\n**核心要点：**\n*   **实验设计：** 八名无精神病史的“假病人”（包括罗森汉本人）通过谎称存在单一幻听症状（如“砰”、“空洞”、“空虚”），成功进入美国12家不同的精神病院。\n*   **关键发现：** 所有假病人均被收治并被诊断为严重精神障碍（主要是精神分裂症）。尽管他们入院后立即停止模拟任何症状并行为正常，但其“理智”状态未得到医护人员的识别。\n*   **医护人员 vs. 患者：** 医护人员持续透过诊断标签的视角解读假病人的正常行为（如记笔记），而其他患者则常常怀疑他们并未患病。\n*   **标签效应：** 该研究有力揭示了精神病学环境中**诊断标签的顽固性**。一旦被贴上标签，患者的行为就会被解读为符合诊断，罗森汉将此过程称为“第二类错误”（未能识别理智状态）。\n*   **去个性化：** 报告描述了机构内**个人自主权的严重丧失和去个性化现象**，患者大多被医护人员忽视，被视为隐形存在。\n*   **结论：** 研究指出精神病院无法可靠地区分理智者与精神失常者，揭示了精神病学诊断中根深蒂固的环境偏见以及机构照护可能存在的非人化本质。这项研究引发了精神病学和精神卫生法领域的重大改革与辩论。"
  },
  {
    "id": "46858966",
    "title": "Show HN: PolliticalScience – Anonymous daily polls with 24-hour windows",
    "url": "https://polliticalscience.vote/",
    "summary": "**Summary of \"PolliticalScience\"**\n\nPolliticalScience is a new platform featuring anonymous, daily polls on political and social topics. The showcased poll for February 2, 2026, focuses on the criminal justice issue of whether the death penalty should remain legal, with options to \"AGREE\" or \"DISAGREE.\"\n\nKey features of the platform highlighted in the post are:\n*   **Anonymous participation:** User votes are not linked to personal identities.\n*   **24-hour polling windows:** Each poll is active for a single day.\n*   **No signup or tracking:** Emphasizing privacy and ease of access, the service requires no account creation and does not track users.\n\nThe core concept is to provide a simple, low-barrier tool for gauging daily public opinion on current issues without the influence of social media profiles or persistent user data.",
    "chinese_title": "展示 HN：政治科学——匿名每日投票，24小时窗口期",
    "chinese_summary": "**《政治科学》平台简介**\n\n《政治科学》是一个专注于政治与社会话题的新型匿名每日投票平台。2026年2月2日的示例投票聚焦于刑事司法议题——死刑是否应保持合法，用户可选择“赞同”或“反对”。\n\n该平台在文中强调的主要特点包括：\n*   **匿名参与**：用户投票不关联个人身份。\n*   **24小时投票窗口**：每项投票仅开放一天。\n*   **无需注册或追踪**：平台注重隐私与便捷性，无需创建账户，也不追踪用户数据。\n\n其核心理念是提供一个简单、低门槛的工具，用于收集公众对时事议题的每日意见，同时避免社交媒体身份或持久用户数据对结果的影响。"
  },
  {
    "id": "46854534",
    "title": "My fast zero-allocation webserver using OxCaml",
    "url": "https://anil.recoil.org/notes/oxcaml-httpz",
    "summary": "This article introduces **httpz**, a high-performance HTTP/1.1 webserver built using **OxCaml**, a version of OCaml with advanced language extensions. The author, who works with large-scale planetary computing data, sought to replace Python infrastructure with a more performant, type-safe solution.\n\nThe core goal of httpz is **zero (or minimal) heap allocation** to maximize performance and minimize garbage collector activity. This is achieved by leveraging several key OxCaml features:\n\n*   **Unboxed Types and Records**: Using types like `int16#` and unboxed records (`#{ ... }`) allows data to be stored directly in registers or on the stack, eliminating the boxing overhead of standard OCaml.\n*   **Local Allocations and Exclaves**: The `local_` and `exclave_` keywords enable stack allocation for data that must not escape a function, preventing heap allocation.\n*   **Mutable Local Variables**: The `let mutable` syntax allows for stack-allocated mutable variables, replacing heap-allocated `ref` cells.\n\nThese features allow the entire HTTP connection handling to occur on the call stack, making connection cleanup as simple as returning from a function. The parser returns results as unboxed, local tuples.\n\nThe author notes some current limitations, including tooling fluidity and challenges with certain OxCaml features like `or_null` types. Despite this, they successfully used OxCaml to build a fast, allocation-efficient webserver, aided by Claude's coding assistance for rapid prototyping.",
    "chinese_title": "我使用OxCaml构建的快速零分配网络服务器",
    "chinese_summary": "本文介绍了**httpz**，这是一个使用**OxCaml**构建的高性能HTTP/1.1网络服务器。OxCaml是具备高级语言扩展功能的OCaml版本。作者因处理大规模行星计算数据，希望用性能更高、类型更安全的方案替代Python基础设施。\n\nhttpz的核心目标是实现**零（或最小化）堆内存分配**，以最大化性能并减少垃圾回收活动。这通过利用OxCaml的几项关键特性实现：\n\n*   **拆箱类型与记录**：使用`int16#`等类型及拆箱记录（`#{ ... }`）可将数据直接存储在寄存器或栈中，消除了标准OCaml的装箱开销。\n*   **局部分配与隔离域**：`local_`和`exclave_`关键字支持对不得逃逸函数的数据进行栈分配，避免堆内存分配。\n*   **可变局部变量**：`let mutable`语法允许栈分配的可变变量，替代堆分配的`ref`单元。\n\n这些特性使得整个HTTP连接处理可在调用栈上完成，连接清理只需简单地从函数返回。解析器以拆箱的局部元组形式返回结果。\n\n作者指出了当前存在的局限，包括工具链的流动性问题以及`or_null`类型等某些OxCaml特性的使用挑战。尽管如此，他们仍成功运用OxCaml构建了这款快速、内存分配高效的网络服务器，并借助Claude的编码辅助实现了快速原型开发。"
  },
  {
    "id": "46855640",
    "title": "Show HN: Adboost – A browser extension that adds ads to every webpage",
    "url": "https://github.com/surprisetalk/AdBoost",
    "summary": "**Summary:**\n\nAdBoost is a satirical browser extension that deliberately adds advertisements to every webpage, inverting the typical ad-blocker's purpose. The project is presented as a tongue-in-cheek \"Show HN\" submission, highlighting the pervasive nature of online advertising.\n\nThe key information is that users can install it by cloning the repository, enabling Chrome's developer mode, and loading the unpacked extension files. The minimalist description and instructions suggest the extension is a conceptual or humorous project meant to critique the ad-saturated browsing experience, rather than a serious tool for actual use.",
    "chinese_title": "展示HN：Adboost – 一款为每个网页添加广告的浏览器扩展",
    "chinese_summary": "**摘要：**\n\nAdBoost是一款讽刺性的浏览器扩展，它故意在每个网页上添加广告，颠覆了典型广告拦截器的用途。该项目以戏谑的“Show HN”形式呈现，突显了网络广告的无处不在。\n\n关键信息是用户可以通过克隆代码库、启用Chrome开发者模式并加载解压的扩展文件来安装它。其极简的描述和说明暗示该扩展是一个概念性或幽默项目，旨在批判广告泛滥的浏览体验，而非真正实用的工具。"
  },
  {
    "id": "46826991",
    "title": "IsoCoaster – Theme Park Builder",
    "url": "https://iso-coaster.com/",
    "summary": "Based on the placeholder text, the article titled \"IsoCoaster – Theme Park Builder\" appears to be a webpage or article that is currently loading or its content is not yet available.\n\nTherefore, a summary cannot be provided as there is no substantive content to analyze. The main point conveyed by the visible text is simply that the intended material is in the process of loading or is temporarily inaccessible.\n\nTo generate a proper summary, the full article detailing the features, gameplay, or purpose of the \"IsoCoaster\" theme park simulation game would need to be loaded and presented.",
    "chinese_title": "IsoCoaster – 主题公园建造者",
    "chinese_summary": "根据占位文本，标题为《IsoCoaster – 主题公园建造者》的页面或文章似乎正在加载中，或其内容暂不可用。\n\n因此，由于缺乏可供分析的实质性内容，无法提供摘要。当前可见文字仅表明目标材料正在加载或暂时无法访问。\n\n若要生成恰当的摘要，需要加载并展示详细介绍《IsoCoaster》主题公园模拟游戏特色、玩法或用途的完整文章内容。"
  },
  {
    "id": "46858829",
    "title": "Linux From Scratch ends SysVinit support",
    "url": "https://lists.linuxfromscratch.org/sympa/arc/lfs-announce/2026-02/msg00000.html",
    "summary": "**Summary of \"Linux From Scratch ends SysVinit support\"**\n\nThe Linux From Scratch (LFS) project has announced the end of support for the SysVinit initialization system in its core books. Starting with the upcoming LFS version 12.0, the project will exclusively support systemd as the init system.\n\nThis decision was made due to the significant and growing maintenance burden of supporting two init systems. The SysVinit scripts required extensive manual updates for each new package version, a process that had become unsustainable for the volunteer development team. In contrast, systemd's unit files are largely auto-generated by the software packages themselves, drastically reducing maintenance overhead.\n\nConsequently, the LFS 11.4 book will be the final version to include instructions for building a system with SysVinit. All future development and official support will focus solely on systemd. The project maintains that this change is purely practical, aimed at ensuring the project's long-term viability, and is not a commentary on the technical merits of either init system.\n\nFor users who strongly prefer SysVinit, the project notes that the archived LFS 11.4 book will remain available, and the broader LFS community may continue to provide unofficial support or forks. However, the core LFS project will now align with the predominant init system used by most major Linux distributions to streamline its development process.",
    "chinese_title": "Linux From Scratch 终止对 SysVinit 的支持",
    "chinese_summary": "**《Linux From Scratch 终止 SysVinit 支持》摘要**\n\nLinux From Scratch（LFS）项目已宣布在其核心手册中终止对 SysVinit 初始化系统的支持。从即将发布的 LFS 12.0 版本开始，该项目将仅支持 systemd 作为初始化系统。\n\n这一决定是由于支持两种初始化系统带来了巨大且日益增长的维护负担。SysVinit 脚本需要为每个新软件包版本进行大量手动更新，这一过程对志愿者开发团队而言已难以为继。相比之下，systemd 的单元文件主要由软件包自身自动生成，从而大幅降低了维护开销。\n\n因此，LFS 11.4 手册将是最后一个包含使用 SysVinit 构建系统指导的版本。所有未来的开发和官方支持将仅专注于 systemd。项目强调，此变更纯粹出于实际考量，旨在确保项目的长期可行性，并非对两种初始化系统技术优劣的评判。\n\n对于强烈偏好 SysVinit 的用户，项目指出存档的 LFS 11.4 手册仍将可用，且更广泛的 LFS 社区可能会继续提供非官方支持或分支版本。然而，核心 LFS 项目今后将与大多数主流 Linux 发行版采用的主流初始化系统保持一致，以简化其开发流程。"
  },
  {
    "id": "46856854",
    "title": "Waymo seeking about $16B near $110B valuation",
    "url": "https://www.bloomberg.com/news/articles/2026-01-31/waymo-seeking-about-16-billion-near-110-billion-valuation",
    "summary": "Unable to access the article link.",
    "chinese_title": "Waymo寻求以约1100亿美元估值融资160亿美元",
    "chinese_summary": "无法访问文章链接。"
  },
  {
    "id": "46848060",
    "title": "Pretty soon, heat pumps will be able to store and distribute heat as needed",
    "url": "https://www.sintef.no/en/latest-news/2026/pretty-soon-heat-pumps-will-be-able-to-store-and-distribute-heat-as-needed/",
    "summary": "Researchers from SINTEF and the Swiss company COWA Thermal Solutions have developed a compact thermal battery for homes with heat pumps. This system stores excess heat when electricity is cheap or green and releases it on demand, acting like a \"thermal battery.\"\n\nThe core innovation uses non-toxic, inexpensive salt hydrates as a phase-change material. These substances store significantly more heat in less space than a traditional water tank—up to four times less—and maintain more stable temperatures.\n\nKey technical improvements include thin cooling fins made from recycled aluminium, which enhance heat transfer. To protect the aluminium from corrosion by the salts, a durable ceramic coating is applied. These enhancements have increased the system's efficiency from 65% to 85%, while reducing charging time by over 70% and heat discharge time by over 80%.\n\nThe solution allows for smarter energy use, reducing grid strain from constant heat pump operation and providing reliable hot water during peak demand. This development, part of the EU-funded Sure2Coat project, represents a significant step toward making advanced thermal storage practical and efficient for private households.",
    "chinese_title": "很快，热泵将能够根据需要储存和分配热量。",
    "chinese_summary": "SINTEF研究所与瑞士COWA Thermal Solutions公司共同为配备热泵的家庭开发了一种紧凑型热能电池。该系统在电价低廉或绿色电力充足时储存多余热量，并按需释放，起到\"热能电池\"的作用。\n\n其核心创新在于使用无毒、廉价的水合盐作为相变材料。相比传统水箱，这些物质在更小空间内储存的热量显著增加——空间需求减少达四分之三，并能保持更稳定的温度。\n\n关键技术改进包括采用回收铝制成的薄型冷却翅片，增强了热传递效率。为保护铝材免受盐分腐蚀，还施加了耐用的陶瓷涂层。这些改进使系统效率从65%提升至85%，充电时间缩短70%以上，放热时间减少80%以上。\n\n该方案实现了更智能的能源利用，既缓解了热泵持续运行对电网的压力，又能在用电高峰期间提供可靠的热水供应。作为欧盟Sure2Coat项目的成果，这项进展标志着先进热能存储技术向实用化、高效化的家庭应用迈出了重要一步。"
  },
  {
    "id": "46855550",
    "title": "UK government launches fuel forecourt price API",
    "url": "https://www.gov.uk/guidance/access-the-latest-fuel-prices-and-forecourt-data-via-api-or-email",
    "summary": "**Summary of UK Government's Fuel Finder Service**\n\nThe UK Department for Energy Security and Net Zero has launched the Fuel Finder service to provide public access to real-time fuel price and forecourt data.\n\nThe service aims to help drivers find the cheapest fuel by making this data available for integration into third-party comparison websites, apps, and other tools. Available data includes current retail prices by fuel type, forecourt addresses, operators, amenities, opening hours, and update timestamps, with prices published within 30 minutes of any change.\n\nData can be accessed in three ways:\n1.  Downloading a CSV file updated twice daily.\n2.  Subscribing via email to receive links to the latest CSV file.\n3.  Using a public REST API for direct integration into applications, which requires authentication via OAuth 2.0 and a GOV.UK One Login.\n\nThe service is intended for a wide range of users, including developers, academics, journalists, and organisations. Technical knowledge is required for API integration, while non-technical users can access the information through participating third-party platforms.",
    "chinese_title": "英国政府推出加油站油价API",
    "chinese_summary": "**英国政府燃油查找服务摘要**\n\n英国能源安全与净零排放部推出了燃油查找服务，旨在为公众提供实时燃油价格及加油站数据。\n\n该服务通过将数据开放给第三方比价网站、应用程序及其他工具进行整合，帮助驾驶者寻找最优惠的燃油。可获取的数据包括按燃油类型划分的当前零售价格、加油站地址、运营商、配套设施、营业时间及更新时间戳，所有价格变动将在30分钟内更新发布。\n\n数据可通过以下三种方式获取：\n1.  下载每日更新两次的CSV文件。\n2.  通过电子邮件订阅以获取最新CSV文件链接。\n3.  使用公共REST API直接集成到应用程序中，此方式需通过OAuth 2.0和GOV.UK统一登录进行身份验证。\n\n该服务面向开发者、学者、记者及各类组织等广泛用户群体。API集成需要技术知识，而非技术用户可通过参与合作的第三方平台获取信息。"
  },
  {
    "id": "46854999",
    "title": "Claude Code is suddenly everywhere inside Microsoft",
    "url": "https://www.theverge.com/tech/865689/microsoft-claude-code-anthropic-partnership-notepad",
    "summary": "Microsoft is increasingly adopting Anthropic's Claude Code AI tool internally, even as it sells GitHub Copilot to customers. The company is encouraging thousands of employees, including non-technical staff in divisions like Windows and Microsoft 365, to use Claude Code for prototyping and coding tasks. Engineers are being asked to compare it with GitHub Copilot.\n\nThis signals a significant internal vote of confidence in Anthropic's technology. Microsoft is now a top Anthropic customer, counts its model sales toward Azure quotas, and has a deal to offer Claude models to its cloud clients. While Microsoft states OpenAI remains its \"primary partner,\" it is leveraging Anthropic's models where they prove more capable.\n\nThe broad pilot highlights a shift toward enabling more employees to generate code with AI, which could pressure junior developer roles and move toward more autonomous AI agents. The article also notes upcoming Xbox game reveals and other Microsoft news, including a Windows update bug and new AI features in apps like Paint.",
    "chinese_title": "Claude Code突然在微软内部无处不在。",
    "chinese_summary": "微软正越来越多地在内部采用Anthropic的Claude Code AI工具，同时继续向客户销售GitHub Copilot。该公司鼓励包括Windows和Microsoft 365部门非技术人员在内的数千名员工，将Claude Code用于原型设计和编码任务。工程师们还被要求将其与GitHub Copilot进行比较。\n\n这标志着微软对Anthropic技术投下了重要的内部信任票。微软现已成为Anthropic的顶级客户，将其模型销售计入Azure配额，并达成协议向云客户提供Claude模型。尽管微软声称OpenAI仍是其“主要合作伙伴”，但在Anthropic模型表现更出色的领域，微软正在积极利用这些模型。\n\n这项广泛的试点计划凸显了让更多员工使用AI生成代码的转变，这可能对初级开发人员岗位构成压力，并推动向更自主的AI代理方向发展。文章还提及了即将发布的Xbox游戏消息及其他微软新闻，包括Windows更新漏洞以及Paint等应用程序中的新AI功能。"
  },
  {
    "id": "46849926",
    "title": "Treasures found on HS2 route",
    "url": "https://www.bbc.com/news/articles/c93v21q5xdvo",
    "summary": "During the construction of the HS2 railway line between London and Birmingham, archaeologists have uncovered an \"unprecedented\" collection of around 450,000 historical objects. These finds, now stored in a secret warehouse in Yorkshire, span over 10,000 years of British history.\n\nKey discoveries include a possible Roman gladiator's bone tag, a Neanderthal-era hand axe, and 19th-century gold dentures. Other notable items are an Anglo-Saxon spindle whorl, a medieval die, and a porcelain pug figurine from an 18th-century grave.\n\nWhile the archaeological fieldwork is largely complete, the future of the collection is undecided. Ownership will be determined by law, with items potentially belonging to the government or landowners. Archaeologists hope many artefacts will be donated to local museums for public display.\n\nThe project has been praised for its archaeological significance but remains controversial. Critics argue HS2's high cost and environmental damage outweigh its benefits, though historians contend the accompanying digs have provided invaluable insights into Britain's past.",
    "chinese_title": "HS2线路沿线发现的宝藏",
    "chinese_summary": "在伦敦至伯明翰的HS2高铁线路建设期间，考古学家发掘出约45万件\"史无前例\"的历史文物。这些横跨英国一万多年历史的发现现储藏于约克郡一处秘密仓库。\n\n重要发现包括可能属于古罗马角斗士的骨制标签、尼安德特人时期的手斧以及19世纪的黄金假牙。其他值得注意的文物有盎格鲁-撒克逊时期的纺轮、中世纪骰子，以及来自18世纪墓葬的瓷质哈巴狗雕像。\n\n虽然考古田野工作已基本完成，但这批藏品的未来尚未确定。文物所有权将依法判定，可能归属政府或土地所有者。考古学家希望许多文物能被捐赠给地方博物馆向公众展示。\n\n该项目因考古学意义受到赞誉，但仍存争议。批评者认为HS2的高昂成本和环境破坏超过了其效益，而历史学家则指出伴随工程开展的挖掘为研究英国历史提供了宝贵资料。"
  },
  {
    "id": "46849258",
    "title": "My iPhone 16 Pro Max produces garbage output when running MLX LLMs",
    "url": "https://journal.rafaelcosta.me/my-thousand-dollar-iphone-cant-do-math/",
    "summary": "The author discovered that their iPhone 16 Pro Max produced nonsensical outputs when running local MLX LLMs, while the same code worked perfectly on an iPhone 15 Pro and a MacBook Pro. After extensive debugging, they found that the tensor values inside the model on the iPhone 16 were wildly different and orders of magnitude off compared to the other devices, despite receiving identical inputs.\n\nThis led them to conclude the issue was a hardware defect, likely in the Neural Engine of the A18 chip, which handles ML computations. The problem was compounded by the fact that Apple Intelligence features also failed to work on the same device. The author's experience highlights the importance of considering hardware as a potential source of error in software debugging. They eventually replaced the defective iPhone 16 Pro Max with an iPhone 17 Pro Max, which performed correctly.",
    "chinese_title": "我的iPhone 16 Pro Max运行MLX LLM时输出效果很差",
    "chinese_summary": "作者发现，其iPhone 16 Pro Max在运行本地MLX大语言模型时会产生无意义的输出，而相同的代码在iPhone 15 Pro和MacBook Pro上却运行完美。经过大量调试后，他们发现尽管输入相同，但iPhone 16上模型内部的张量值与其他设备相比差异巨大，且存在数量级上的偏差。\n\n这使他们得出结论：问题源于硬件缺陷，很可能出在处理机器学习计算的A18芯片神经引擎上。同一设备上的苹果智能功能也无法正常工作，进一步加剧了问题的复杂性。作者的经历凸显了在软件调试中将硬件视为潜在错误源的重要性。最终，他们将存在缺陷的iPhone 16 Pro Max更换为iPhone 17 Pro Max，后者表现正常。"
  },
  {
    "id": "46815136",
    "title": "Tomo: A statically typed, imperative language that cross-compiles to C [video]",
    "url": "https://www.youtube.com/watch?v=-vGE0I8RPcc",
    "summary": "This is not an article about a programming language. The text appears to be the standard legal and informational footer from a YouTube video page.\n\nThe provided \"content\" is generic YouTube platform information, including:\n*   Copyright and policy links (Terms, Privacy, Safety).\n*   Contact information for Google/YouTube.\n*   A disclaimer that products featured in videos are sold by third parties, not YouTube.\n\nThere is no information about \"Tomo,\" a statically typed language, or any technical content to summarize. The title \"[video]\" suggests the actual article or video description about the Tomo language is missing from the provided text.",
    "chinese_title": "Tomo：一种静态类型、命令式语言，可交叉编译为C语言 [视频]",
    "chinese_summary": "这不是一篇关于编程语言的文章。这段文字似乎是YouTube视频页面的标准法律和信息页脚。\n\n所提供的“内容”是通用的YouTube平台信息，包括：\n*   版权和政策链接（条款、隐私、安全）。\n*   Google/YouTube的联系信息。\n*   免责声明：视频中展示的产品由第三方销售，而非YouTube。\n\n文中没有关于“Tomo”这种静态类型语言的信息，也没有任何技术内容可供总结。标题“[video]”表明，关于Tomo语言的实际文章或视频描述并未包含在所提供的文本中。"
  },
  {
    "id": "46811207",
    "title": "Valanza – my Unix way for weight tracking and anlysis",
    "url": "https://github.com/paolomarrone/valanza",
    "summary": "**Valanza** is an experimental, Unix-style tool for tracking and analyzing weight data. Its core philosophy is to use small, composable programs (written in R, awk, and bash) that communicate via pipes, rather than combining data and logic in a single spreadsheet.\n\nThe workflow begins with raw weight data. A series of specialized filters process it: an R script fills gaps via linear interpolation, an awk script calculates a moving average, and another applies a low-pass filter. These processes run in parallel using named pipes, with their outputs recombined. Finally, Gnuplot generates a visualization showing the original, interpolated, and smoothed data signals.\n\nDesigned as a personal project for \"fun and pleasure,\" Valanza demonstrates a modular, Unix-inspired approach to data analysis. It requires bash, R, awk, and Gnuplot to run. The tool is released under the MIT license.",
    "chinese_title": "瓦兰扎——我的Unix式体重追踪与分析之道",
    "chinese_summary": "**Valanza** 是一款实验性的 Unix 风格工具，用于追踪和分析体重数据。其核心理念是使用小型、可组合的程序（用 R、awk 和 bash 编写），通过管道进行通信，而不是将数据和逻辑结合在单一的电子表格中。\n\n工作流程从原始体重数据开始。一系列专用过滤器对其进行处理：一个 R 脚本通过线性插值填补缺失值，一个 awk 脚本计算移动平均值，另一个则应用低通滤波器。这些进程通过命名管道并行运行，并将输出重新组合。最后，Gnuplot 生成可视化图表，显示原始、插值和经过平滑处理的数据信号。\n\nValanza 是作为个人项目“出于兴趣和乐趣”而设计的，展示了模块化、受 Unix 启发的数据分析方法。运行该工具需要 bash、R、awk 和 Gnuplot。该工具采用 MIT 许可证发布。"
  },
  {
    "id": "46830026",
    "title": "Hypergrowth isn’t always easy",
    "url": "https://tailscale.com/blog/hypergrowth-isnt-always-easy",
    "summary": "This article addresses recent service disruptions at Tailscale, acknowledging that its uptime has been \"shakier than usual.\" The company maintains transparency through a public status page but notes that its updates can lead to varied interpretations.\n\nThe core of the discussion explains Tailscale's system architecture. The \"coordination server\" is actually a sharded \"coordination service\"—a high-speed, centralized message bus for each customer network (tailnet). This design enables near-instantaneous updates (like ACL changes) but means that if a specific server instance fails, the control plane for those connected tailnets is affected. Crucially, the data plane (existing connections) continues to work even during such an outage, though actions like adding devices or changing settings are blocked.\n\nThe company frames its response around \"continuous improvement.\" It outlines several initiatives to enhance reliability: caching network maps locally so restarts don't require the control server; evolving the sharded service with features like hot spares and live migrations; developing better multi-tailnet sharing for geographic resilience; and investing in more rigorous testing.\n\nThe author concludes by committing to over-communication, measuring every incident, and systematically working to eliminate downtime, while inviting user reports and potential job applicants interested in solving these challenges.",
    "chinese_title": "高速增长并非总是轻而易举。",
    "chinese_summary": "本文探讨了Tailscale近期服务中断的问题，承认其运行稳定性“比往常更不稳定”。公司通过公开状态页面保持透明度，但也指出其更新可能导致不同的解读。\n\n讨论的核心解释了Tailscale的系统架构。“协调服务器”实际上是一个分片的“协调服务”——为每个客户网络（tailnet）提供高速、集中的消息总线。这种设计实现了近乎即时的更新（如ACL变更），但也意味着如果特定服务器实例发生故障，相关tailnet的控制平面就会受到影响。关键的是，即使在此类中断期间，数据平面（现有连接）仍能继续工作，但添加设备或更改设置等操作会被阻止。\n\n公司将其应对措施定位为“持续改进”。概述了多项提升可靠性的举措：在本地缓存网络映射，使重启无需依赖控制服务器；通过热备和实时迁移等功能演进分片服务；开发更好的多tailnet共享机制以实现地理弹性；并投入更严格的测试。\n\n作者最后承诺将加强沟通、记录每起事件并系统性地消除停机时间，同时欢迎用户反馈以及有兴趣解决这些挑战的潜在职位申请者。"
  },
  {
    "id": "46793100",
    "title": "Serverless backend hosting without idle costs – open-source",
    "url": "https://github.com/aryankashyap0/shorlabs",
    "summary": "**Shorlabs** is an open-source platform designed to simplify backend hosting by offering a serverless, \"Vercel-like\" experience for Python and Node.js applications. It eliminates idle costs by running on AWS Lambda, ensuring you only pay for actual compute time with automatic scaling.\n\nKey features include one-click deployments from GitHub, automatic runtime detection, custom subdomains, secure environment variable management, and configurable compute resources. The platform provides a dashboard for tracking deployments and viewing real-time logs.\n\nTo get started, developers need Node.js, Python, Docker, and AWS credentials. The setup involves cloning the repository, installing dependencies, and configuring environment variables. Deployment requires running scripts to set up the core API on AWS Lambda, configure wildcard subdomain routing via Lambda@Edge and CloudFront, and schedule usage metrics aggregation. The frontend is a Next.js application deployed separately.\n\nShorlabs addresses the complexity of backend deployment by abstracting infrastructure management, allowing developers to focus solely on their code. The tech stack includes FastAPI, DynamoDB, SQS, and Clerk for authentication, all built to provide a seamless, cost-effective backend hosting solution.",
    "chinese_title": "无闲置成本的无服务器后端托管——开源",
    "chinese_summary": "**Shorlabs** 是一个开源平台，旨在通过为 Python 和 Node.js 应用提供类似 Vercel 的无服务器体验来简化后端托管。它基于 AWS Lambda 运行，消除了闲置成本，确保您只需为实际计算时间付费，并支持自动扩缩容。\n\n核心功能包括从 GitHub 一键部署、自动运行时检测、自定义子域名、安全的环境变量管理以及可配置的计算资源。该平台提供仪表板，用于跟踪部署状态和查看实时日志。\n\n开发者需准备 Node.js、Python、Docker 和 AWS 凭证才能开始使用。设置步骤包括克隆代码库、安装依赖项和配置环境变量。部署过程需要运行脚本，以在 AWS Lambda 上设置核心 API，通过 Lambda@Edge 和 CloudFront 配置通配符子域名路由，并安排使用指标聚合任务。前端是一个独立部署的 Next.js 应用。\n\nShorlabs 通过抽象基础设施管理，解决了后端部署的复杂性，让开发者能够专注于代码开发。其技术栈包括 FastAPI、DynamoDB、SQS 以及用于身份验证的 Clerk，所有组件共同构建了一个无缝、经济高效的后端托管解决方案。"
  },
  {
    "id": "46852096",
    "title": "Apple's MacBook Pro DFU port documentation is wrong",
    "url": "https://lapcatsoftware.com/articles/2026/2/1.html",
    "summary": "The author discovered that Apple's official documentation for the DFU (Device Firmware Update) port on Apple silicon MacBook Pros is incorrect. According to Apple, the DFU port for a 14-inch MacBook Pro with an M4/M5 chip is the rightmost USB-C port, while for all other models it is the leftmost port. However, the author's 16-inch MacBook Pro with an M4 Pro chip required the external startup disk to be plugged into the right-side port for a successful macOS update, contradicting the guide.\n\nThis port selection is critical when installing or updating macOS on an external drive, as using the DFU port causes the update to fail silently. The process appears to complete normally but leaves the macOS version unchanged. The author's issue was resolved only after moving the external SSD to a different port, a solution highlighted in referenced articles by Michael Tsai, who experienced the same problem.\n\nThe article criticizes the poor user experience, noting that the system provides no clear error message about the port issue and that Software Update allowed the Mac to sleep during the update process, further delaying completion.",
    "chinese_title": "苹果MacBook Pro的DFU端口文档有误",
    "chinese_summary": "作者发现苹果官方文档中关于Apple silicon MacBook Pro DFU（设备固件更新）接口的说明存在错误。根据苹果的说法，搭载M4/M5芯片的14英寸MacBook Pro的DFU接口是最右侧的USB-C端口，而其他所有型号均为最左侧端口。然而，作者使用的搭载M4 Pro芯片的16英寸MacBook Pro在更新macOS时，必须将外置启动盘插入右侧端口才能成功，这与官方指南相矛盾。\n\n在外置驱动器上安装或更新macOS时，端口选择至关重要，因为使用DFU端口会导致更新静默失败。整个过程看似正常完成，但macOS版本实际并未改变。作者将外置SSD移至其他端口后才解决问题，Michael Tsai在相关文章中也强调了这一解决方案，他同样遇到了该问题。\n\n文章批评了这种糟糕的用户体验，指出系统未就端口问题提供明确错误提示，且软件更新过程中允许Mac进入睡眠状态，进一步延迟了更新完成时间。"
  },
  {
    "id": "46824398",
    "title": "Solvingn the Santa Claus concurrency puzzle with a model checker",
    "url": "https://wyounas.github.io/puzzles/concurrency/2026/01/10/how-to-help-santa-claus-concurrently/",
    "summary": "This article explores solving the Santa Claus concurrency puzzle using the SPIN model checker and its Promela language. The puzzle requires Santa to coordinate with nine reindeer or three elves, prioritizing reindeer and ensuring entire groups participate together without Santa marshalling them.\n\nThe author first demonstrates how intuitive but flawed solutions fail under subtle interleavings. Three failure scenarios are modeled: Santa delivering with incomplete reindeer, Santa consulting and delivering simultaneously, and Santa serving elves while reindeer wait—all violating core constraints.\n\nThe correct solution, inspired by Ben-Ari, introduces separate \"room\" processes to handle marshalling, freeing Santa from counting. Santa simply waits for a ready signal, serves the prioritized group, and notifies the room to release its members. This design is validated in SPIN using Linear Temporal Logic (LTL) properties to prove it avoids all previous failures under exhaustive state exploration.\n\nThe key takeaway is that model checking provides rigorous verification by exploring all possible interleavings, uncovering bugs that conventional testing might miss, and ensuring the synchronization logic correctly implements the puzzle's constraints.",
    "chinese_title": "使用模型检查器解决圣诞老人并发难题",
    "chinese_summary": "本文探讨了如何使用SPIN模型检查器及其Promela语言解决圣诞老人并发难题。该难题要求圣诞老人协调九只驯鹿或三个精灵，优先处理驯鹿，并确保整个群体共同参与，而无需圣诞老人进行调度。\n\n作者首先展示了直观但有缺陷的解决方案如何在微妙的交错执行下失败。文中模拟了三种失败场景：圣诞老人与不完整的驯鹿群出发送礼物、圣诞老人同时咨询和送礼物，以及圣诞老人在驯鹿等待时服务精灵——这些均违反了核心约束。\n\n受Ben-Ari启发，正确的解决方案引入了独立的“房间”进程来处理调度，从而免除了圣诞老人的计数负担。圣诞老人只需等待就绪信号，服务优先群体，并通知房间释放其成员。该设计在SPIN中使用线性时序逻辑（LTL）属性进行验证，通过穷举状态探索证明其避免了所有先前的失败情况。\n\n关键启示在于：模型检查通过探索所有可能的交错执行，提供了严格的验证，能够发现传统测试可能遗漏的错误，并确保同步逻辑正确实现了难题的约束条件。"
  },
  {
    "id": "46856899",
    "title": "Show HN: Stelvio – Ship Python to AWS",
    "url": "https://stelvio.dev/",
    "summary": "**Stelvio** is an open-source Python framework designed to simplify deploying serverless applications to AWS. It allows developers to define cloud infrastructure directly in Python code, eliminating the need for YAML configuration files.\n\nThe core promise is to enable shipping applications in \"minutes, not days\" by providing smart defaults and automating complex tasks. Key features include:\n*   **Infrastructure as Python:** Define AWS resources like Lambda functions, S3 buckets, DynamoDB tables, API Gateways, and messaging services using Python classes.\n*   **Automated Permissions:** Its \"linking\" system automatically configures IAM policies and environment variables when resources (e.g., a function and a database) are connected.\n*   **Developer Experience:** It offers a live dev mode for local Lambda testing, full overrides for customization, and integrates with existing Python tooling (IDEs, linters).\n\nThe tool supports a comprehensive suite of AWS components essential for cloud apps, including scheduled functions (Cron), storage, databases, messaging (SQS/SNS), email (SES), and REST APIs with custom domain routing.\n\nPositioned as a bridge between simple scripting and complex infrastructure, Stelvio aims to give developers both speed and full control, remaining free and open-source under the Apache 2.0 license.",
    "chinese_title": "Show HN: Stelvio – 将Python项目部署至AWS",
    "chinese_summary": "**Stelvio** 是一款开源 Python 框架，旨在简化将无服务器应用程序部署到 AWS 的过程。它允许开发者直接在 Python 代码中定义云基础设施，无需使用 YAML 配置文件。\n\n其核心承诺是通过提供智能默认值和自动化复杂任务，实现“数分钟而非数天”的应用交付。主要特性包括：\n*   **基础设施即 Python 代码：** 使用 Python 类定义 AWS 资源，如 Lambda 函数、S3 存储桶、DynamoDB 表、API 网关和消息服务。\n*   **自动化权限管理：** 其“链接”系统在资源（例如函数与数据库）连接时，自动配置 IAM 策略和环境变量。\n*   **开发者体验：** 提供用于本地 Lambda 测试的实时开发模式、支持完全自定义覆盖，并能与现有 Python 工具链（IDE、代码检查器）集成。\n\n该工具支持云应用所需的全套 AWS 组件，包括定时函数（Cron）、存储、数据库、消息服务（SQS/SNS）、电子邮件（SES）以及支持自定义域名路由的 REST API。\n\nStelvio 定位为简单脚本与复杂基础设施之间的桥梁，旨在让开发者同时获得开发速度和完全控制权，并在 Apache 2.0 许可下保持免费和开源。"
  }
]