[
  {
    "id": "46367224",
    "title": "Fabrice Bellard Releases MicroQuickJS",
    "url": "https://github.com/bellard/mquickjs/blob/main/README.md",
    "summary": "Fabrice Bellard has released MicroQuickJS (mquickjs), a new, ultra-compact JavaScript engine designed for embedded systems and constrained environments. As a stripped-down version of his QuickJS engine, it prioritizes minimal memory usage and a tiny binary size, making it suitable for microcontrollers and other low-resource hardware. Key features include support for the full ECMAScript 2020 specification, a compact runtime, and the ability to compile JavaScript to standalone executables. The project is open source and has quickly gained significant attention on GitHub, amassing over 700 stars. This release provides developers with a powerful tool for running modern JavaScript in extremely resource-limited contexts where engines like V8 or Node.js would be impractical.",
    "chinese_title": "法布里斯·贝拉发布MicroQuickJS",
    "chinese_summary": "法布里斯·贝拉发布了MicroQuickJS（mquickjs），这是一款专为嵌入式系统和受限环境设计的新型超紧凑JavaScript引擎。作为其QuickJS引擎的精简版本，它优先考虑最小内存占用和极小的二进制体积，适用于微控制器和其他低资源硬件。主要特性包括支持完整的ECMAScript 2020规范、紧凑的运行时环境，以及将JavaScript编译为独立可执行文件的能力。该项目是开源的，在GitHub上迅速获得了广泛关注，已收获超过700颗星。这一发布为开发者提供了在资源极度受限的环境中运行现代JavaScript的强大工具，而在这些环境中，像V8或Node.js这样的引擎将不切实际。"
  },
  {
    "id": "46367864",
    "title": "Volvo Centum is Dalton Maag's new typeface for Volvo",
    "url": "https://www.wallpaper.com/design-interiors/corporate-design-branding/volvo-new-font-volvo-centum",
    "summary": "Volvo has unveiled a new custom typeface, Volvo Centum, created by London-based studio Dalton Maag. Designed in preparation for the company's 100th anniversary in 2027, the sans-serif font aims to enhance safety and readability, particularly for glance-driven environments like in-car touchscreens.\n\nThe primary goal is to improve driver attention and promote a calmer experience through exceptional clarity and distinct character shapes. The typeface is engineered to function across multiple platforms, in various driving conditions, and support 35 languages, including Chinese and Arabic.\n\nThe newly refreshed Volvo XC60 and upcoming EX60 electric SUV will be the first vehicles to feature Volvo Centum, with plans to roll it out to millions of other cars via over-the-air updates. The font represents a design evolution for Volvo, seeking to address past criticisms about over-reliance on central touchscreens by improving the digital interface's legibility.",
    "chinese_title": "Volvo Centum是Dalton Maag为沃尔沃设计的新字体。",
    "chinese_summary": "沃尔沃发布了一款全新定制字体“Volvo Centum”，由伦敦工作室Dalton Maag设计。这款无衬线字体专为迎接公司2027年百年庆典而开发，旨在提升安全性和可读性，尤其适用于车载触摸屏等需快速识读的环境。\n\n其主要目标是通过出色的清晰度和独特的字形设计，增强驾驶员注意力并营造更从容的驾驶体验。该字体支持在多平台、各种驾驶条件下使用，并兼容包括中文和阿拉伯语在内的35种语言。\n\n全新升级的沃尔沃XC60及即将推出的EX60电动SUV将率先搭载Volvo Centum字体，后续计划通过空中升级技术推广至数百万辆其他车型。这款字体代表了沃尔沃的设计演进，旨在通过提升数字界面的易读性，回应此前对过度依赖中央触摸屏的批评。"
  },
  {
    "id": "46366998",
    "title": "Meta is using the Linux scheduler designed for Valve's Steam Deck on its servers",
    "url": "https://www.phoronix.com/news/Meta-SCX-LAVD-Steam-Deck-Server",
    "summary": "Meta is deploying a Linux scheduler originally developed for Valve's Steam Deck handheld gaming device across its server fleet. The scheduler, called SCX-LAVD (Latency-criticality Aware Virtual Deadline), was created by Igalia for Valve to optimize performance on the Steam Deck, offering similar or better performance than the standard EEVDF scheduler.\n\nMeta engineers presented their findings at the Linux Plumbers Conference 2025, detailing how they successfully adapted SCX-LAVD for large-scale server environments. They found it performs well across a wide range of hardware configurations and use cases, making it a versatile choice. As a result, Meta has adopted it as its new default fleet scheduler, built on the sched_ext framework, for servers where a specialized scheduler isn't required.\n\nKey benefits identified by Meta include effective performance across diverse CPU and memory setups and efficient load balancing between core complexes (CCX) and last-level caches (LLC). This case highlights how a scheduler designed for a specific consumer device can be effectively repurposed to meet the demands of hyperscale data center infrastructure.",
    "chinese_title": "Meta正在其服务器上使用为Valve的Steam Deck设计的Linux调度程序。",
    "chinese_summary": "Meta正在其服务器群中部署一款最初为Valve的Steam Deck掌上游戏设备开发的Linux调度器。这款名为SCX-LAVD（延迟关键性感知虚拟截止时间）的调度器由Igalia为Valve创建，旨在优化Steam Deck的性能，其表现与标准EEVDF调度器相当或更优。\n\nMeta工程师在2025年Linux Plumbers大会上展示了他们的研究成果，详细介绍了如何成功将SCX-LAVD适配于大规模服务器环境。他们发现该调度器在广泛的硬件配置和用例中表现优异，具备高度通用性。因此，Meta已将其作为基于sched_ext框架的新默认集群调度器，应用于无需专用调度器的服务器中。\n\nMeta指出的关键优势包括：在不同CPU和内存配置下均能实现高效性能，以及在核心复合体（CCX）与末级缓存（LLC）之间实现有效的负载均衡。这一案例表明，为特定消费设备设计的调度器能够成功改造，以满足超大规模数据中心基础设施的需求。"
  },
  {
    "id": "46368557",
    "title": "Terrence Malick's Disciples",
    "url": "https://yalereview.org/article/bilge-ebiri-terrence-malick",
    "summary": "This article argues that Terrence Malick is a profoundly influential figure in contemporary Hollywood, despite his divisive, non-commercial films. His impact is seen in a generation of directors who emulate his signature style and philosophical themes.\n\nKey filmmakers cited as his \"disciples\" include RaMell Ross (*Nickel Boys*), Chloé Zhao (*Nomadland*, *Eternals*), Clint Bentley (*Train Dreams*), David Gordon Green (*George Washington*), and Laura Dunn. Their work reflects Malick's core characteristics: a lyrical, impressionistic visual style using natural light; a focus on ordinary lives and the natural world to find transcendence; and an earnest, spiritual humanism that avoids irony.\n\nThe article explains Malick's appeal lies in offering an alternative to mainstream, effects-driven cinema and cynical independents. His working method—improvisational shooting and collage-like editing—prioritizes emotion and atmosphere over conventional narrative, which resonates with these directors. While his visual techniques are widely imitated, the article notes that the most successful disciples harmonize this style with Malick's core sensibility of finding grace and meaning in everyday existence.",
    "chinese_title": "泰伦斯·马利克的追随者",
    "chinese_summary": "本文认为，泰伦斯·马利克是当代好莱坞极具影响力的人物，尽管他的电影充满争议且非商业化。他的影响体现在一代效仿其标志性风格和哲学主题的导演身上。\n\n被视为其“门徒”的关键电影人包括拉梅尔·罗斯（《镍币男孩》）、赵婷（《无依之地》《永恒族》）、克林特·本特利（《火车梦》）、大卫·戈登·格林（《乔治·华盛顿》）以及劳拉·邓恩。他们的作品反映了马利克的核心特征：运用自然光的抒情式、印象派视觉风格；关注平凡生活与自然世界以寻求超越；以及一种真挚的、充满灵性的人文主义，避免反讽。\n\n文章指出，马利克的吸引力在于提供了一种不同于主流特效电影和愤世嫉俗独立电影的替代选择。他的工作方法——即兴拍摄和拼贴式剪辑——将情感与氛围置于传统叙事之上，这引起了这些导演的共鸣。尽管他的视觉技巧被广泛模仿，但文章强调，最成功的门徒将这种风格与马利克的核心情感——即在日常存在中发现优雅与意义——和谐地融为一体。"
  },
  {
    "id": "46367232",
    "title": "Towards a secure peer-to-peer app platform for Clan",
    "url": "https://clan.lol/blog/towards-app-platform-vmtech/",
    "summary": "This article outlines the Clan project's vision for a secure, user-controlled peer-to-peer app platform that aims to compete with commercial software. It identifies key shortcomings in current FOSS solutions, such as poor app isolation, difficulty running multiple instances, and complex server setup for decentralized apps.\n\nThe proposed solution is built on three core technologies:\n\n1.  **Nix**: For fast, reproducible software deployment and management.\n2.  **microVMs**: Using hardware virtualization (via projects like `muvm` and `libkrun`) for strong security, fast launch times, and consistent environments, moving beyond traditional heavy VMs.\n3.  **Desktop Integration**: Implementing advanced GPU virtualization (leveraging `virtio-gpu`, `rutabaga_gfx`, and DRM native contexts) for high-performance graphics and integrating XDG Desktop Portals (like D-Bus and PipeWire) to allow secure, controlled sharing of host resources (files, camera) with isolated guest apps.\n\nThe goal is to combine these elements into a platform where community apps can be installed quickly, are securely isolated, and are pre-connected to necessary network services for a seamless user experience. The work is ongoing, with current development focused on debugging and refining the GPU and portal integration stacks. An early implementation is available in the `munix` project.",
    "chinese_title": "迈向安全的Clan点对点应用平台",
    "chinese_summary": "本文概述了Clan项目的愿景：构建一个安全、用户控制的点对点应用平台，旨在与商业软件竞争。文章指出了当前自由开源软件解决方案的主要不足，例如应用隔离性差、难以运行多个实例以及去中心化应用的服务器设置复杂。\n\n提出的解决方案基于三项核心技术：\n\n1.  **Nix**：用于快速、可复现的软件部署与管理。\n2.  **微虚拟机**：利用硬件虚拟化（通过`muvm`和`libkrun`等项目）实现强安全性、快速启动和一致的环境，超越传统的重型虚拟机。\n3.  **桌面集成**：通过先进的GPU虚拟化（利用`virtio-gpu`、`rutabaga_gfx`和DRM原生上下文）实现高性能图形处理，并集成XDG桌面门户（如D-Bus和PipeWire），使隔离的客应用能够安全、受控地共享主机资源（文件、摄像头等）。\n\n目标是将这些要素整合为一个平台，使社区应用能够快速安装、安全隔离，并预先连接到必要的网络服务，从而提供无缝的用户体验。该项目仍在进行中，当前开发重点在于调试和完善GPU与门户集成堆栈。早期实现可在`munix`项目中查看。"
  },
  {
    "id": "46313962",
    "title": "Adobe Photoshop 1.0 Source Code (1990)",
    "url": "https://computerhistory.org/blog/adobe-photoshop-source-code/",
    "summary": "This article announces the Computer History Museum's acquisition and release of the original source code for Adobe Photoshop 1.0 (1990). Written by the Museum's Chairman, Leonard Shustek, it explains the code's historical significance as a landmark in software development that revolutionized digital imaging.\n\nThe summary highlights that the code, written primarily for the Apple Macintosh, showcases early programming ingenuity, such as its custom memory management to work within the Mac's 128KB RAM limit. It also reveals that the application was originally named \"Display\" and was created by Thomas Knoll as a personal project before evolving into a commercial product with his brother John Knoll's involvement.\n\nThe article concludes by noting that the source code is available for non-commercial use, allowing researchers, educators, and enthusiasts to study this foundational piece of software history.",
    "chinese_title": "Adobe Photoshop 1.0 源代码（1990年）",
    "chinese_summary": "本文宣布计算机历史博物馆获得并发布了Adobe Photoshop 1.0（1990年）的原始源代码。由博物馆主席伦纳德·舒斯特克撰写，文章阐释了这段代码作为软件开发里程碑的历史意义，它彻底改变了数字影像处理。\n\n摘要强调，这段主要为苹果麦金塔电脑编写的代码展示了早期的编程智慧，例如其自定义内存管理技术，以在麦金塔128KB内存限制下运行。文章还透露，该应用程序最初名为“Display”，由托马斯·诺尔作为个人项目创建，后来在其兄弟约翰·诺尔的参与下演变为商业产品。\n\n文章最后指出，该源代码可供非商业用途使用，使研究人员、教育工作者和爱好者能够研究这一软件历史上的奠基之作。"
  },
  {
    "id": "46367475",
    "title": "We replaced H.264 streaming with JPEG screenshots (and it worked better)",
    "url": "https://blog.helix.ml/p/we-mass-deployed-15-year-old-screen",
    "summary": "**Summary of \"We replaced H.264 streaming with JPEG screenshots (and it worked better)\"**\n\nThe article details how the team at Helix (a machine learning platform) replaced a complex, modern video streaming system (using H.264) with a simpler approach of rapidly sending sequential JPEG screenshots for their browser-based remote desktop feature.\n\nFacing challenges with the H.264 pipeline—including high latency, instability, and complexity across diverse client environments—the team sought a more robust solution. They discovered that by using the `libvips` library to generate highly optimized JPEGs from screen captures and sending them via WebSocket, they could achieve better performance.\n\nThe key to making this \"old\" technique viable was aggressive optimization: using GPU acceleration for capture and encoding, differential updates (only sending changed parts of the screen), and efficient compression. This JPEG-based approach resulted in **lower latency, higher reliability, and reduced system complexity** compared to the video codec pipeline. It proved particularly effective for their use case of streaming typical developer desktop applications (like IDEs and terminals), which often have static regions and benefit from the method's simplicity.\n\nThe core takeaway is that for certain applications—especially where ultra-low latency and robustness are prioritized over extreme bandwidth efficiency for dynamic content—a well-optimized \"slideshow\" of JPEGs can outperform a traditional video streaming solution. The article advocates questioning default technology choices and fitting the solution to the specific problem.",
    "chinese_title": "我们将H.264流媒体替换为JPEG截图（效果反而更佳）",
    "chinese_summary": "**《我们如何用JPEG截图替代H.264流媒体（效果反而更好）》摘要**\n\n文章详述了Helix（一个机器学习平台）团队如何为其基于浏览器的远程桌面功能，用快速发送连续JPEG截图的简单方案，替代了复杂现代的H.264视频流系统。\n\n面对H.264方案的高延迟、不稳定及跨多样客户端环境复杂性等挑战，团队寻求更稳健的解决方案。他们发现，通过使用`libvips`库从屏幕捕获生成高度优化的JPEG，并通过WebSocket传输，反而能获得更佳性能。\n\n使这一“传统”技术可行的关键在于极致优化：采用GPU加速捕获与编码、差分更新（仅发送屏幕变化部分）及高效压缩。与视频编解码方案相比，这种基于JPEG的方法实现了**更低延迟、更高可靠性和更低的系统复杂度**。对于其典型开发者桌面应用（如IDE和终端）的流式传输场景尤为有效，因为这些应用常包含静态区域，且得益于该方案的简洁性。\n\n核心启示是：对于某些应用场景——尤其是当超低延迟和稳健性优先于动态内容的极致带宽效率时——精心优化的JPEG“幻灯片放映”方案可以超越传统视频流解决方案。文章提倡质疑默认的技术选择，让解决方案契合具体问题。"
  },
  {
    "id": "46363360",
    "title": "Instant database clones with PostgreSQL 18",
    "url": "https://boringsql.com/posts/instant-database-clones/",
    "summary": "This article explains how to leverage PostgreSQL 18's new `file_copy_method = clone` feature to create instant, space-efficient database clones using copy-on-write filesystem capabilities.\n\nThe core mechanism builds on PostgreSQL's existing `CREATE DATABASE ... TEMPLATE` command. While the default `WAL_LOG` strategy is safe but slow for large databases, the `FILE_COPY` strategy can be accelerated by modern filesystems like XFS, ZFS, or APFS. When configured with `clone`, the operation uses system-level reflinks, creating a new database that shares the same physical data blocks as the source in milliseconds, without consuming additional disk space.\n\nThe article demonstrates a dramatic performance improvement: cloning a 6GB database took over a minute with `WAL_LOG` but only 212 milliseconds with `FILE_COPY` and `clone`. It clarifies that while logical size reports remain identical, physical divergence occurs only when data is modified, triggering copy-on-write at the page level.\n\nKey limitations are noted: the source database cannot have active connections during cloning, the operation is restricted to a single filesystem, and it's generally unavailable in managed cloud services. The feature is best suited for development, testing, or creating snapshots from a dedicated template on self-managed infrastructure.",
    "chinese_title": "PostgreSQL 18 即时数据库克隆功能",
    "chinese_summary": "本文介绍了如何利用PostgreSQL 18新增的`file_copy_method = clone`功能，通过写时复制文件系统特性创建即时、节省空间的数据库克隆。\n\n该机制基于PostgreSQL现有的`CREATE DATABASE ... TEMPLATE`命令。虽然默认的`WAL_LOG`策略对大型数据库安全但缓慢，而`FILE_COPY`策略可借助XFS、ZFS或APFS等现代文件系统加速。当配置为`clone`时，操作会利用系统级重链接技术，在毫秒级内创建与源数据库共享物理数据块的新数据库，且不占用额外磁盘空间。\n\n文章展示了显著的性能提升：克隆6GB数据库时，`WAL_LOG`策略耗时超过一分钟，而`FILE_COPY`配合`clone`仅需212毫秒。文中阐明，虽然逻辑大小报告保持不变，但仅当数据被修改时才会发生物理分离，并在页面级别触发写时复制。\n\n关键限制包括：克隆期间源数据库不能存在活动连接，操作仅限于单个文件系统，且通常不适用于托管云服务。该功能最适合在自主管理的基础设施中用于开发、测试或从专用模板创建快照。"
  },
  {
    "id": "46364973",
    "title": "Test, don't (just) verify",
    "url": "https://alperenkeles.com/posts/test-dont-verify/",
    "summary": "This article examines the growing role of AI in formal verification and argues for a balanced approach that integrates testing.\n\nThe author acknowledges the promise of AI-assisted formal verification, which can prove the absence of bugs and is being accelerated by AI's ability to generate and check proofs. However, significant challenges remain. Most software lacks formal specifications, and autoformalization (turning informal descriptions into formal ones) introduces a critical point of potential error. Proof assistants can be slow for practical use, and creating accurate mathematical models for complex systems (like hardware performance) is extremely difficult. Furthermore, verification alone cannot efficiently identify when a sought-after property is actually false.\n\nThe article concludes that testing remains indispensable. It complements verification by providing falsification through tools like random testing, which can quickly find counterexamples. The author advocates for Verification-Guided Development (VGD), a hybrid methodology. VGD involves creating a simple, verified reference implementation and a complex, optimized production version, then using differential testing to ensure they behave identically. This approach leverages the certainty of verification for the core logic while using testing to bridge the gap to efficient, real-world code.",
    "chinese_title": "测试，而非（仅）验证",
    "chinese_summary": "本文探讨了人工智能在形式化验证中日益重要的作用，并主张采用一种结合测试的平衡方法。\n\n作者肯定了人工智能辅助形式化验证的前景，它能够证明程序无缺陷，并借助人工智能生成和检查证明的能力加速这一过程。然而，重大挑战依然存在。大多数软件缺乏形式化规范，而自动形式化（将非正式描述转化为形式化描述）引入了潜在错误的关键点。证明辅助工具在实际应用中可能速度缓慢，为复杂系统（如硬件性能）创建精确的数学模型也极为困难。此外，仅靠验证无法有效识别所寻求的属性何时实际为假。\n\n文章结论认为测试仍然不可或缺。它通过随机测试等工具提供证伪，快速找到反例，从而与验证形成互补。作者提倡一种混合方法——验证引导开发（VGD）。VGD包括创建一个简单、经过验证的参考实现和一个复杂、优化的生产版本，然后使用差分测试确保两者行为一致。这种方法利用验证对核心逻辑的确定性，同时通过测试弥合与高效实际代码之间的差距。"
  },
  {
    "id": "46330012",
    "title": "Astrophotography Target Planner: Discover Hidden Nebulas",
    "url": "https://astroimagery.com/techniques/imaging/astrophotography-target-planner/",
    "summary": "This article introduces an astrophotography target planner app designed to help backyard astronomers discover lesser-known deep-sky objects. The author, Karl Perera, built the tool out of frustration with the time-consuming manual process of using planetarium software, which often led him to repeatedly image the same popular targets like the Andromeda Galaxy.\n\nThe core function of the app is to streamline planning by filtering objects based on the user's location, sky conditions (Bortle scale), focal length, and camera sensor. It then provides a tailored list of viable targets for a given night, complete with optimal imaging times, coordinates, framing previews, and difficulty ratings.\n\nA key feature highlighted is \"Discovery Mode,\" which specifically surfaces hidden gems like NGC 7822 or the Question Mark Nebula—photogenic but often overlooked objects suitable for amateur gear. The author credits this tool with expanding his personal catalog from about 10 repeat targets to over 40 different objects in a year by reducing planning time from over 13 minutes to under 90 seconds.\n\nThe app is currently in free beta, optimized for the Northern Hemisphere, and the author invites user feedback for further development.",
    "chinese_title": "天文摄影目标规划器：探索隐藏的星云",
    "chinese_summary": "本文介绍了一款专为后院天文爱好者设计的深空天体拍摄规划应用，旨在帮助用户发现鲜为人知的深空目标。开发者卡尔·佩雷拉因受困于使用天文馆软件时耗时繁琐的手动规划流程而创建此工具——过去他常因规划效率低下反复拍摄如仙女座星系等热门目标。\n\n该应用的核心功能是通过用户地理位置、天空条件（波特尔暗空分类）、焦距和相机传感器参数筛选天体，从而简化规划流程。它会为特定观测夜生成定制化的可行目标列表，包含最佳拍摄时间、坐标、构图预览图和拍摄难度评级。\n\n文中重点介绍了“探索模式”，该功能专门推荐像NGC 7822或问号星云这类被忽视的拍摄宝藏——这些适合业余设备拍摄的上镜天体往往鲜少进入常规观测清单。开发者表示，借助此工具将规划时间从超过13分钟缩短至90秒内，使他的个人拍摄目标库在一年内从约10个重复对象扩展到40多个不同天体。\n\n该应用目前提供免费测试版，主要针对北半球优化，开发者诚邀用户反馈以推动后续开发。"
  },
  {
    "id": "46312621",
    "title": "Executorch: On-device AI across mobile, embedded and edge for PyTorch",
    "url": "https://github.com/pytorch/executorch",
    "summary": "ExecuTorch is PyTorch's official solution for deploying AI models directly on mobile, embedded, and edge devices. It enables developers to export PyTorch models natively—without converting to intermediate formats like ONNX—and run them efficiently across a wide range of hardware, from microcontrollers to smartphones.\n\nKey features include a tiny runtime (~50KB), support for over 12 hardware backends (including Apple, Qualcomm, ARM, and Vulkan), and the ability to switch deployment targets with minimal code changes. The workflow involves exporting a model via `torch.export`, optimizing and partitioning it for specific hardware, and then executing the compiled `.pte` file using a lightweight C++ runtime on the device.\n\nExecuTorch is production-proven, powering on-device AI in Meta apps like Instagram and WhatsApp, as well as devices like Quest 3 and Ray-Ban Meta Smart Glasses. It supports various model types, including LLMs (like Llama), vision, speech, and multimodal models, with built-in tools for quantization and memory optimization. The framework is open-source, BSD-licensed, and backed by extensive documentation and a community for support and contributions.",
    "chinese_title": "Executorch：面向PyTorch的移动端、嵌入式与边缘设备端侧AI平台",
    "chinese_summary": "ExecuTorch是PyTorch官方推出的解决方案，用于将AI模型直接部署到移动设备、嵌入式系统和边缘设备上。它允许开发者原生导出PyTorch模型——无需转换为ONNX等中间格式——并能在从微控制器到智能手机的广泛硬件上高效运行。\n\n其关键特性包括极小的运行时（约50KB）、支持超过12种硬件后端（包括Apple、Qualcomm、ARM和Vulkan），以及只需少量代码修改即可切换部署目标。工作流程包括通过`torch.export`导出模型，针对特定硬件进行优化与分区，然后在设备上使用轻量级C++运行时执行编译后的`.pte`文件。\n\nExecuTorch已通过生产验证，为Instagram和WhatsApp等Meta应用以及Quest 3和Ray-Ban Meta智能眼镜等设备提供端侧AI支持。它支持多种模型类型，包括大语言模型（如Llama）、视觉、语音和多模态模型，并内置量化与内存优化工具。该框架采用开源BSD许可证，提供详尽的文档支持，并拥有活跃的社区供开发者交流与贡献。"
  },
  {
    "id": "46367744",
    "title": "An initial analysis of the discovered Unix V4 tape",
    "url": "https://www.spinellis.gr/blog/20251223/?yc261223",
    "summary": "In December 2025, Diomidis Spinellis analyzed the source code from a recently discovered 1970s magnetic tape containing Unix Fourth Edition (V4). He integrated the code into the Unix History Repository on GitHub, removing binaries to focus on source files.\n\nTo address claims that the tape's contents were very similar to the later Fifth Edition (V5), Spinellis performed a comparative analysis. He found that while the core file sets were largely the same, V5 introduced several new compiler files and a C-based `cmp` utility. A deeper `git blame` analysis revealed that V4 contained over 75,000 lines of code, with about 10% inherited from earlier editions. V5 reused 52,000 lines from V4 but also added about 11,000 new lines, indicating significant development.\n\nFurthermore, an analysis of average file timestamps showed that V4 (March 1974) preceded V5 (November 1974) by about eight months, confirming it as a distinct and earlier snapshot in Unix's rapid evolution. The work also helped refine the historical record by updating author attribution with help from original Bell Labs developers.",
    "chinese_title": "对发现的Unix V4磁带进行初步分析",
    "chinese_summary": "2025年12月，迪奥米迪斯·斯皮内利斯分析了最近发现的一盘1970年代磁带中的源代码，其中包含Unix第四版（V4）。他将代码整合到GitHub上的Unix历史代码库中，移除了二进制文件以专注于源文件。\n\n针对该磁带内容与后来第五版（V5）高度相似的说法，斯皮内利斯进行了对比分析。他发现，虽然核心文件集大体相同，但V5引入了若干新的编译器文件和一个基于C语言的`cmp`实用工具。更深入的`git blame`分析显示，V4包含超过75,000行代码，其中约10%继承自更早版本。V5复用了V4的52,000行代码，同时新增约11,000行，表明其间存在显著开发进展。\n\n此外，对文件平均时间戳的分析表明，V4（1974年3月）比V5（1974年11月）早约八个月，证实了它是Unix快速演进过程中一个独立且更早的版本快照。这项工作还借助贝尔实验室原开发者的帮助更新了作者归属信息，从而完善了历史记录。"
  },
  {
    "id": "46364131",
    "title": "Font with Built-In Syntax Highlighting (2024)",
    "url": "https://blog.glyphdrawing.club/font-with-built-in-syntax-highlighting/",
    "summary": "This article introduces a novel approach to syntax highlighting for hand-coded websites by embedding the highlighting logic directly into a font file. The author's goal was to eliminate the need for external JavaScript libraries like Prism or highlight.js, which add complexity and bloat.\n\nThe method leverages two OpenType features: the **COLR table** for multi-colored glyphs and **contextual alternates** for pattern-based text substitution. The author modified the Monaspace Krypton font, creating colored alternate glyphs and writing OpenType rules to identify and color-code keywords, functions, and other syntax elements for HTML, CSS, and JavaScript.\n\nKey advantages include:\n*   **Simplicity:** It works by simply applying the custom font via CSS, with no JavaScript required.\n*   **Clean HTML:** Code snippets remain plain text without injected `<span>` tags.\n*   **Unique capability:** It enables syntax highlighting even inside `<textarea>` and `<input>` elements, which was previously impossible.\n\nHowever, the approach has limitations:\n*   **Limited flexibility:** Modifying the syntax rules or adding new languages requires editing the font file itself, a specialized skill.\n*   **Basic pattern matching:** It cannot match the power of regex-based highlighters and can incorrectly highlight keywords in non-code contexts (e.g., within prose).\n*   **Platform dependency:** It only works where OpenType features are supported.\n\nIn summary, this is a creative proof-of-concept that offers a lightweight, script-free alternative for basic syntax highlighting, particularly valuable for its ability to highlight editable text areas, but it is not a full replacement for traditional highlighter libraries.",
    "chinese_title": "内置语法高亮字体（2024）",
    "chinese_summary": "本文介绍了一种为手工编码网站实现语法高亮的新方法，通过将高亮逻辑直接嵌入字体文件。作者的目标是消除对Prism或highlight.js等外部JavaScript库的依赖，这些库会增加复杂性和冗余。\n\n该方法利用了两种OpenType特性：用于多色字形的**COLR表**和用于基于模式的文本替换的**上下文替代字形**。作者修改了Monaspace Krypton字体，创建了彩色替代字形，并编写了OpenType规则来识别HTML、CSS和JavaScript中的关键字、函数及其他语法元素，并进行颜色编码。\n\n主要优势包括：\n*   **简洁性：** 仅需通过CSS应用自定义字体即可工作，无需JavaScript。\n*   **HTML代码纯净：** 代码片段保持纯文本格式，无需注入`<span>`标签。\n*   **独特能力：** 它甚至能在`<textarea>`和`<input>`元素内实现语法高亮，这在以前是不可能的。\n\n然而，该方法也存在局限性：\n*   **灵活性有限：** 修改语法规则或添加新语言需要编辑字体文件本身，这是一项专业技能。\n*   **基础模式匹配：** 它无法匹敌基于正则表达式的高亮工具，并可能在非代码上下文（例如散文）中错误高亮关键字。\n*   **平台依赖性：** 它仅在支持OpenType特性的环境中有效。\n\n总之，这是一个创造性的概念验证，为基本语法高亮提供了一个轻量级、无需脚本的替代方案，尤其因其能够高亮可编辑文本区域而具有价值，但它并非传统高亮库的完全替代品。"
  },
  {
    "id": "46338480",
    "title": "Space Math Academy",
    "url": "https://space-math.academy",
    "summary": "**Summary of \"SpaceMath: Mission Control\"**\n\nThis article introduces \"SpaceMath: Mission Control,\" a hypothetical educational program or initiative designed to teach mathematics through the engaging context of space exploration.\n\nThe core concept is to frame math problems and learning modules as mission-critical tasks for a space agency. Students would take on roles like flight controllers, engineers, or scientists, applying mathematical concepts—such as calculating orbital trajectories, fuel consumption, communication delays, or life support system metrics—to solve practical challenges.\n\nThe key objective is to increase student engagement and comprehension by demonstrating the real-world, high-stakes application of math. By embedding algebra, geometry, calculus, and physics within compelling space mission scenarios, the program aims to move beyond abstract theory and show math as an essential tool for problem-solving.\n\nThe article likely positions SpaceMath as an innovative approach to STEM education, seeking to inspire the next generation of scientists, engineers, and mathematicians by connecting curriculum to the excitement of space discovery.",
    "chinese_title": "太空数学学院",
    "chinese_summary": "**《太空数学：任务控制》概要**\n\n本文介绍了“太空数学：任务控制”，这是一个假设性的教育项目或倡议，旨在通过引人入胜的太空探索情境来教授数学。\n\n其核心理念是将数学问题和学习模块构建为航天机构的关键任务。学生将扮演飞行控制员、工程师或科学家等角色，运用数学概念——例如计算轨道轨迹、燃料消耗、通信延迟或生命支持系统指标——来解决实际挑战。\n\n主要目标是通过展示数学在现实世界高风险场景中的应用，来提高学生的参与度和理解力。该项目将代数、几何、微积分和物理学融入引人入胜的太空任务情境中，旨在超越抽象理论，展示数学作为解决问题的重要工具。\n\n文章很可能将“太空数学”定位为STEM教育的一种创新方法，试图通过将课程与激动人心的太空探索联系起来，激励下一代科学家、工程师和数学家。"
  },
  {
    "id": "46335069",
    "title": "The post-GeForce era: What if Nvidia abandons PC gaming?",
    "url": "https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html",
    "summary": "This article explores the possibility of Nvidia significantly reducing its focus on PC gaming hardware due to the overwhelming financial dominance of its AI data center business. In its latest quarter, data centers generated $51.2 billion in revenue compared to just $4.3 billion from gaming, making gaming a minor part of its portfolio.\n\nThe author presents a hypothetical future where high-end gaming GPUs become prohibitively expensive and scarce, partly due to AI-driven memory shortages inflating component costs. Instead, Nvidia could pivot toward promoting its GeForce Now cloud gaming subscription service as the primary way to access high-performance graphics.\n\nThe piece draws parallels to companies like IBM and Adobe, which shifted from products to services, suggesting Nvidia might spin off or de-emphasize its gaming hardware division. While gaming itself won't disappear, the business model may fundamentally change from consumer hardware ownership to cloud-based subscription services, mirroring trends in other media industries. The core argument is that as AI revenue skyrockets, it becomes increasingly difficult for Nvidia to justify major investment in the lower-margin gaming GPU market.",
    "chinese_title": "后GeForce时代：如果英伟达放弃PC游戏会怎样？",
    "chinese_summary": "本文探讨了英伟达因其人工智能数据中心业务的压倒性财务优势而大幅减少对PC游戏硬件关注的可能性。在最新季度，数据中心创造了512亿美元的收入，而游戏业务仅为43亿美元，使游戏成为其业务组合中的次要部分。\n\n作者设想了一个未来场景：高端游戏GPU可能因价格过高而变得稀缺，部分原因是人工智能驱动的内存短缺推高了组件成本。相反，英伟达可能转向推广其GeForce Now云游戏订阅服务，将其作为获取高性能图形体验的主要方式。\n\n文章类比了IBM和Adobe等从产品转向服务模式的公司，暗示英伟达可能会剥离或弱化其游戏硬件部门。虽然游戏本身不会消失，但商业模式可能从消费者硬件拥有权转变为基于云的订阅服务，这与其他媒体行业的发展趋势相似。核心论点是：随着人工智能收入飙升，英伟达越来越难以为利润率较低的游戏GPU市场进行重大投资提供合理依据。"
  },
  {
    "id": "46360856",
    "title": "Local AI is driving the biggest change in laptops in decades",
    "url": "https://spectrum.ieee.org/ai-models-locally",
    "summary": "Local AI is driving a fundamental redesign of laptop hardware and software. Currently, most laptops lack the power to run sophisticated large language models (LLMs) locally, relying instead on cloud data centers. To enable local AI, manufacturers are integrating specialized Neural Processing Units (NPUs) for efficient, low-power AI computations, sparking a performance race measured in trillions of operations per second (TOPS).\n\nBeyond NPUs, a critical shift is toward unified memory architectures. Traditional laptops split memory between the CPU and GPU, creating inefficiencies for AI models that require large, contiguous memory pools. New systems-on-a-chip (like AMD's Ryzen AI Max and upcoming Intel-Nvidia collaborations) integrate the CPU, GPU, and NPU on one piece of silicon with shared memory, boosting performance and power management but making upgrades more difficult.\n\nThis hardware evolution is matched by software initiatives. Microsoft's Copilot+ PC push and its AI Foundry Local platform provide developers with tools and a catalog of models to build applications that run AI locally, automatically directing tasks to the optimal hardware (CPU, GPU, or NPU). The goal is to deliver faster, more private, and power-efficient AI experiences directly on the device, marking the most significant change to laptop design in decades.",
    "chinese_title": "本地人工智能正推动几十年来笔记本电脑领域的最大变革。",
    "chinese_summary": "本地AI正在推动笔记本电脑硬件与软件的根本性重新设计。目前，大多数笔记本电脑缺乏本地运行复杂大型语言模型（LLM）的能力，只能依赖云端数据中心。为了实现本地AI，制造商正在集成专用的神经处理单元（NPU）以进行高效、低功耗的AI计算，从而引发了一场以每秒万亿次操作（TOPS）为衡量标准的性能竞赛。\n\n除了NPU之外，一个关键转变是向统一内存架构发展。传统笔记本电脑在CPU和GPU之间分割内存，导致需要大量连续内存池的AI模型效率低下。新的片上系统（如AMD的Ryzen AI Max以及即将推出的英特尔-英伟达合作产品）将CPU、GPU和NPU集成在一块芯片上，并共享内存，从而提升了性能和功耗管理能力，但也使得升级更加困难。\n\n与硬件演进相匹配的是软件方面的举措。微软的Copilot+ PC推广及其AI Foundry Local平台为开发者提供了工具和模型目录，以构建可在本地运行AI的应用程序，并自动将任务分配给最优硬件（CPU、GPU或NPU）。其目标是在设备上直接提供更快、更私密且更节能的AI体验，这标志着几十年来笔记本电脑设计中最重大的变革。"
  },
  {
    "id": "46330369",
    "title": "The Coffee Warehouse",
    "url": "https://www.scopeofwork.net/the-coffee-warehouse/",
    "summary": "This article compares Starbucks' operational challenges to warehouse logistics, focusing on how the company manages order complexity. Starbucks is facing declining sales and aims to improve wait times, a key initiative under new leadership. A major source of difficulty is its three sales channels—walk-in, drive-thru, and mobile orders—which are all processed in a simple first-in, first-out sequence. This system creates inefficiencies, as baristas may prepare drinks for mobile customers who haven't arrived while in-store customers wait.\n\nThe author draws a parallel to warehouse operations, suggesting Starbucks could apply similar principles to optimize flow. These include: prioritizing \"urgent\" orders (like those from customers already present), processing all components of a single order simultaneously to keep items together and reduce errors, and batching similar drink orders to increase speed and accuracy through task repetition.\n\nThe core argument is that mobile orders, while convenient, introduce a valuable delay between order placement and customer arrival. This window presents an opportunity for Starbucks to intelligently re-sequence work—departing from a strict first-come, first-served model—to improve efficiency, reduce wait times, and enhance the customer experience.",
    "chinese_title": "咖啡仓库",
    "chinese_summary": "本文以仓库物流类比星巴克的运营挑战，聚焦于该公司如何应对订单复杂性。星巴克正面临销售额下滑，并在新任领导层推动下将缩短等待时间作为关键改进目标。其运营困境的主要根源在于三大销售渠道——堂食、汽车餐厅和手机订单——均采用简单的先到先得顺序处理。这种系统导致效率低下：咖啡师可能为尚未到店的手机用户备餐，而店内顾客却仍在等待。\n\n作者通过类比仓库运营提出，星巴克可借鉴类似原则优化流程。具体包括：优先处理“紧急”订单（如已到店顾客的订单）；同步处理同一订单的所有组成部分以保持餐品完整、减少差错；将相似饮品的订单批量处理，通过任务重复提升速度与准确性。\n\n核心观点在于：手机订单虽带来便利，却在下单与取餐之间创造了宝贵的延迟窗口。星巴克可借此机会智能调整工作顺序——突破严格遵循先到先得的模式——从而提升运营效率、缩短等待时间并优化顾客体验。"
  },
  {
    "id": "46363319",
    "title": "10 years bootstrapped: €6.5M revenue with a team of 13",
    "url": "https://www.datocms.com/blog/a-look-back-at-2025",
    "summary": "In 2025, DatoCMS, a bootstrapped headless CMS, achieved €6.5 million in revenue with a lean team of 13, marking a decade in business. The company reported strong 10% year-over-year growth and an exceptional 65% EBIT margin, far exceeding typical SaaS benchmarks.\n\nKey achievements included significant product enhancements focused on developer experience (like full type safety), content editing (such as inline blocks), and AI readiness (including bulk translations). The partner network grew to 185 agencies, and the public plugin ecosystem expanded.\n\nThe year's major technical milestone was a complete infrastructure migration from Heroku to a custom AWS Kubernetes setup. This move halved API response times, increased capacity, and reduced overall infrastructure costs by over 25%, while granting full operational control.\n\nFinancially, the company also brought accounting in-house for greater visibility. Throughout, DatoCMS emphasized its philosophy of sustainable, profitable growth without external funding, prioritizing product quality and team well-being over rapid scaling.",
    "chinese_title": "10年自筹资金：13人团队实现650万欧元营收",
    "chinese_summary": "2025年，自筹资金的无头CMS平台DatoCMS以13人的精干团队实现650万欧元营收，迎来创业十周年。公司年同比增长率达10%，EBIT利润率高达65%，远超SaaS行业常规标准。\n\n年度重要成果包括聚焦开发者体验（如全类型安全）、内容编辑（如内联区块）和AI就绪（含批量翻译）的重大产品升级。合作伙伴网络扩展至185家机构，公开插件生态持续壮大。\n\n全年关键技术里程碑是从Heroku到定制化AWS Kubernetes架构的完整基础设施迁移。此举使API响应时间减半，承载能力提升，整体基础设施成本降低超25%，同时获得完全自主运维控制权。\n\n财务方面，公司通过内部会计体系提升财务透明度。DatoCMS始终秉持无需外部融资的可持续盈利增长理念，坚持将产品质量与团队福祉置于快速扩张之上。"
  },
  {
    "id": "46361229",
    "title": "Snitch – A friendlier ss/netstat",
    "url": "https://github.com/karol-broda/snitch",
    "summary": "**Snitch** is a user-friendly command-line tool designed as an alternative to `ss` and `netstat` for inspecting network connections. It offers a clean, interactive TUI (Terminal User Interface) and styled table outputs for easier readability.\n\n**Key Features:**\n*   **Interactive TUI (`snitch`):** A live-updating interface with keybindings for navigation, filtering (by protocol, state), sorting, process monitoring, and killing connections.\n*   **One-shot Output (`snitch ls`):** Prints a formatted table of connections, with options for plain, JSON, or CSV output for scripting.\n*   **Flexible Filtering:** Supports quick flags (e.g., `-l` for listening sockets) and key-value filters (e.g., `proc=nginx`).\n*   **Multiple Installation Methods:** Available via Go install, Nix, AUR (Arch Linux), a shell script, or direct binary download for Linux and macOS.\n*   **Cross-Platform:** Works on Linux (using `/proc/net/`) and macOS (using system APIs). Root/sudo may be needed for full process details.\n\n**Quick Commands:**\n*   `snitch` launches the interactive TUI.\n*   `snitch ls` prints a styled connection table.\n*   `snitch json` outputs data in JSON format for scripts.\n\nThe tool prioritizes a human-readable experience while maintaining the power needed for network diagnostics.",
    "chinese_title": "Snitch – 更友好的 ss/netstat 工具",
    "chinese_summary": "**Snitch** 是一款用户友好的命令行工具，旨在替代 `ss` 和 `netstat` 用于检查网络连接。它提供简洁的交互式 TUI（终端用户界面）和风格化的表格输出，便于阅读。\n\n**主要特性：**\n*   **交互式 TUI (`snitch`):** 实时更新的界面，支持通过快捷键进行导航、过滤（按协议、状态）、排序、进程监控和终止连接。\n*   **单次输出 (`snitch ls`):** 打印格式化的连接表格，支持纯文本、JSON 或 CSV 输出，便于脚本处理。\n*   **灵活过滤:** 支持快速标志（例如 `-l` 用于监听套接字）和键值过滤器（例如 `proc=nginx`）。\n*   **多种安装方式:** 可通过 Go install、Nix、AUR（Arch Linux）、Shell 脚本或直接下载二进制文件在 Linux 和 macOS 上安装。\n*   **跨平台:** 支持 Linux（使用 `/proc/net/`）和 macOS（使用系统 API）。可能需要 root/sudo 权限以获取完整的进程详情。\n\n**快速命令:**\n*   `snitch` 启动交互式 TUI。\n*   `snitch ls` 打印风格化的连接表格。\n*   `snitch json` 以 JSON 格式输出数据，供脚本使用。\n\n该工具优先考虑人类可读的体验，同时保持网络诊断所需的强大功能。"
  },
  {
    "id": "46363751",
    "title": "Carnap – A formal logic framework for Haskell",
    "url": "https://carnap.io/",
    "summary": "**Carnap** is a free, open-source software framework built with the Haskell programming language, designed specifically for teaching and studying formal logic. It serves as the educational platform for logic courses at numerous colleges and universities globally.\n\nThe primary audience is students enrolled in courses that utilize Carnap, who can log in via the website to access their specific course materials and exercises. For general visitors, the project provides an about page with further information.\n\nThe framework is also promoted to educators and contributors. Instructors interested in adopting Carnap for their own classes, as well as individuals wanting to contribute to the project's development, are encouraged to make contact. In summary, Carnap is a Haskell-based, educational tool that functions both as a student learning platform and an open project welcoming academic collaboration.",
    "chinese_title": "卡尔纳普——一个用于Haskell的形式逻辑框架",
    "chinese_summary": "**Carnap** 是一款基于 Haskell 编程语言构建的免费开源软件框架，专为形式逻辑的教学与研究而设计。它作为全球众多高校逻辑课程的教育平台，主要服务于使用 Carnap 课程的学生，他们可通过网站登录以获取特定课程资料与练习。普通访客则可浏览项目简介页面了解更多信息。\n\n该框架也面向教育工作者和贡献者推广。欢迎有意在教学中采用 Carnap 的教师，以及希望参与项目开发的各界人士联系合作。总之，Carnap 是一款基于 Haskell 的教育工具，既是学生的学习平台，也是一个欢迎学术协作的开放项目。"
  },
  {
    "id": "46352191",
    "title": "Dancing around the rhythm space with Euclid",
    "url": "https://pv.wtf/posts/euclidean-rhythms",
    "summary": "This article details the author's exploration of rhythm generation, moving from standard Euclidean rhythms to more experimental \"Non-Euclidean\" patterns. Euclidean rhythms algorithmically distribute a set number of hits evenly across a pattern's length, creating familiar, globally recognized grooves. However, the author found their evenness could become repetitive.\n\nTo introduce more variation and syncopation for live improvisation, the author experimented with algorithms that create uneven, clustered hit patterns (anti-Euclidean rhythms). A key discovery was that interpolating between a Euclidean rhythm and a clustered version allowed for interesting exploration of \"rhythm space\" while maintaining musicality.\n\nThese experiments culminated in a custom-built web-based sequencer. Its core features let users control the density (number of hits) and the \"distance\" from a Euclidean pattern for up to four parts, which can be layered or sequenced. Additional elements like rotation, inversion, and a Turing machine-inspired pitch generator provide further creative control. The author suggests this tool bridges the gap between quick, generative inspiration and intentional musical shaping, with potential future development as a VCV Rack plugin or a WebMIDI instrument.",
    "chinese_title": "与欧几里得共舞于韵律空间",
    "chinese_summary": "本文详细阐述了作者对节奏生成的探索，从标准的欧几里得节奏转向更具实验性的“非欧几里得”模式。欧几里得节奏通过算法将一定数量的击打均匀分布在节奏长度上，创造出熟悉且全球公认的律动。然而，作者发现其均匀性可能变得重复。\n\n为了在即兴演奏中引入更多变化和切分音，作者尝试了能产生不均匀、集群式击打模式的算法（反欧几里得节奏）。一个关键发现是，在欧几里得节奏与集群化版本之间进行插值，可以在保持音乐性的同时，实现对“节奏空间”的有趣探索。\n\n这些实验最终形成了一个定制的基于网络的音序器。其核心功能让用户最多可为四个声部控制密度（击打数量）以及与欧几里得模式的“距离”，这些声部可以分层或按序排列。额外的元素，如旋转、倒置以及受图灵机启发的音高生成器，提供了进一步的创作控制。作者认为，这个工具在快速的生成式灵感与有意识的音乐塑造之间架起了桥梁，未来有潜力开发为VCV Rack插件或WebMIDI乐器。"
  },
  {
    "id": "46364272",
    "title": "Ryanair fined €256M over ‘abusive strategy’ to limit ticket sales by OTAs",
    "url": "https://www.theguardian.com/business/2025/dec/23/ryanair-fined-limit-online-travel-agencies-ticket-sales-ota",
    "summary": "Italy's competition authority has fined Ryanair €256 million for abusing its dominant market position to limit ticket sales by online travel agencies (OTAs). The regulator found that between April 2023 and at least April 2025, the airline implemented a deliberate strategy of technical obstacles, such as blocking payment methods and imposing complex security checks like facial recognition, to make it difficult for OTAs to sell its tickets. The goal was to force customers to book directly through Ryanair's own website.\n\nRyanair's CEO, Michael O'Leary, had publicly criticized OTAs as \"pirate\" agents that overcharge consumers. The airline's actions led to a temporary drop in its own sales but did not prevent it from achieving a record valuation of €31 billion, making it the world's second most valuable airline.\n\nThe Italian authority ruled that Ryanair's tactics, which included preventing OTAs from selling its flights in combination with other airlines, weakened competition and harmed consumers. Ryanair has strongly rejected the ruling, calling it \"legally flawed\" and an \"affront to consumer protection,\" and plans to appeal immediately. The airline argues that its direct sales model saves customers money.",
    "chinese_title": "瑞安航空因限制OTA售票的“滥用策略”被罚款2.56亿欧元",
    "chinese_summary": "意大利竞争监管机构因瑞安航空滥用其市场主导地位限制在线旅行社销售机票，对其处以2.56亿欧元罚款。监管机构发现，该航空公司在2023年4月至至少2025年4月期间，通过设置技术障碍——如封锁支付方式、强制实施人脸识别等复杂安全检查——蓄意阻碍在线旅行社销售其机票，目的是迫使客户直接通过瑞安航空官网预订。\n\n瑞安航空首席执行官迈克尔·奥莱利曾公开指责在线旅行社是“海盗”代理商，向消费者收取过高费用。该航空公司的行为导致其自身销量短期下滑，但并未阻止其达到310亿欧元的历史最高估值，成为全球市值第二大的航空公司。\n\n意大利监管机构裁定，瑞安航空禁止在线旅行社将其航班与其他航空公司航班组合销售等策略削弱了竞争并损害了消费者权益。瑞安航空强烈反对该裁决，称其“存在法律缺陷”且“违背消费者保护原则”，并计划立即提出上诉。该航空公司辩称，其直销模式为顾客节省了费用。"
  },
  {
    "id": "46359120",
    "title": "It's Always TCP_NODELAY",
    "url": "https://brooker.co.za/blog/2024/05/09/nagle.html",
    "summary": "This article argues that Nagle's algorithm, a TCP feature designed in the 1980s to improve network efficiency by batching small packets, is now harmful to modern distributed systems and should be disabled by default.\n\nThe author explains that Nagle's algorithm works by delaying the sending of new data until previous data is acknowledged. While this was useful for interactive applications like telnet, it interacts poorly with another TCP feature called \"delayed ACK,\" creating a latency-deadlock scenario. This interaction is particularly detrimental to latency-sensitive, pipelined applications common in today's datacenters.\n\nThe core justification for Nagle—amortizing header overhead for tiny, single-byte packets—is deemed largely obsolete. Modern distributed systems (databases, microservices) naturally send larger messages due to serialization and protocol overhead, pushing efficiency concerns to the application layer. The latency penalty of waiting even one network round-trip (RTT) is now more costly than the bandwidth savings.\n\nThe author's conclusion is twofold: first, builders of latency-sensitive systems should always enable `TCP_NODELAY` (disabling Nagle) without hesitation. More controversially, they propose that `TCP_NODELAY` should become the default TCP behavior, as Nagle's algorithm is no longer necessary for the modern traffic mix and causes more problems than it solves.",
    "chinese_title": "始终启用TCP_NODELAY",
    "chinese_summary": "本文认为，纳格尔算法——一种20世纪80年代为提升网络效率而设计的、通过批量处理小数据包的TCP特性——如今对现代分布式系统有害，应默认禁用。\n\n作者解释道，纳格尔算法通过延迟发送新数据直至先前数据获得确认来工作。虽然这对telnet等交互式应用曾有益处，但它与另一项称为“延迟确认”的TCP特性配合不佳，会造成延迟死锁。这种交互对当今数据中心常见的延迟敏感型流水线应用尤为不利。\n\n纳格尔算法的核心理由——为极小的单字节数据包分摊头部开销——已被认为基本过时。现代分布式系统（数据库、微服务）因序列化和协议开销自然发送更大的消息，效率问题已转移至应用层。如今，即使等待一个网络往返时间（RTT）所造成的延迟代价，也已超过其节省的带宽价值。\n\n作者的结论有两点：首先，构建延迟敏感系统的开发者应毫不犹豫地启用`TCP_NODELAY`（禁用纳格尔算法）。更具争议的是，他们提出`TCP_NODELAY`应成为TCP的默认行为，因为纳格尔算法对现代流量模式已不再必要，且引发的问题多于其解决的问题。"
  },
  {
    "id": "46362655",
    "title": "Show HN: CineCLI – Browse and torrent movies directly from your terminal",
    "url": "https://github.com/eyeblech/cinecli",
    "summary": "**CineCLI** is a terminal-based application that allows users to search for movies, view their details, and directly download torrents from the YTS database.\n\n**Key Features:**\n*   **Search & Browse:** Users can search for movies via the command line (`cinecli search`) and view details like title, year, and rating.\n*   **Torrent Download:** It can automatically launch magnet links into the user's default torrent client (`cinecli watch`) or download `.torrent` files.\n*   **Smart Selection:** The tool auto-selects the best available torrent (based on quality and seed count), but allows for manual override.\n*   **User Interface:** It features a clean, interactive terminal interface built with the Rich library.\n*   **Cross-Platform:** It works on Linux, macOS, and Windows.\n\n**How It Works:**\nThe tool uses the YTS API for movie data. When launching a torrent, it relies on the operating system to handle the magnet link with the user's registered torrent client (e.g., qBittorrent, Transmission).\n\n**Technical Details:**\nCineCLI is built with Python (3.9+) using the Typer framework for the CLI and is installed via pip. It is open-source under an MIT license.",
    "chinese_title": "Show HN: CineCLI – 直接在终端中浏览和种子下载电影",
    "chinese_summary": "**CineCLI** 是一款基于终端的应用程序，允许用户搜索电影、查看详细信息，并直接从 YTS 数据库下载种子。\n\n**主要功能：**\n*   **搜索与浏览：** 用户可通过命令行（`cinecli search`）搜索电影，并查看标题、年份和评分等详细信息。\n*   **种子下载：** 可自动将磁力链接推送到用户的默认种子客户端（`cinecli watch`），或直接下载 `.torrent` 文件。\n*   **智能选择：** 工具会自动选择最佳可用种子（基于质量和做种数量），但也支持手动覆盖选择。\n*   **用户界面：** 采用 Rich 库构建，拥有简洁、交互式的终端界面。\n*   **跨平台支持：** 可在 Linux、macOS 和 Windows 上运行。\n\n**工作原理：**\n该工具使用 YTS API 获取电影数据。启动种子下载时，它依赖操作系统来处理磁力链接，并调用用户已注册的种子客户端（如 qBittorrent、Transmission）。\n\n**技术细节：**\nCineCLI 使用 Python（3.9+）开发，采用 Typer 框架构建命令行界面，并通过 pip 安装。它在 MIT 许可证下开源。"
  },
  {
    "id": "46366285",
    "title": "Stop Slopware",
    "url": "https://stopslopware.net/",
    "summary": "This website, Stop Slopware, defines \"slopware\" as low-effort, careless, and unmaintainable software, often made worse by the incorrect use of AI. It is presented as a constructive resource for developers whose projects receive this criticism.\n\nThe core message is that while being a beginner or writing imperfect code is acceptable, over-reliance on AI for tasks like writing project descriptions is harmful. It makes the software seem disingenuous and hinders genuine learning. The site advises authors to fix existing projects by slowing down, removing clutter, and understanding their code fully. For new projects, it recommends solving a single problem cleanly, keeping scope small, and writing all documentation personally.\n\nFor the wider open-source community, the site serves as a tool to address the exhausting prevalence of low-quality projects. Instead of writing repetitive critical feedback, users can share this link to provide clear, honest guidance efficiently. The ultimate goal is to encourage higher-quality, maintainable software as a \"love letter to FOSS.\"",
    "chinese_title": "停止粗制滥造",
    "chinese_summary": "该网站“Stop Slopware”将“slopware”定义为低投入、粗心且难以维护的软件，而AI的错误使用往往使其雪上加霜。它旨在为那些项目受到此类批评的开发者提供建设性资源。\n\n其核心观点是：作为初学者或编写不完美的代码是可以接受的，但过度依赖AI来完成诸如撰写项目描述等任务是有害的。这会让软件显得缺乏诚意，并阻碍真正的学习。网站建议作者通过放慢节奏、清理冗余代码并完全理解自己的代码来修复现有项目。对于新项目，则建议清晰解决单一问题、控制项目范围，并亲自撰写所有文档。\n\n对于更广泛的开源社区，该网站可作为应对低质量项目泛滥问题的工具。用户无需重复撰写批评性反馈，只需分享此链接即可高效提供清晰、诚实的指导。最终目标是鼓励开发更高质量、可维护的软件，以此作为“献给自由开源软件的一封情书”。"
  },
  {
    "id": "46357675",
    "title": "The Illustrated Transformer",
    "url": "https://jalammar.github.io/illustrated-transformer/",
    "summary": "This article explains the Transformer model, a neural network architecture introduced in the paper \"Attention is All You Need.\" It uses attention mechanisms to process sequences, enabling parallelization and outperforming earlier models like RNNs in tasks like machine translation.\n\nThe model consists of an encoder stack and a decoder stack. The encoder uses self-attention layers to weigh the importance of other words when encoding a specific word, followed by feed-forward networks. The decoder includes an additional attention layer to focus on the encoder's output.\n\nKey concepts detailed include:\n*   **Self-Attention:** Calculated using Query, Key, and Value vectors derived from input embeddings to determine contextual relationships between words.\n*   **Multi-Head Attention:** Employs multiple sets of attention weights to allow the model to focus on different parts of the sequence simultaneously, improving representation.\n*   **Positional Encoding:** Adds information about word order to the input embeddings since the model lacks inherent sequence awareness.\n\nThe article emphasizes that the Transformer's design, particularly its parallelizable self-attention, makes it faster to train and highly effective, forming the foundation for modern large language models.",
    "chinese_title": "图解Transformer",
    "chinese_summary": "本文介绍了Transformer模型，这是一种在《注意力就是一切》论文中提出的神经网络架构。它利用注意力机制处理序列，实现了并行化计算，并在机器翻译等任务中超越了RNN等早期模型。\n\n该模型由编码器堆栈和解码器堆栈组成。编码器使用自注意力层在编码特定词语时权衡其他词语的重要性，随后通过前馈网络处理。解码器则包含一个额外的注意力层，用于聚焦编码器的输出。\n\n详细阐述的关键概念包括：\n*   **自注意力：** 通过输入嵌入衍生的查询、键和值向量进行计算，以确定词语间的上下文关系。\n*   **多头注意力：** 采用多组注意力权重，使模型能同时关注序列的不同部分，从而提升表示能力。\n*   **位置编码：** 由于模型本身缺乏对序列顺序的感知，因此在输入嵌入中添加词语位置信息。\n\n文章强调，Transformer的设计——尤其是其可并行化的自注意力机制——使其训练速度更快且效果显著，为现代大型语言模型奠定了基础。"
  },
  {
    "id": "46361024",
    "title": "Inside CECOT – 60 Minutes [video]",
    "url": "https://archive.org/details/insidececot",
    "summary": "This text describes a video titled \"Inside CECOT | 60 Minutes\" hosted on the Internet Archive. The video is a report by CBS News correspondent Sharyn Alfonsi, with a publication date listed as December 22, 2025.\n\nThe key points are:\n\n*   The video item is an episode of the news program *60 Minutes*.\n*   The report, \"Inside CECOT,\" was reportedly censored by journalist Bari Weiss.\n*   The uploaded copy of the segment is identified as the version that aired on Canada's Global TV app, implying it may differ from what aired in the United States.\n*   The video file is large (1.4 GB) and was uploaded to the Internet Archive on December 23, 2025, by a user named Colin Haskins.\n*   The description includes standard video player warnings and download options, as well as content flagging options for viewers.\n\nIn summary, this is metadata for an archived news segment that is presented as a censored *60 Minutes* report, which was subsequently uploaded and shared online.",
    "chinese_title": "走进CECOT内部——60分钟[视频]",
    "chinese_summary": "这段文字描述了一个名为“Inside CECOT | 60 Minutes”的视频，该视频托管在互联网档案馆。视频是CBS新闻记者莎琳·阿尔方西的报道，发布日期标注为2025年12月22日。\n\n关键点包括：\n\n*   该视频是新闻节目《60分钟》的一期内容。\n*   报道“Inside CECOT”据称被记者巴里·韦斯审查。\n*   上传的视频片段被确认为在加拿大Global TV应用程序上播出的版本，暗示其可能与在美国播出的内容有所不同。\n*   视频文件较大（1.4 GB），由用户科林·哈斯金斯于2025年12月23日上传至互联网档案馆。\n*   描述中包含标准的视频播放器警告和下载选项，以及供观众使用的内容标记选项。\n\n总之，这是关于一个存档新闻片段的元数据，该片段据称是一份被审查的《60分钟》报道，随后被上传并在网上分享。"
  },
  {
    "id": "46357945",
    "title": "Ultrasound Cancer Treatment: Sound Waves Fight Tumors",
    "url": "https://spectrum.ieee.org/ultrasound-cancer-treatment",
    "summary": "This article details the development of histotripsy, a non-invasive cancer treatment that uses focused ultrasound waves to destroy tumors. The technology, commercialized by HistoSonics, creates and controls cavitation—the rapid formation and collapse of microscopic bubbles—within a tumor. This generates mechanical forces that liquefy cancerous tissue without generating significant heat, sparing surrounding healthy structures.\n\nHistoSonics' Edison system is FDA-approved for liver tumors, with pivotal studies for kidney and pancreatic cancer underway. Pancreatic cancer is a key target due to its lethality and the treatment's promising early results. Beyond direct ablation, histotripsy offers additional benefits: the body naturally clears the liquefied debris, and the process appears to stimulate an immune response, potentially helping the body attack cancer cells elsewhere.\n\nThe company, now backed by a new ownership group including Jeff Bezos, is advancing the technology with research into new imaging guidance systems and real-time feedback mechanisms. The goal is to expand histotripsy's use, positioning it as a new pillar of non-invasive medicine that uses sound waves instead of scalpels.",
    "chinese_title": "超声波癌症治疗：声波对抗肿瘤",
    "chinese_summary": "本文详述了组织切片术的发展历程，这是一种利用聚焦超声波摧毁肿瘤的非侵入性癌症治疗方法。该技术由HistoSonics公司商业化，通过在肿瘤内部产生并控制空化效应——即微观气泡的快速形成与破裂——产生机械力液化癌组织，而不会产生显著热量，从而保护周围健康组织。\n\nHistoSonics的爱迪生系统已获美国FDA批准用于治疗肝脏肿瘤，针对肾癌和胰腺癌的关键研究正在进行中。胰腺癌因其致命性及该疗法早期展现的良好疗效成为重点目标。除直接消融外，组织切片术还具有额外优势：人体可自然清除液化后的组织残骸，且该过程似乎能激发免疫反应，可能帮助机体攻击其他部位的癌细胞。\n\n该公司目前获得包括杰夫·贝索斯在内的新资方支持，正通过研发新型影像引导系统和实时反馈机制推进技术发展。其目标是拓展组织切片术的应用范围，将其打造为以声波替代手术刀的非侵入性医疗新支柱。"
  },
  {
    "id": "46352350",
    "title": "Show HN: Yapi – FOSS terminal API client for power users",
    "url": "https://yapi.run/blog/what-is-yapi",
    "summary": "**Summary:**\n\nYapi is a free, open-source, command-line API client designed for developers who prefer working in the terminal. It supports multiple protocols including HTTP, gRPC, TCP, and GraphQL, and is positioned as a terminal-based alternative to tools like Postman and Insomnia.\n\nKey features highlighted in the article include:\n*   **Declarative Request Files:** Users define API requests (method, URL, headers, body) in YAML files, which can include environment variables.\n*   **Testing & Assertions:** Built-in support for writing integration tests with expected status codes and assertions using jq-like syntax on responses.\n*   **Multi-Protocol Chaining:** Ability to chain requests together and share data between them, even across different protocols (e.g., HTTP to gRPC).\n*   **Environment Management:** Easy configuration for different environments (dev, staging, prod) using a central config file.\n*   **Developer Tooling:** Includes an LSP server for IDE integration (like Neovim) and a GitHub Action for running integration tests in CI/CD pipelines.\n\nThe author emphasizes that Yapi is in early alpha, encourages user feedback for bugs and feature requests, and is open to contributions. The tool is designed to be pipeable, sending only the response body to stdout for easy scripting.",
    "chinese_title": "展示 HN：Yapi – 专为高级用户打造的开源终端 API 客户端",
    "chinese_summary": "**摘要：**\n\nYapi 是一款免费、开源的命令行 API 客户端，专为偏爱在终端工作的开发者设计。它支持 HTTP、gRPC、TCP 和 GraphQL 等多种协议，定位为 Postman 和 Insomnia 等工具的终端替代品。\n\n文章强调的主要功能包括：\n*   **声明式请求文件：** 用户在 YAML 文件中定义 API 请求（方法、URL、头部、正文），并可包含环境变量。\n*   **测试与断言：** 内置支持编写集成测试，可设定预期状态码，并使用类似 jq 的语法对响应进行断言。\n*   **多协议链式调用：** 能够将请求链接在一起并在它们之间共享数据，甚至跨不同协议（例如从 HTTP 到 gRPC）。\n*   **环境管理：** 通过中央配置文件轻松配置不同环境（开发、预发布、生产）。\n*   **开发者工具：** 包含用于 IDE 集成（如 Neovim）的 LSP 服务器，以及用于在 CI/CD 流水线中运行集成测试的 GitHub Action。\n\n作者强调 Yapi 目前处于早期 Alpha 阶段，鼓励用户反馈错误和功能请求，并欢迎贡献。该工具设计为可管道化，仅将响应正文发送到标准输出，便于脚本编写。"
  },
  {
    "id": "46357287",
    "title": "GLM-4.7: Advancing the Coding Capability",
    "url": "https://z.ai/blog/glm-4.7",
    "summary": "**Summary:**\n\nThe article introduces GLM-4.7, the latest iteration of the GLM (General Language Model) series, which represents a significant advancement in coding capability over its predecessor, GLM-4.6. The primary focus is on the model's enhanced performance in programming-related tasks.\n\nKey improvements highlighted include superior code generation, more accurate code completion, and better understanding and debugging of complex code. GLM-4.7 is trained on a larger and more diverse corpus of high-quality code data, enabling it to handle a wider range of programming languages, frameworks, and development scenarios with greater precision.\n\nThe advancement positions GLM-4.7 as a more powerful tool for developers, aiming to boost productivity by assisting with routine coding, suggesting optimizations, and explaining code logic. The model's improved reasoning allows it to better follow intricate instructions and generate functionally correct and syntactically accurate code snippets.\n\nOverall, the release of GLM-4.7 underscores a dedicated effort to push the boundaries of AI-assisted programming, making sophisticated coding support more accessible and reliable for software development.",
    "chinese_title": "GLM-4.7：编码能力再升级",
    "chinese_summary": "**摘要：**\n\n本文介绍了GLM系列的最新版本GLM-4.7，相较于前代GLM-4.6，它在编码能力上实现了显著提升。文章重点阐述了该模型在编程相关任务中增强的性能表现。\n\n主要改进包括更卓越的代码生成能力、更精准的代码补全，以及对复杂代码更好的理解与调试功能。GLM-4.7基于规模更大、更多样化的高质量代码数据训练而成，使其能够更精确地处理更广泛的编程语言、框架和开发场景。\n\n这一进步使GLM-4.7成为开发者更强大的工具，旨在通过辅助日常编码、提出优化建议和解释代码逻辑来提高生产力。模型改进后的推理能力使其能更好地遵循复杂指令，生成功能正确且语法准确的代码片段。\n\n总体而言，GLM-4.7的发布彰显了推动AI辅助编程边界的不懈努力，旨在为软件开发提供更易获取、更可靠的先进编码支持。"
  }
]