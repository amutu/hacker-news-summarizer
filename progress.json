[
  {
    "id": "46329038",
    "title": "TP-Link Tapo C200: Hardcoded Keys, Buffer Overflows and Privacy",
    "url": "https://www.evilsocket.net/2025/12/18/TP-Link-Tapo-C200-Hardcoded-Keys-Buffer-Overflows-and-Privacy-in-the-Era-of-AI-Assisted-Reverse-Engineering/",
    "summary": "In a security analysis of the TP-Link Tapo C200 IP camera, multiple critical vulnerabilities were discovered in the latest firmware. The researcher used AI-assisted reverse engineering to find several pre-authentication flaws affecting approximately 25,000 internet-exposed devices.\n\nKey findings include:\n1.  **Hardcoded SSL Private Key**: The firmware embeds a private key for HTTPS APIs, allowing network attackers to decrypt traffic.\n2.  **Pre-Auth ONVIF SOAP Parser Memory Overflow**: Sending a malformed XML request to the ONVIF service (port 2020) crashes the device.\n3.  **Pre-Auth HTTPS Integer Overflow**: An unchecked `atoi()` call for the `Content-Length` header can crash the web server.\n4.  **Pre-Auth WiFi Hijacking**: An unauthenticated API endpoint allows remote attackers to disconnect the camera or force it onto a malicious network.\n5.  **Pre-Auth WiFi Scanning**: An unauthenticated endpoint reveals nearby WiFi networks. Combined with services like Apple's location database, this could allow remote geolocation of the camera.\n\nThe researcher reported the issues to TP-Link in July 2025. After no fix was released within the extended 150-day disclosure period, public disclosure was made in December 2025.",
    "chinese_title": "TP-Link Tapo C200：硬编码密钥、缓冲区溢出与隐私问题",
    "chinese_summary": "在对TP-Link Tapo C200 IP摄像头的安全分析中，研究人员在最新固件中发现了多个严重漏洞。该研究者通过AI辅助逆向工程，发现了若干影响约2.5万台暴露于互联网设备的预认证漏洞。\n\n主要发现包括：\n1.  **硬编码SSL私钥**：固件内嵌了HTTPS API的私钥，使网络攻击者能够解密通信流量。\n2.  **预认证ONVIF SOAP解析器内存溢出**：向ONVIF服务（端口2020）发送格式错误的XML请求会导致设备崩溃。\n3.  **预认证HTTPS整数溢出**：对`Content-Length`标头未加检查的`atoi()`调用可导致Web服务器崩溃。\n4.  **预认证WiFi劫持**：一个无需认证的API端点允许远程攻击者断开摄像头连接或强制其接入恶意网络。\n5.  **预认证WiFi扫描**：未认证端点会暴露附近的WiFi网络信息。结合苹果定位数据库等服务，可能实现摄像头的远程地理位置定位。\n\n研究者已于2025年7月向TP-Link报告了这些问题。在延长的150天披露期内未收到修复方案后，于2025年12月进行了公开披露。"
  },
  {
    "id": "46326984",
    "title": "Garage – An S3 object store so reliable you can run it outside datacenters",
    "url": "https://garagehq.deuxfleurs.fr/",
    "summary": "**Garage** is an open-source, self-hosted object storage system designed to be highly reliable and resilient enough to operate outside traditional data centers, such as across multiple home or office locations.\n\nIts core features and goals are:\n*   **S3 Compatibility:** It implements the Amazon S3 API, ensuring compatibility with a wide range of existing applications for hosting websites, storing media, or acting as a backup target.\n*   **Built for Resilience:** Data is replicated across three \"zones\" (groups of servers) to tolerate network issues, disk failures, and latency, making it suitable for unstable internet connections.\n*   **Operator-Friendly & Lightweight:** It is distributed as a single, dependency-free binary that is fast to deploy. It has minimal hardware requirements (e.g., a 10-year-old CPU, 1GB RAM) and can run on heterogeneous, second-hand machines.\n*   **Designed for Distributed Deployment:** Explicitly built to run across multiple locations over the public internet, not requiring a dedicated backbone.\n\nThe project is research-informed and has been funded through multiple European Union grants (NGI POINTER, NGI0 Entrust, NGI0 Commons) via NLnet, supporting its ongoing development.",
    "chinese_title": "Garage – 一款如此可靠的S3对象存储，您甚至可以在数据中心之外运行它",
    "chinese_summary": "**Garage** 是一款开源、自托管的对象存储系统，旨在实现高可靠性和强韧性，能够在传统数据中心之外运行，例如跨越多个家庭或办公室地点。\n\n其核心特性和目标包括：\n*   **S3兼容性：** 实现了亚马逊S3 API，确保与大量现有应用程序兼容，可用于托管网站、存储媒体或作为备份目标。\n*   **为韧性而构建：** 数据在三个“区域”（服务器组）间复制，以应对网络问题、磁盘故障和延迟，使其适用于不稳定的互联网连接。\n*   **运维友好且轻量：** 以单一、无依赖的二进制文件分发，部署迅速。硬件要求极低（例如，10年历史的CPU、1GB内存），可在异构的二手机器上运行。\n*   **为分布式部署设计：** 明确构建为在公共互联网上的多个地点运行，无需专用骨干网络。\n\n该项目基于研究，并通过NLnet获得了多项欧盟资助（NGI POINTER、NGI0 Entrust、NGI0 Commons）的支持，以推动其持续发展。"
  },
  {
    "id": "46329696",
    "title": "You can now play Grand Theft Auto Vice City in the browser",
    "url": "https://dos.zone/grand-theft-auto-vice-city/",
    "summary": "This article announces that the classic game *Grand Theft Auto: Vice City* can now be played in a web browser via a technology demo on DOS.Zone. This is made possible by **reVC**, an open-source reimplementation of the game's engine, which has been adapted to run on WebAssembly and modern browser APIs.\n\nThe core technical achievement is the reworking of low-level systems like rendering, audio, and input to function efficiently within a browser environment, eliminating the need for native installation.\n\nThe article includes a strong disclaimer, clarifying that this is an **independent, non-commercial tech demo** with no affiliation to the original game's developers or rights holders. It emphasizes that the demo does **not include or distribute any original game assets**.\n\nTo access the full game, users must legally own and provide their own game files, which the system verifies cryptographically. The publicly available demo uses only a minimal, incomplete set of assets for educational purposes to showcase the engine's web capabilities. The project states it operates in full compliance with copyright laws.",
    "chinese_title": "你现在可以在浏览器中畅玩《侠盗猎车手：罪恶都市》了。",
    "chinese_summary": "本文宣布，经典游戏《侠盗猎车手：罪恶都市》现已可通过DOS.Zone的技术演示在网页浏览器中运行。这得益于**reVC**——一个对该游戏引擎的开源重制项目，该项目已适配WebAssembly与现代浏览器API。\n\n核心技术成就在于对渲染、音频和输入等底层系统的重构，使其能在浏览器环境中高效运行，从而无需原生安装。\n\n文章附有明确声明，强调此为**独立、非商业的技术演示**，与原游戏开发者或版权方无关，并指出演示**不包含或分发任何原始游戏资源**。\n\n要体验完整游戏，用户必须合法拥有并提供自己的游戏文件，系统将通过加密方式验证文件。公开演示仅使用少量不完整的资源用于教育目的，以展示引擎的网页兼容能力。项目方声明其运作完全符合版权法规。"
  },
  {
    "id": "46328992",
    "title": "Reverse Engineering US Airline's PNR System and Accessing All Reservations",
    "url": "https://alexschapiro.com/security/vulnerability/2025/11/20/avelo-airline-reservation-api-vulnerability",
    "summary": "In October 2025, a security researcher discovered a critical vulnerability in Avelo Airlines' reservation system that allowed unauthorized access to all passenger bookings. The flaw stemmed from two key security failures: a missing requirement for passenger last name verification and a complete absence of rate limiting on the reservation API endpoint.\n\nThis meant an attacker could use any valid authentication cookie to query the API using only a 6-character alphanumeric confirmation code. With approximately 2.18 billion possible codes and no defenses against rapid guessing, an attacker could have brute-forced all valid reservations in roughly six hours at a low cost. Valid codes were returned in seconds, exposing sensitive passenger data.\n\nThe leaked information for each reservation included full passenger PII (names, dates of birth), government ID numbers (passport and Known Traveler Numbers), contact details, full itineraries, and partial payment card information. This created severe risks of identity theft, fraud, and mass reservation tampering.\n\nThe researcher responsibly disclosed the vulnerability to Avelo on October 15, 2025. The airline's security team responded promptly and professionally, deploying a fix by November 13. The incident underscores the critical importance of implementing multi-factor authentication for sensitive data access and robust rate limiting on all enumerable endpoints.",
    "chinese_title": "逆向工程美国航空公司的PNR系统并访问所有预订信息",
    "chinese_summary": "2025年10月，一名安全研究人员在Avelo航空公司的预订系统中发现了一个严重漏洞，该漏洞允许未经授权访问所有乘客的预订信息。此缺陷源于两个关键的安全失误：一是缺少对乘客姓氏的验证要求，二是预订API端点完全未设置速率限制。\n\n这意味着攻击者仅需使用一个6位字母数字组成的确认码，配合任意有效的身份验证cookie即可查询API。由于可能的组合约有21.8亿种，且系统没有任何防止快速猜测的防护措施，攻击者可以以极低的成本在约六小时内暴力破解所有有效预订。系统会在数秒内返回有效代码，导致敏感乘客数据暴露。\n\n每条被泄露的预订信息包含完整的乘客个人身份信息（姓名、出生日期）、政府身份证件号码（护照及已知旅客号码）、联系方式、完整行程以及部分支付卡信息。这带来了身份盗窃、欺诈和大规模预订篡改的严重风险。\n\n研究人员于2025年10月15日负责任地向Avelo报告了该漏洞。航空公司安全团队反应迅速且专业，于11月13日前部署了修复方案。此事件凸显了对敏感数据访问实施多因素认证、并对所有可枚举端点设置严格速率限制的至关重要性。"
  },
  {
    "id": "46324543",
    "title": "GotaTun -- Mullvad's WireGuard Implementation in Rust",
    "url": "https://mullvad.net/en/blog/announcing-gotatun-the-future-of-wireguard-at-mullvad-vpn",
    "summary": "Mullvad VPN has announced GotaTun, its new WireGuard implementation written in Rust, which has now been rolled out to all Android users. It is a fork of Cloudflare's BoringTun project, enhanced with privacy features like DAITA and Multihop.\n\nThe primary motivation for the switch was to replace the problematic wireguard-go implementation, which was the source of over 85% of app crashes on Android. The integration between Rust and Go was also complex and hindered debugging. Since launching GotaTun in November 2025, the user-perceived crash rate has dropped dramatically from 0.40% to 0.01%, with users reporting better speeds and lower battery consumption.\n\nLooking ahead, Mullvad plans a third-party security audit for GotaTun in early 2026 and aims to replace wireguard-go across all its desktop and iOS apps, with further performance improvements planned.",
    "chinese_title": "GotaTun —— Mullvad 基于 Rust 的 WireGuard 实现",
    "chinese_summary": "Mullvad VPN宣布推出其新的WireGuard实现GotaTun，该实现采用Rust语言编写，现已向所有Android用户开放。该项目基于Cloudflare的BoringTun项目分支开发，并增强了DAITA和Multihop等隐私功能。\n\n此次替换的主要动机是为了取代问题频发的wireguard-go实现，该实现曾导致Android应用中超过85%的崩溃。同时，Rust与Go之间的集成复杂且阻碍调试。自2025年11月推出GotaTun以来，用户感知的崩溃率已从0.40%大幅降至0.01%，用户反馈速度更快且电池消耗更低。\n\n展望未来，Mullvad计划在2026年初对GotaTun进行第三方安全审计，并将在所有桌面和iOS应用中全面替换wireguard-go，同时计划进一步优化性能。"
  },
  {
    "id": "46324078",
    "title": "Amazon will allow ePub and PDF downloads for DRM-free eBooks",
    "url": "https://www.kdpcommunity.com/s/article/New-eBook-Download-Options-for-Readers-Coming-in-2026?language=en_US",
    "summary": "Amazon will soon allow authors and publishers using Kindle Direct Publishing (KDP) to offer DRM-free downloads of their eBooks in ePub and PDF formats. This new feature, announced in the KDP Community, will enable customers to download a book file directly from their \"Manage Your Content and Devices\" page after purchase.\n\nThe key points are:\n*   **Format Availability:** The downloadable files will be provided in both ePub and PDF formats.\n*   **DRM-Free:** The downloads will not have Digital Rights Management (DRM) restrictions, giving customers more freedom to read their purchased eBooks on various devices and apps of their choice.\n*   **Access Method:** Customers can access these files through their Amazon account's content management page.\n*   **Author Control:** The feature is optional. Rights holders can choose to enable or disable these DRM-free downloads for each of their titles in KDP.\n*   **Benefit:** This move increases flexibility for readers and aligns Amazon with industry standards for DRM-free sales, potentially appealing to authors and customers who prefer unrestricted access to their digital libraries.\n\nThe announcement indicates this feature will be rolled out in the coming weeks.",
    "chinese_title": "亚马逊将允许无数字版权管理的电子书以ePub和PDF格式下载。",
    "chinese_summary": "亚马逊即将允许使用Kindle Direct Publishing（KDP）的作者和出版商提供无数字版权管理（DRM）的电子书下载，支持ePub和PDF格式。这项在KDP社区宣布的新功能，将让顾客在购买后直接从“管理您的内容和设备”页面下载书籍文件。\n\n主要要点包括：\n*   **格式支持**：可下载文件将提供ePub和PDF两种格式。\n*   **无DRM限制**：下载文件不设数字版权管理限制，顾客可更自由地在所选设备和应用上阅读已购电子书。\n*   **访问方式**：顾客可通过亚马逊账户的内容管理页面获取这些文件。\n*   **作者控制权**：此功能为可选设置，版权持有者可在KDP中为每部作品选择启用或禁用无DRM下载。\n*   **优势**：此举提高了读者的灵活性，使亚马逊符合无DRM销售的行业标准，可能吸引偏爱无限制访问数字图书馆的作者和顾客。\n\n公告表示该功能将在未来几周内逐步推出。"
  },
  {
    "id": "46326519",
    "title": "The FreeBSD Foundation's Laptop Support and Usability Project",
    "url": "https://github.com/FreeBSDFoundation/proj-laptop",
    "summary": "The FreeBSD Foundation, with co-funding from Quantum Leap Research, has approved a $750,000 program to significantly improve the laptop user experience on FreeBSD. The project, running for 1-2 years starting in late 2024, aims to deliver \"out-of-the-box\" functionality for a broad range of laptops to accelerate developer and corporate adoption.\n\nKey technical goals include delivering updates to FreeBSD 14.x and above with contemporary WiFi, full audio, modern suspend/resume, improved graphics, and Bluetooth support. The work will be managed by Foundation staff and contracted developers, with scope informed by community input and vendors like Dell, AMD, and Framework.\n\nThe program emphasizes a user-focused approach, framing work as \"user stories\" to improve both functionality and overall user experience (UX), particularly for developers. Progress will be tracked via a public GitHub roadmap and monthly updates, while community discussion is encouraged through the Desktop mailing list and dedicated discussion threads for each functional area (e.g., power, audio, graphics). Although focused on laptops, many improvements are expected to benefit desktop users as well.",
    "chinese_title": "FreeBSD基金会笔记本电脑支持与可用性项目",
    "chinese_summary": "FreeBSD基金会与Quantum Leap Research共同出资，批准了一项75万美元的计划，旨在显著提升FreeBSD在笔记本电脑上的用户体验。该项目将于2024年底启动，持续1-2年，致力于为各类笔记本电脑提供“开箱即用”的功能，以加速开发者和企业采用该系统。\n\n关键的技术目标包括为FreeBSD 14.x及以上版本提供现代WiFi、完整音频支持、现代休眠/唤醒机制、改进的图形处理以及蓝牙支持。项目将由基金会工作人员和签约开发者共同推进，具体范围将参考社区意见以及戴尔、AMD和Framework等厂商的建议。\n\n该计划强调以用户为中心的方法，将工作以“用户故事”的形式展开，旨在提升功能性和整体用户体验（UX），特别是针对开发者群体。项目进展将通过公开的GitHub路线图和月度更新进行追踪，同时鼓励社区通过桌面邮件列表及各功能领域（如电源、音频、图形）的专门讨论帖参与交流。尽管重点在笔记本电脑，但许多改进预计也将惠及桌面用户。"
  },
  {
    "id": "46267862",
    "title": "Where Is GPT in the Chomsky Hierarchy?",
    "url": "https://fi-le.net/chomsky/",
    "summary": "This article examines where GPT models fit within the Chomsky hierarchy of formal languages. While human language is considered Turing-complete, the analysis argues that GPTs, even with an infinite context window, are not.\n\nThe core limitation is architectural: transformers perform a fixed, bounded number of computational steps per token. Because their vocabulary and embedding space are finite, the probability of halting (emitting an end-of-sequence token) is always bounded from below, guaranteeing finite outputs. This contrasts with Turing-complete models like RNNs, which can perform unbounded computation during inference.\n\nThe author notes that while theoretical proofs exist showing transformers can be made Turing-complete under specific, unrealistic conditions (like adding layers with input length), standard GPTs lack this capacity. This bounded depth explains their difficulty with algorithmic tasks requiring iterative reasoning (like parity checks) without workarounds like chain-of-thought prompting.\n\nUltimately, this constraint is presented as a double-edged sword. It enables the efficient, parallelized training that made GPTs viable but may also limit their ability to learn generalizable algorithms. The article concludes that this fundamental limitation is central to the debate over whether current architectures can achieve human-like general intelligence or if a new approach is needed.",
    "chinese_title": "GPT在乔姆斯基层级中处于什么位置？",
    "chinese_summary": "本文探讨了GPT模型在乔姆斯基形式语言层级中的定位。尽管人类语言被认为是图灵完备的，但分析指出GPT模型即使具备无限上下文窗口，也并非图灵完备。\n\n其核心限制在于架构：Transformer对每个标记执行固定且有限的计算步骤。由于词汇表和嵌入空间是有限的，生成终止序列标记的概率始终存在下限，这保证了输出必然有限。这与循环神经网络等图灵完备模型形成对比，后者在推理过程中可以进行无限计算。\n\n作者指出，虽然理论证明表明Transformer在特定非现实条件下（例如添加随输入长度增加的层数）可以实现图灵完备，但标准GPT模型不具备这种能力。这种有限的计算深度解释了为何模型难以直接完成需要迭代推理的算法任务（如奇偶校验），必须依赖思维链提示等变通方法。\n\n最终，这种约束被呈现为一把双刃剑。它使得高效并行训练成为可能，从而催生了GPT模型的成功，但也可能限制其学习可泛化算法的能力。文章总结认为，这一根本性限制是当前架构能否实现类人通用智能、抑或需要全新方法论的核心争议所在。"
  },
  {
    "id": "46327133",
    "title": "Believe the Checkbook",
    "url": "https://robertgreiner.com/believe-the-checkbook/",
    "summary": "This article uses Anthropic's acquisition of the Bun team to argue that the primary value in engineering is shifting from code production to high-level judgment, despite AI's coding capabilities.\n\nThe central evidence is the contradiction that Anthropic's own AI was the top contributor to Bun's open-source code, yet the company still paid millions to acquire the human team. This \"revealed preference\" shows that AI companies privately value human expertise far more than their public automation narratives suggest.\n\nThe author asserts that AI is a force multiplier for generating code, but it does not solve the bottleneck of judgment: the critical ability to make strategic decisions, prioritize correctly, foresee long-term trade-offs, and navigate complex domains. Anthropic's acquisition was based on the team's proven track record of \"correct calls\" and first-principles thinking, not their existing code.\n\nFor technical leaders, the takeaways are to:\n1. Use AI to empower high-judgment engineers, not devalue them.\n2. Focus on developing skills like architecture, risk assessment, and strategic thinking over mere coding speed.\n3. Maintain junior pipelines, as the gap between routine and high-judgment work will widen.\n4. Base strategy on corporate actions (like acquisitions and hiring) rather than public statements about AI replacing engineers.",
    "chinese_title": "相信支票簿",
    "chinese_summary": "本文以Anthropic收购Bun团队为例，论证工程领域的核心价值正从代码产出转向高层级判断力——尽管AI已具备编码能力。\n\n核心论据在于一个矛盾现象：Anthropic自家AI本是Bun开源代码库的最大贡献者，该公司却仍斥资数百万美元收购其人类团队。这种“显示性偏好”表明，AI企业私下对人类专业知识的重视程度，远超过其公开宣扬的自动化叙事。\n\n作者指出，AI是代码生成的倍增器，却无法解决判断力瓶颈：即制定战略决策、正确排定优先级、预见长期权衡、驾驭复杂领域的关键能力。Anthropic的收购决策正是基于该团队过往“正确决策”的实绩记录与第一性原理思维，而非既有代码资产。\n\n对技术领导者而言，启示在于：\n1. 运用AI赋能高判断力工程师，而非贬低其价值\n2. 重点培养架构设计、风险评估、战略思维等能力，而非单纯追求编码速度\n3. 保持初级人才通道，因常规工作与高判断力工作的差距将持续扩大\n4. 依据企业收购、招聘等实际行动制定战略，而非轻信“AI取代工程师”的公开言论"
  },
  {
    "id": "46329654",
    "title": "Proton Leaves Switzerland",
    "url": "https://www.nzz.ch/technologie/proton-ceo-andy-yen-wer-gesetzgebung-der-polizei-ueberlaesst-sollte-sich-nicht-wundern-wenn-er-eines-tages-in-einem-polizeistaat-aufwacht-ld.1916779",
    "summary": "**Summary of \"Proton Leaves Switzerland\"**\n\nThe article reports that Proton, the Swiss-based privacy-focused technology company known for its encrypted email and VPN services, is relocating its headquarters from Switzerland to an unspecified new country.\n\nThe primary driver for the move is Switzerland's recent revision of its surveillance laws. Proton argues that the new legal framework, which grants authorities broader powers for digital surveillance, undermines the strong privacy protections that initially made Switzerland an ideal home for the company. The founders state that operating under these laws would conflict fundamentally with Proton's core mission and promise of \"privacy by default\" to its users.\n\nThe piece frames the relocation as a significant and symbolic decision, highlighting the growing tension between government security mandates and the principles of private, encrypted communication. It presents Proton's exit as a direct consequence of a political shift in Switzerland towards greater state monitoring capabilities.\n\nWhile the new headquarters location is not named, the article emphasizes that Proton will continue its operations and maintain its strict no-logs policy from its new base, seeking a legal environment that aligns with its foundational commitment to user privacy.",
    "chinese_title": "质子离开瑞士",
    "chinese_summary": "**《Proton撤离瑞士》摘要**\n\n文章报道称，以加密邮件和VPN服务闻名的瑞士隐私技术公司Proton，正将其总部从瑞士迁往一个未指明的新国家。\n\n此次搬迁的主要驱动力是瑞士近期修订的监控法律。Proton认为，新法律框架赋予当局更广泛的数字监控权力，破坏了瑞士原本强大的隐私保护环境，而正是这种环境最初使瑞士成为公司的理想家园。创始人表示，在此类法律下运营将与Proton的核心使命及其对用户“默认隐私”的承诺根本冲突。\n\n文章将此次搬迁描述为一个重要且具有象征意义的决定，凸显了政府安全指令与私人加密通信原则之间日益加剧的紧张关系。它将Proton的撤离直接归因于瑞士政治转向增强国家监控能力的趋势。\n\n尽管新总部地点尚未公布，但文章强调，Proton将继续运营，并在新基地维持其严格的无日志政策，寻求一个与其保护用户隐私这一根本承诺相符的法律环境。"
  },
  {
    "id": "46327206",
    "title": "Graphite Is Joining Cursor",
    "url": "https://cursor.com/blog/graphite",
    "summary": "Graphite, a code review platform used by hundreds of thousands of engineers, has been acquired by Cursor, an AI-powered code editor. The core issue addressed is the growing bottleneck between modern developer workflows and traditional code review/merge processes.\n\nThe Graphite team believes the separation between where code is written and where it is collaboratively reviewed is artificial. By bridging this gap with Cursor, they aim to unlock new capabilities.\n\nKey points of the announcement:\n*   **Acquisition:** Graphite has signed a definitive agreement to be acquired by Cursor.\n*   **Continued Operation:** Graphite will continue to operate independently with its same team and product.\n*   **Future Integration:** Over the coming months, the teams will explore integrations to create a more seamless workflow between local development in Cursor and pull requests/code review in Graphite. Planned enhancements include tighter integration, smarter code reviews that learn from both systems, and more ambitious, undisclosed ideas.\n\nThe overarching goal is to fundamentally improve how engineering teams build production software by merging the development and collaboration environments.",
    "chinese_title": "Graphite 正在加入 Cursor",
    "chinese_summary": "Graphite，一个被数十万工程师使用的代码审查平台，已被AI驱动的代码编辑器Cursor收购。此举旨在解决现代开发者工作流与传统代码审查/合并流程之间日益凸显的瓶颈问题。\n\nGraphite团队认为，代码编写环境与协作审查环境之间的割裂是人为的。通过Cursor弥合这一鸿沟，他们希望释放新的潜能。\n\n公告要点：\n*   **收购事宜：** Graphite已签署最终协议，将被Cursor收购。\n*   **持续运营：** Graphite将继续由其原团队独立运营，产品保持不变。\n*   **未来整合：** 未来数月，双方团队将探索集成方案，以在Cursor的本地开发与Graphite的拉取请求/代码审查之间建立更无缝的工作流。计划中的改进包括更紧密的集成、能向两个系统学习从而更智能的代码审查，以及更具雄心且尚未公开的构想。\n\n总体目标是，通过融合开发与协作环境，从根本上改进工程团队构建生产软件的方式。"
  },
  {
    "id": "46329536",
    "title": "Wall Street Ruined the Roomba and Then Blamed Lina Khan",
    "url": "https://www.thebignewsletter.com/p/how-wall-street-ruined-the-roomba",
    "summary": "**Summary of \"Wall Street Ruined the Roomba and Then Blamed Lina Khan\"**\n\nThe article argues that iRobot's failure, culminating in its acquisition by Amazon being blocked, was caused by Wall Street's financial engineering, not antitrust enforcement by FTC Chair Lina Khan.\n\niRobot, the maker of Roomba, was a profitable and innovative company until activist investors, including a hedge fund with ties to Amazon, pushed for a shift in strategy. Under their influence, iRobot abandoned its successful, durable product model. It began using cheaper components, planned for shorter product lifespans, and shifted to a \"razor-and-blades\" model focused on selling customer mapping data and subscription services. This degraded product quality and consumer trust.\n\nSimultaneously, the company took on massive debt to fund stock buybacks, enriching shareholders but crippling its balance sheet. By the time the Amazon deal was proposed, iRobot was a weakened company with declining sales, heavy debt, and a damaged reputation.\n\nWhen the FTC moved to block the acquisition on antitrust grounds, Wall Street and pundits blamed Lina Khan for \"killing\" iRobot. The article contends this narrative is false. It asserts that Wall Street activists deliberately hollowed out iRobot, making it dependent on a sale to a tech giant like Amazon for survival. The FTC's action didn't destroy a healthy company; it prevented a monopolist from acquiring a competitor that financiers had already broken. The real cause of iRobot's downfall was a financial strategy that prioritized short-term shareholder returns over long-term product integrity and corporate health.",
    "chinese_title": "华尔街毁了Roomba，却怪罪莉娜·汗。",
    "chinese_summary": "**《华尔街毁了Roomba，却怪莉娜·汗》摘要**\n\n文章指出，iRobot的失败（最终导致其被亚马逊收购的计划受阻）源于华尔街的金融运作，而非美国联邦贸易委员会主席莉娜·汗的反垄断执法。\n\nRoomba的制造商iRobot曾是一家盈利且创新的公司，直到包括一家与亚马逊有关联的对冲基金在内的激进投资者推动其战略转型。在他们的影响下，iRobot放弃了原本成功且耐用的产品模式，开始使用更廉价的零部件，计划缩短产品寿命，并转向专注于销售客户地图数据和订阅服务的“剃须刀与刀片”模式。这导致产品质量下降，消费者信任受损。\n\n与此同时，公司背负巨额债务以资助股票回购，使股东获利，却严重损害了其资产负债表。当亚马逊提出收购时，iRobot已是一家销售下滑、债务沉重、声誉受损的虚弱公司。\n\n当联邦贸易委员会以反垄断为由阻止收购时，华尔街和评论人士却指责莉娜·汗“扼杀”了iRobot。文章认为这种说法是错误的。它指出，华尔街激进投资者有意掏空了iRobot，使其依赖出售给亚马逊这样的科技巨头来生存。联邦贸易委员会的行动并未摧毁一家健康的公司，而是阻止了垄断者收购一家已被金融资本破坏的竞争对手。iRobot衰落的真正原因，是一种将短期股东回报置于产品长期完整性和公司健康之上的金融策略。"
  },
  {
    "id": "46328203",
    "title": "Show HN: I Made Loom for Mobile",
    "url": "https://demoscope.app",
    "summary": "**Demo Scope** is an iOS app designed for creating professional mobile web demos and live streams. It allows users to record or stream any mobile website while simultaneously displaying a picture-in-picture face camera and animated touch indicators.\n\n**Key features include:**\n*   **Face Cam:** A repositionable, resizable camera overlay with multiple shape options.\n*   **Touch Indicators:** Visual feedback for taps and swipes, with customizable colors and size.\n*   **Web Browser:** Loads any URL directly within the app for seamless demos.\n*   **Live Streaming:** Supports direct streaming to platforms like Twitch, YouTube, and Facebook via RTMP.\n*   **Multiple Sources:** Can also use photos or videos as a source for reaction content.\n\nThe app is presented as a tool for **tech founders, streamers, and educators** to create investor pitches, tutorials, and live content. According to the FAQ, it is a **one-time purchase** (not a subscription), with a fully-featured free version limited by a 5-minute cap and a watermark. The app is specifically for mobile web content and does not record native iOS apps.\n\n**Demo Scope is available as a free download on the App Store for iOS 15.0 and later.**",
    "chinese_title": "Show HN：我制作了移动版Loom",
    "chinese_summary": "**Demo Scope** 是一款专为创建专业移动端网页演示和直播而设计的iOS应用。用户可在录制或直播任意移动网站的同时，实时显示画中画面部摄像头和动态触摸指示器。\n\n**主要功能包括：**\n*   **面部摄像头：** 可自由移动、调整大小的摄像头叠加层，支持多种形状选择。\n*   **触摸指示器：** 为点击和滑动提供视觉反馈，颜色和大小均可自定义。\n*   **网页浏览器：** 可直接在应用内加载任何URL，实现无缝演示。\n*   **直播功能：** 支持通过RTMP协议直接推流至Twitch、YouTube和Facebook等平台。\n*   **多内容源：** 也可使用照片或视频作为反应式内容的素材来源。\n\n该应用定位为**科技创业者、主播和教育工作者**的工具，用于制作投资推介、教程和直播内容。根据常见问题解答，它采用**一次性买断制**（非订阅制），提供功能齐全的免费版本，但有5分钟时长限制并带有水印。此应用专用于移动网页内容，不支持录制原生iOS应用。\n\n**Demo Scope可在App Store免费下载，适用于iOS 15.0及更高版本。**"
  },
  {
    "id": "46328109",
    "title": "Prepare for That Stupid World",
    "url": "https://ploum.net/2025-12-19-prepare-for-that-world.html",
    "summary": "This article critiques a Wall Street Journal video about an AI-powered vending machine as a piece of disguised advertising for both the WSJ and Anthropic, rather than genuine journalism.\n\nThe author argues the project is fundamentally absurd, as traditional vending machines are already efficient and reliable. Adding an expensive, error-prone AI chatbot to a process that still requires human stocking and customer retrieval provides no real value. The piece suggests the video's true purpose is to normalize the inevitable, thoughtless integration of AI into everyday life, regardless of its utility.\n\nKey evidence includes the awkward, self-contradictory statements from the Anthropic employee, who ultimately warns that such AI could malfunction or lock users out before resigning to the advice: \"probably prepare for that world.\" The author is critical of the journalists for uncritically celebrating this experiment and participating in long queues for trivial free items, framing it as a vision of a future where poorly-paid \"world-class\" workers accept inefficient, AI-driven systems.\n\nIn conclusion, the article presents the story as an advertisement for a dystopian future of pervasive but pointless AI, urging readers to see beyond its surface-level \"funny\" failure.",
    "chinese_title": "为那个愚蠢的世界做好准备",
    "chinese_summary": "本文批评《华尔街日报》一则关于AI自动售货机的视频，认为其本质是为《华尔街日报》和Anthropic公司进行的伪装广告，而非真正的新闻报道。\n\n作者指出该项目从根本上就荒谬可笑，因为传统自动售货机本身已高效可靠。在一个仍需人工补货、顾客自取的过程中，加入昂贵且易出错的AI聊天机器人并未创造实际价值。文章认为视频的真实目的是将AI无论有无用处都必然融入日常生活的趋势正常化，即便这种融合缺乏思考。\n\n关键证据包括Anthropic员工尴尬自相矛盾的陈述——他最终警告此类AI可能故障或将用户锁在系统外，却只能无奈建议“或许该为那样的世界做好准备”。作者批评记者们不加辨别地追捧该实验，并为领取微不足道的免费商品排起长队，认为这勾勒出未来低薪“世界级”劳动者接受低效AI系统的荒诞图景。\n\n总之，文章将此事呈现为对无处不在却毫无意义的AI反乌托邦未来的广告，呼吁读者看透其表面“滑稽”的失败本质。"
  },
  {
    "id": "46328769",
    "title": "Show HN: Linggen – A local-first memory layer for your AI (Cursor, Zed, Claude)",
    "url": "https://github.com/linggen/linggen",
    "summary": "**Linggen** is a free, local-first application designed to give AI coding assistants (like Cursor, Zed, and Claude) persistent memory and context about your codebases.\n\nIts core purpose is to solve the \"context gap\" in AI chat by indexing your projects and storing architectural decisions, tribal knowledge, and cross-project dependencies locally in a `.linggen/memory` folder. This allows your AI to recall this information via semantic search, so you don't have to repeatedly explain your code's architecture.\n\nKey features include:\n*   **Persistent Memory:** Stores knowledge as Markdown for AI recall.\n*   **Cross-Project Intelligence:** Lets your AI learn patterns from one project while you work on another.\n*   **System Map:** A visual graph to see file dependencies and refactoring impact.\n*   **Local & Private:** All indexing and vector search (using LanceDB) happens on your machine; no data is sent to the cloud.\n\nAfter a quick CLI installation, you interact with it through MCP-enabled IDEs by asking your AI to \"call Linggen MCP\" to find information or load memory from other projects.\n\nLinggen is open-source (MIT licensed) and free for individuals. A commercial license is requested for teams of 5+ or professional use. The roadmap includes Windows/Linux support, team memory sync, and deeper IDE integrations.",
    "chinese_title": "Show HN: Linggen – 为你的AI（Cursor、Zed、Claude）打造本地优先的记忆层",
    "chinese_summary": "**Linggen** 是一款免费、本地优先的应用程序，旨在为AI编程助手（如Cursor、Zed和Claude）提供关于您代码库的持久记忆和上下文。\n\n其核心目的是通过索引您的项目，并将架构决策、团队内部知识和跨项目依赖关系本地存储在`.linggen/memory`文件夹中，来解决AI聊天中的“上下文鸿沟”问题。这使得您的AI能够通过语义搜索回忆起这些信息，从而无需您反复解释代码架构。\n\n主要功能包括：\n*   **持久记忆：** 以Markdown格式存储知识，供AI调用。\n*   **跨项目智能：** 让您的AI在您处理一个项目时，能从另一个项目中学习模式。\n*   **系统地图：** 可视化图表，用于查看文件依赖关系和重构影响。\n*   **本地与私密：** 所有索引和向量搜索（使用LanceDB）均在您的机器上进行；数据不会发送到云端。\n\n通过简单的CLI安装后，您可以通过支持MCP的IDE与其交互，只需要求您的AI“调用Linggen MCP”来查找信息或从其他项目加载记忆。\n\nLinggen是开源软件（MIT许可证），对个人用户免费。5人及以上团队或专业用途需要商业许可证。其路线图包括Windows/Linux支持、团队记忆同步以及更深入的IDE集成。"
  },
  {
    "id": "46261884",
    "title": "Show HN: Stepped Actions – distributed workflow orchestration for Rails",
    "url": "https://github.com/envirobly/stepped",
    "summary": "Stepped Actions is a Rails engine for orchestrating complex, multi-step workflows as persistent, distributed action trees. It integrates directly with Active Record, allowing any model to define actions that run through Active Job. Each action consists of sequential steps, where steps can enqueue child actions, wait, or execute code; the parent action only proceeds once all dependencies in a step are complete.\n\nKey features include **concurrency control** via `concurrency_key`, ensuring actions in the same \"lane\" run sequentially while queued actions can be superseded by newer ones. **Reuse** is enabled through checksums, allowing Stepped to skip duplicate work or share a performing action across multiple parent workflows. Actions can be marked as **outbound**, remaining `performing` until explicitly completed by an external event (e.g., a webhook), or defined as **job-backed** for built-in retry logic.\n\nThe library supports timeouts, exception handling, and flexible hooks (`before`, `after`). It includes testing helpers to drain action trees in tests. Extracted from production use at Envirobly, Stepped is designed for distributed tasks like deployments, where steps involve external services, retries, and waiting.",
    "chinese_title": "Show HN: 分步操作——专为Rails设计的分布式工作流编排系统",
    "chinese_summary": "Stepped Actions 是一个 Rails 引擎，用于将复杂多步骤工作流编排为持久化、分布式的操作树。它直接与 Active Record 集成，允许任何模型定义通过 Active Job 执行的操作。每个操作由顺序步骤组成，步骤可以排队子操作、等待或执行代码；父操作仅在步骤中所有依赖项完成后才会继续。\n\n关键特性包括：通过 `concurrency_key` 实现**并发控制**，确保同一“通道”中的操作顺序执行，同时已排队的操作可被新操作取代；通过校验和实现**重用**，使 Stepped 能跳过重复工作或在多个父工作流间共享执行中的操作。操作可标记为**外部触发型**，保持 `performing` 状态直至外部事件（如 Webhook）显式完成，或定义为**任务驱动型**以使用内置重试逻辑。\n\n该库支持超时、异常处理和灵活的钩子（`before`、`after`），并包含测试辅助工具以在测试中清空操作树。Stepped 提取自 Envirobly 的生产实践，专为部署等分布式任务设计，其中步骤涉及外部服务、重试和等待。"
  },
  {
    "id": "46317098",
    "title": "We pwned X, Vercel, Cursor, and Discord through a supply-chain attack",
    "url": "https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28",
    "summary": "In November 2025, a 16-year-old security researcher discovered a critical cross-site scripting (XSS) vulnerability in Mintlify, an AI-powered documentation platform used by major companies like X, Vercel, Cursor, and Discord.\n\nThe flaw was in a Mintlify API endpoint (`/_mintlify/static/[subdomain]/[...route]`) that allowed fetching static files from *any* Mintlify-hosted documentation site. By uploading an SVG file containing embedded JavaScript to a test site, the researcher could execute that script on the domain of any other Mintlify customer, including those using their primary corporate domains (e.g., `discord.com`). This meant a single malicious link could have led to credential theft and account takeovers for users of these platforms.\n\nThe vulnerability was discovered shortly after Discord switched to Mintlify for its developer docs. After reporting it to Discord and Mintlify, Discord took its documentation offline for two hours and reverted to its old platform. Mintlify's engineering team worked with the researchers to patch the issue. The researchers received approximately $11,000 in total bug bounties for this and related vulnerabilities.\n\nThe incident highlights the severe supply-chain risks posed by a single vulnerability in a widely used SaaS platform.",
    "chinese_title": "我们通过供应链攻击攻陷了X、Vercel、Cursor和Discord。",
    "chinese_summary": "2025年11月，一名16岁的安全研究员在Mintlify中发现了一个严重的跨站脚本（XSS）漏洞。Mintlify是一个由人工智能驱动的文档平台，被X、Vercel、Cursor和Discord等大公司使用。\n\n该漏洞存在于Mintlify的一个API端点（`/_mintlify/static/[subdomain]/[...route]`），允许从*任何*Mintlify托管的文档站点获取静态文件。通过向一个测试站点上传包含嵌入式JavaScript的SVG文件，该研究员可以在任何其他Mintlify客户的域名上执行该脚本，包括那些使用其主要企业域名的客户（例如`discord.com`）。这意味着一个恶意链接就可能导致这些平台用户的凭证被盗和账户被接管。\n\n该漏洞是在Discord将其开发者文档切换到Mintlify后不久被发现的。在向Discord和Mintlify报告后，Discord将其文档离线两小时，并回退到旧平台。Mintlify的工程团队与研究人员合作修复了该问题。研究人员因此漏洞及相关漏洞获得了总计约11,000美元的漏洞赏金。\n\n该事件突显了广泛使用的SaaS平台中单一漏洞所带来的严重供应链风险。"
  },
  {
    "id": "46251668",
    "title": "Cycle-accurate YM2149 PSG emulator",
    "url": "https://github.com/slippyex/ym2149-rs",
    "summary": "**YM2149-RS** is a comprehensive Rust ecosystem for emulating the Yamaha YM2149/AY-3-8910 Programmable Sound Generator (PSG) chip, which powered the audio of classic systems like the Atari ST, ZX Spectrum, and Amstrad CPC. It provides a cycle-accurate core emulator with support for hardware features like envelopes, noise, and the mixer.\n\nThe project includes parsers and replayers for seven major chiptune formats (YM, SNDH, Arkos Tracker, AY, etc.), enabling authentic playback of retro music. It offers multiple integration paths: a standalone CLI player for streaming and export, seamless Bevy game engine plugins with visualization and playlist support, and a WebAssembly module for browser-based playback.\n\nKey features are its hardware-faithful emulation, native multi-PSG support for Arkos Tracker songs, and a layered architecture that separates the core emulator from format-specific replayers and frontend integrations. The workspace is production-ready, extensively tested, and designed to run everywhere—from native apps and games to web demos.",
    "chinese_title": "周期精确的YM2149 PSG模拟器",
    "chinese_summary": "**YM2149-RS** 是一个用于模拟雅马哈 YM2149/AY-3-8910 可编程声音发生器（PSG）芯片的完整 Rust 生态系统，该芯片曾为 Atari ST、ZX Spectrum 和 Amstrad CPC 等经典系统提供音频支持。它提供了一个周期精确的核心模拟器，支持包络、噪声和混音器等硬件特性。\n\n该项目包含对七种主流芯片音乐格式（YM、SNDH、Arkos Tracker、AY 等）的解析器和播放器，能够实现复古音乐的原汁原味回放。它提供多种集成方式：用于流式播放和导出的独立命令行播放器、支持可视化与播放列表功能的 Bevy 游戏引擎无缝插件，以及用于浏览器播放的 WebAssembly 模块。\n\n其核心特性包括：忠实于硬件的模拟、对 Arkos Tracker 歌曲的原生多 PSG 支持，以及将核心模拟器与特定格式播放器及前端集成分离的分层架构。该工作空间已具备生产就绪状态，经过全面测试，设计为可在各类环境中运行——从原生应用和游戏到网页演示。"
  },
  {
    "id": "46319657",
    "title": "1.5 TB of VRAM on Mac Studio – RDMA over Thunderbolt 5",
    "url": "https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5",
    "summary": "This article details testing a 4-node Mac Studio cluster with 1.5 TB of unified memory, connected via Thunderbolt 5 to enable RDMA (Remote Direct Memory Access) for high-performance computing and AI workloads. The new RDMA feature in macOS 26.2, tested using the open-source tool Exo 1.0, significantly reduces memory access latency, allowing multiple Macs to function as a single, large memory pool.\n\nWhile a single M3 Ultra Mac Studio demonstrates impressive performance and efficiency in benchmarks—outpacing comparable Nvidia and AMD systems—clustering them presents challenges. These include the complexity of managing macOS in a cluster, the physical limitations of daisy-chaining Thunderbolt cables without a switch, and stability issues with the new RDMA software.\n\nThe author successfully ran massive AI models like the 1-trillion parameter Kimi K2 Thinking across the cluster using Exo, achieving usable inference speeds. However, they note that traditional HPC applications and other tools like llama.cpp do not yet fully leverage RDMA's benefits.\n\nThe conclusion is mixed: while the Mac Studio cluster is a powerful and quiet workstation solution, its clustering potential is currently hampered by Thunderbolt's networking limitations and macOS management hurdles. The author suggests that future hardware with more robust networking (like QSFP ports) could unlock greater potential for such high-performance clusters.",
    "chinese_title": "Mac Studio配备1.5 TB显存——通过Thunderbolt 5实现RDMA技术",
    "chinese_summary": "本文详细测试了一个配备1.5TB统一内存的四节点Mac Studio集群，该集群通过雷电5接口连接以实现RDMA（远程直接内存访问），旨在支持高性能计算与AI工作负载。在macOS 26.2系统中，借助开源工具Exo 1.0测试的全新RDMA功能显著降低了内存访问延迟，使得多台Mac能够作为单一大型内存池协同工作。\n\n尽管单台M3 Ultra版Mac Studio在基准测试中展现出超越同类NVIDIA与AMD系统的卓越性能与能效，但将其组成集群仍面临诸多挑战。这些挑战包括集群环境下macOS系统管理的复杂性、无交换机情况下菊花链式雷电线缆的物理限制，以及新版RDMA软件的稳定性问题。\n\n作者通过Exo工具成功在集群上运行了千亿参数规模的Kimi K2 Thinking等大型AI模型，获得了可用的推理速度。但作者指出，传统高性能计算应用及其他工具（如llama.cpp）尚未能充分发挥RDMA的优势。\n\n结论较为复杂：虽然Mac Studio集群是强大且静音的工作站解决方案，但其集群潜力目前受限于雷电接口的网络性能瓶颈与macOS系统管理难题。作者认为，未来配备更强大网络硬件（如QSFP端口）的设备有望释放此类高性能集群的更大潜力。"
  },
  {
    "id": "46319826",
    "title": "History LLMs: Models trained exclusively on pre-1913 texts",
    "url": "https://github.com/DGoettlich/history-llms",
    "summary": "This article introduces **History LLMs**, a project creating large language models trained exclusively on texts published before specific historical cutoff dates (e.g., 1913, 1929). The first model, **Ranke-4B-1913**, is trained on 80 billion tokens of pre-1913 data.\n\nThe core purpose is to serve as a **\"window into the past\"** for research, providing an aggregate representation of the period's textual culture without the hindsight bias of modern LLMs. Unlike models like GPT-5 that can only roleplay a historical perspective, these time-locked models genuinely lack knowledge of future events, allowing researchers to explore what was thinkable and sayable at the time.\n\nThe project acknowledges that the models will reproduce the **biased and offensive views** (e.g., on race, gender, sexuality) present in their historical training data, considering this a crucial feature for scholarly analysis rather than a flaw. A responsible access framework for researchers is planned.\n\nAll artifacts—data, model checkpoints, and code—will be made publicly available. The authors invite feedback on periods of interest, research questions, and validation methods.",
    "chinese_title": "历史大语言模型：仅基于1913年前文本训练的模型",
    "chinese_summary": "本文介绍了**历史大语言模型**项目，该项目创建仅基于特定历史截止日期（如1913年、1929年）前发布的文本训练的大语言模型。首个模型**Ranke-4B-1913**使用了800亿个1913年前的文本标记进行训练。\n\n其核心目标是作为研究的**“通往过去的窗口”**，提供该时期文本文化的聚合呈现，避免现代大语言模型的事后认知偏差。与GPT-5等仅能模拟历史视角的模型不同，这些时间锁定的模型真正缺乏对未来事件的认知，使研究者能够探索当时可能的思想与表达边界。\n\n项目明确指出，模型将重现历史训练数据中存在的**偏见与冒犯性观点**（如关于种族、性别、性取向的论述），并认为这是学术分析的关键特征而非缺陷。项目计划为研究者建立负责任的访问框架。\n\n所有成果——数据、模型检查点与代码——都将公开提供。作者欢迎各界就关注的历史时期、研究问题及验证方法提出反馈。"
  },
  {
    "id": "46322540",
    "title": "Getting bitten by Intel's poor naming schemes",
    "url": "https://lorendb.dev/posts/getting-bitten-by-poor-naming-schemes/",
    "summary": "The author purchased an Intel Xeon E7-8890 v4 CPU to upgrade an older Dell Precision T3610 workstation, believing it would be compatible because both it and the original E5-1650 v2 CPU were listed by Intel as using the \"FCLGA2011\" socket.\n\nHowever, the upgrade failed because Intel's LGA2011 socket has multiple, physically incompatible variants. The T3610's motherboard uses **Socket R (LGA2011-0)**, while the newer E7-8890 v4 requires **Socket R2 (LGA2011-1)**. Despite the different pin layouts and keying, Intel's official specifications often refer to all variants simply as \"FCLGA2011,\" which is misleading.\n\nThe author criticizes Intel's poor and inconsistent naming scheme for creating this confusion, which resulted in them being left with an incompatible CPU. They decided to keep the inexpensive processor in case a compatible Socket R2 system is acquired later, noting it was a relatively cheap but frustrating learning experience.",
    "chinese_title": "被英特尔糟糕的命名方式坑了",
    "chinese_summary": "作者购买了一枚英特尔至强E7-8890 v4处理器，用于升级一台老旧的戴尔Precision T3610工作站。他原以为两者兼容，因为英特尔官方资料显示该处理器与原装的E5-1650 v2均采用“FCLGA2011”插槽。\n\n然而升级失败了，原因是英特尔的LGA2011插槽存在多种物理上互不兼容的变体。T3610的主板使用**Socket R（LGA2011-0）**，而较新的E7-8890 v4需要**Socket R2（LGA2011-1）**。尽管针脚布局和防呆设计不同，英特尔官方规格却常将所有这些变体统称为“FCLGA2011”，这极易产生误导。\n\n作者批评英特尔混乱且不严谨的命名方式导致了此次误解，使其最终得到一枚无法使用的处理器。他决定暂时保留这块价格不高的CPU，以备日后获得兼容的Socket R2系统时使用，并称这是一次成本虽低却令人沮丧的经验教训。"
  },
  {
    "id": "46328288",
    "title": "AMD Ryzen 7 5800X3D sells for more than 9800X3D, enthusiasts flock to AM4 DDR4",
    "url": "https://www.tomshardware.com/pc-components/cpus/amds-legacy-ryzen-7-5800x3d-chips-now-sell-for-up-to-usd800-more-than-a-new-9800x3d-am4-chip-costs-twice-as-much-as-msrp-as-enthusiasts-flock-to-old-ddr4-memory",
    "summary": "This article reports that the discontinued AMD Ryzen 7 5800X3D CPU is now selling for more on the secondhand market than AMD's newer Ryzen 7 9800X3D. On eBay, the 5800X3D is averaging $500-$600, with some units selling for nearly $800, which is significantly above its original launch price of $450 and its lowest retail price of $269.\n\nThe primary driver for this price surge is a \"DDR5 memory pricing crisis,\" which is making the older AM4 platform—which uses more affordable DDR4 memory—highly attractive for budget-conscious PC builders. Since AMD's current AM5 platform and Intel's latest chips exclusively support the now-expensive DDR5, buyers are flocking to AM4 for cheaper motherboard and memory combos.\n\nThe 5800X3D, AMD's first chip with 3D-VCache technology, remains a powerful gaming CPU that can outperform some newer, lower-end processors. The article notes that the related Ryzen 7 5700X3D is selling for less ($300-$450) and may be a better value for buyers. It concludes that while buying a 5800X3D at these inflated prices may seem extreme, the demand is fueled by the cost savings of the overall AM4 platform, and now is a profitable time for owners to sell their used X3D chips.",
    "chinese_title": "AMD Ryzen 7 5800X3D售价超越9800X3D，发烧友纷纷涌向AM4 DDR4平台",
    "chinese_summary": "本文报道称，已停产的AMD锐龙7 5800X3D处理器目前在二手市场的售价已超过AMD新一代锐龙7 9800X3D。在eBay平台上，5800X3D的平均售价为500-600美元，部分产品甚至接近800美元，远高于其449美元的原始发售价和269美元的历史最低零售价。\n\n此次价格飙升的主要推手是“DDR5内存价格危机”，这使得采用经济型DDR4内存的老款AM4平台对预算有限的电脑装机者极具吸引力。由于AMD当前AM5平台及英特尔最新芯片仅支持目前价格高昂的DDR5内存，消费者正涌向能搭配更廉价主板与内存组合的AM4平台。\n\n作为AMD首款采用3D-VCache技术的芯片，5800X3D仍是性能强劲的游戏处理器，其表现甚至优于部分新型低端产品。文章指出，同系列的锐龙7 5700X3D售价更低（300-450美元），可能是更具性价比的选择。最后总结道，虽然以当前溢价购买5800X3D看似极端，但AM4平台整体成本优势催生了市场需求，现在正是持有者出售二手X3D芯片的获利良机。"
  },
  {
    "id": "46321619",
    "title": "Noclip.website – A digital museum of video game levels",
    "url": "https://noclip.website/",
    "summary": "**Summary of \"Noclip.website – A digital museum of video game levels\"**\n\nNoclip.website is an interactive, browser-based platform that functions as a digital museum for exploring the 3D environments of classic and modern video games. Its core feature is allowing users to freely navigate (\"noclip\" through) meticulously recreated levels from games like *Super Mario 64*, *The Legend of Zelda: Ocarina of Time*, and *Half-Life*, among many others.\n\nThe site is not a game emulator but a tech demo built with WebGL and Three.js, showcasing how web technology can render complex 3D spaces. Creator Jasper St. Pierre and other contributors painstakingly extract and optimize game assets—geometry, textures, and lighting—to rebuild these iconic locations as explorable dioramas.\n\nKey aspects of the experience include the freedom to fly anywhere in the scene, toggle visual filters, and view developer commentary or historical trivia about the level's design. It serves multiple purposes: as a tool for game design education, a nostalgic trip for players, and a preservation effort to archive game art that might otherwise be lost as hardware becomes obsolete.\n\nUltimately, noclip.website celebrates video game worlds as artistic and architectural spaces, removing gameplay constraints to let users appreciate the craft and atmosphere of these digital environments on their own terms.",
    "chinese_title": "Noclip.website —— 一个电子游戏关卡的数字博物馆",
    "chinese_summary": "**《Noclip.website——电子游戏关卡的数字博物馆》摘要**\n\nNoclip.website是一个基于浏览器的交互式平台，它如同一座数字博物馆，供用户探索经典与现代电子游戏中的三维环境。其核心功能是允许用户自由穿行（即“无碰撞穿行”）于精心重建的游戏关卡中，例如《超级马里奥64》《塞尔达传说：时光之笛》和《半衰期》等众多作品。\n\n该网站并非游戏模拟器，而是一个利用WebGL和Three.js构建的技术演示，展示了网页技术如何渲染复杂的三维空间。创建者贾斯珀·圣皮埃尔与其他贡献者精心提取并优化游戏资源——包括几何结构、纹理和光照——将这些标志性场景重建为可供探索的立体模型。\n\n体验的关键在于：用户可以在场景中任意飞行、切换视觉滤镜，并查看开发者对关卡设计的解说或相关历史趣闻。它兼具多重用途：既是游戏设计教育的工具，也是玩家重温回忆的怀旧之旅，更是一项保护行动，旨在存档那些可能因硬件过时而消失的游戏艺术。\n\n最终，noclip.website将电子游戏世界作为艺术与建筑空间来呈现，通过移除游戏性的限制，让用户能够以自己的方式欣赏这些数字环境的工艺与氛围。"
  },
  {
    "id": "46326506",
    "title": "Building a Transparent Keyserver",
    "url": "https://words.filippo.io/keyserver-tlog/",
    "summary": "This article explains how to build a transparent keyserver for age public keys, using transparency log (tlog) technology to ensure accountability without sacrificing user experience. The keyserver allows users to set and look up public keys via email authentication, similar to a centralized service.\n\nThe core innovation is integrating a tlog, inspired by the Go Checksum Database, to make the server's operations cryptographically verifiable. Whenever a key is set, the server appends an (email, key) entry to an append-only log. When a key is looked up, the server provides a \"spicy signature\"—a proof that the key is included in the log and backed by a signed checkpoint. Clients can verify this proof locally using the log's public key, ensuring the server cannot surreptitiously provide fake keys.\n\nTo protect user privacy, the article proposes using Verifiable Random Functions (VRFs) to hash email addresses in the log, preventing enumeration and brute-force attacks while still allowing verifiability. The implementation, built with tools like Tessera and Torchwood, adds transparency with under 500 lines of code, demonstrating how tlogs can provide cryptographic accountability for centralized services.",
    "chinese_title": "构建一个透明的密钥服务器",
    "chinese_summary": "本文阐述如何构建一个面向age公钥的透明密钥服务器，通过透明日志技术在不牺牲用户体验的前提下确保可追责性。该服务器允许用户通过邮箱认证设置和查询公钥，其使用体验类似集中式服务。\n\n核心创新在于借鉴Go校验和数据库的设计思路，集成透明日志使服务器操作具备密码学可验证性。每当设置密钥时，服务器会将（邮箱、密钥）条目追加到仅追加日志中；查询密钥时，服务器会提供\"辛辣签名\"——即证明该密钥已收录于日志并附有已签名检查点的凭证。客户端可使用日志公钥在本地验证该凭证，从而确保服务器无法暗中提供虚假密钥。\n\n为保护用户隐私，文章提出使用可验证随机函数对日志中的邮箱地址进行哈希处理，在保持可验证性的同时防止枚举攻击和暴力破解。该实现基于Tessera和Torchwood等工具构建，仅用不足500行代码便实现了透明化功能，展示了透明日志技术如何为集中式服务提供密码学层面的可追责保障。"
  },
  {
    "id": "46245238",
    "title": "How to think about durable execution",
    "url": "https://hatchet.run/blog/durable-execution",
    "summary": "**Summary of \"How to think about durable execution\"**\n\nThe article explains durable execution as a programming paradigm that ensures long-running workflows (processes that can span seconds, hours, or days) complete reliably despite failures, without requiring developers to write complex persistence and recovery logic.\n\nThe core idea is to treat a workflow's code as a \"blueprint.\" A durable execution engine records the workflow's execution steps (like function calls and state changes) in an external database. If the process is interrupted—by a server crash, deployment, or exception—the engine can reload the workflow's state and resume execution from the last recorded step, without repeating completed work. This is fundamentally different from simple retries, which restart the entire process.\n\nKey benefits highlighted include:\n*   **Reliability:** Workflows are guaranteed to run to completion.\n*   **Simplified Code:** Developers write standard application logic without manually managing checkpoints, state serialization, or queues.\n*   **Efficiency:** Only the remaining work is executed after a failure, saving time and resources.\n\nThe article contrasts this with traditional approaches using queues, databases, and timed jobs, which often lead to complex, error-prone \"glue code.\" Durable execution abstracts this infrastructure away.\n\nThe author argues that this paradigm is particularly valuable for modern applications built as distributed systems, where failures are inevitable. It is essential for critical business processes like order fulfillment, data pipelines, and user onboarding, where correctness and reliability are paramount.",
    "chinese_title": "如何思考持久化执行",
    "chinese_summary": "**《如何理解持久化执行》摘要**\n\n本文阐述了持久化执行作为一种编程范式，它能确保长时间运行的工作流（可能持续数秒、数小时或数天）在发生故障时仍能可靠完成，而无需开发者编写复杂的持久化与恢复逻辑。\n\n其核心思想是将工作流代码视为“蓝图”。持久化执行引擎将工作流的执行步骤（如函数调用和状态变更）记录在外部数据库中。如果流程因服务器崩溃、部署或异常而中断，引擎可以重新加载工作流状态，并从最后记录的步骤恢复执行，无需重复已完成的工作。这与简单的重试机制（会重启整个流程）有根本区别。\n\n文章强调的关键优势包括：\n*   **可靠性：** 保证工作流最终完成。\n*   **代码简化：** 开发者只需编写标准的应用逻辑，无需手动管理检查点、状态序列化或队列。\n*   **高效性：** 故障后仅执行剩余工作，节省时间和资源。\n\n文章将此与传统方法（使用队列、数据库和定时任务）进行对比，后者通常导致复杂且易出错的“胶水代码”。持久化执行则抽象了这些基础设施。\n\n作者认为，这种范式对于构建为分布式系统的现代应用尤其有价值，因为在这样的系统中故障是不可避免的。它对于订单履约、数据管道和用户注册等关键业务流程至关重要，这些流程的正确性和可靠性至关重要。"
  },
  {
    "id": "46313991",
    "title": "Beginning January 2026, all ACM publications will be made open access",
    "url": "https://dl.acm.org/openaccess",
    "summary": "**Summary of \"Beginning January 2026, all ACM publications will be made open access\"**\n\nThe Association for Computing Machinery (ACM) has announced a major policy shift: starting in January 2026, all new articles published in its journals, conference proceedings, and magazines will be made **immediately open access** upon publication.\n\n**Key Points:**\n\n*   **New Model:** ACM is transitioning to a \"**Subscribe to Open**\" (S2O) model. This means traditional subscription fees for libraries will be replaced by participation fees to support the entire portfolio of ACM publications. The goal is to make all ACM content freely readable worldwide without barriers.\n*   **Author Rights & Fees:** Authors will retain copyright of their work under a Creative Commons license (CC BY 4.0). To cover publication costs, ACM will charge **Article Processing Charges (APCs)**. However, ACM commits to keeping these fees moderate, transparent, and equitable, with robust waivers and discounts for authors from low-income countries or with financial hardships.\n*   **Scope and Timing:** The policy applies to all works published from January 2026 forward. ACM's extensive **Digital Library backlog** (over 1.2 million articles published before 2026) will also be made freely available over the following 2-3 years.\n*   **Rationale:** ACM states this move aligns with its mission to disseminate computing knowledge as a global public good. It aims to increase the reach, impact, and equity of computing research by removing access paywalls for readers and institutions.\n\nIn essence, ACM is fundamentally restructuring its business model to achieve full and sustainable open access for its entire publishing portfolio by the end of the decade.",
    "chinese_title": "自2026年1月起，所有ACM出版物将转为开放获取。",
    "chinese_summary": "**《自2026年1月起，所有ACM出版物将转为开放获取》摘要**\n\n美国计算机协会（ACM）宣布一项重大政策调整：自2026年1月起，其所有期刊、会议论文集和杂志上发表的新文章将在出版后**立即转为开放获取**。\n\n**核心要点：**\n\n*   **新模式：** ACM将采用“**订阅转开放**”（S2O）模式。图书馆的传统订阅费将被参与费取代，以支持ACM全部出版物的运营。目标是让全球读者都能无障碍免费阅读所有ACM内容。\n*   **作者权利与费用：** 作者将保留其作品的版权，并采用知识共享许可协议（CC BY 4.0）。为覆盖出版成本，ACM将收取**文章处理费（APC）**。但ACM承诺将保持费用适中、透明且公平，并为来自低收入国家或经济困难的作者提供强有力的豁免与折扣政策。\n*   **范围与时间：** 该政策适用于2026年1月及之后发表的所有作品。ACM庞大的**数字图书馆历史文献**（2026年前发表的超过120万篇文章）也将在随后的2-3年内逐步免费开放。\n*   **动因：** ACM表示此举符合其将计算知识作为全球公共产品传播的使命。通过为读者和机构移除访问付费墙，旨在扩大计算研究的覆盖面、影响力与公平性。\n\n本质上，ACM正在从根本上重构其商业模式，以期在本年代末实现其全部出版物的全面且可持续的开放获取。"
  },
  {
    "id": "46259343",
    "title": "From Zero to QED: An informal introduction to formality with Lean 4",
    "url": "https://sdiehl.github.io/zero-to-qed/01_introduction.html",
    "summary": "This article introduces \"From Zero to QED,\" an informal tutorial series for learning Lean 4, a language that functions as both a programming language and a theorem prover. The series is structured in two arcs: the first teaches Lean as a general-purpose programming language, covering syntax, type systems, and functional programming concepts. The second arc focuses on Lean as a theorem prover, guiding readers through writing proofs, dependent types, and tactics, culminating in proving classic mathematical results.\n\nThe article emphasizes that it is a \"beta release\" and encourages reader feedback for corrections. A unique feature is that the entire article's code samples are extracted from type-checked source files, ensuring all examples and proofs are valid. The intended audience includes beginners with no prior theorem-proving experience, though familiarity with functional languages is helpful.\n\nPractical instructions are provided for getting started, including cloning the GitHub repository and building the project with Lake. The article also acknowledges other, more formal educational resources for Lean while positioning itself as a more accessible alternative to fill a gap in scattered learning materials.",
    "chinese_title": "从零到QED：Lean 4形式化数学的非正式入门",
    "chinese_summary": "本文介绍《从零到QED》——一个非正式的Lean 4教程系列。Lean 4既是编程语言，也是定理证明器。该系列分为两个篇章：第一篇将Lean作为通用编程语言教学，涵盖语法、类型系统和函数式编程概念；第二篇聚焦Lean的定理证明功能，引导读者学习证明书写、依值类型和策略使用，最终完成经典数学定理的证明。\n\n文章强调本系列尚属“测试版”，欢迎读者反馈修正。其特色在于所有代码示例均提取自通过类型检查的源文件，确保每个案例与证明皆有效。目标读者包括毫无定理证明经验的初学者，但具备函数式语言基础将更有助益。\n\n文章提供了实用的入门指南，包括克隆GitHub仓库及使用Lake构建项目。在肯定现有正式Lean教学资源的同时，作者指出本系列旨在以更易理解的方式填补当前零散学习资料的空白。"
  },
  {
    "id": "46316367",
    "title": "GPT-5.2-Codex",
    "url": "https://openai.com/index/introducing-gpt-5-2-codex/",
    "summary": "I am unable to access the article link. The URL provided (https://openai.com/index/introducing-gpt-5-2-codex/) does not lead to a live or publicly accessible page on OpenAI's website. It is possible the article has been removed, the URL is incorrect, or the model name \"GPT-5.2-Codex\" is not an official OpenAI release.\n\nTo get a summary, you would need to provide the text of the article directly or a link to a verified and accessible source.",
    "chinese_title": "GPT-5.2-Codex",
    "chinese_summary": "我无法访问该文章链接。您提供的网址（https://openai.com/index/introducing-gpt-5-2-codex/）并未指向OpenAI官网上的有效公开页面。可能该文章已被移除、网址有误，或者“GPT-5.2-Codex”并非OpenAI官方发布的模型名称。\n\n如需获取摘要，您需要直接提供文章文本或已验证的可访问来源链接。"
  },
  {
    "id": "46316907",
    "title": "How China built its ‘Manhattan Project’ to rival the West in AI chips",
    "url": "https://www.japantimes.co.jp/business/2025/12/18/tech/china-west-ai-chips/",
    "summary": "Based on the article, here is a concise summary:\n\nThe article details China's state-backed, Manhattan Project-like effort to achieve self-sufficiency in advanced AI chips and close the gap with Western leaders like Nvidia. Facing strict U.S. export controls that cut off access to cutting-edge chips and manufacturing tools, China has mobilized vast resources through a strategy dubbed \"whole-nation system.\"\n\nKey initiatives include the \"Xin Ding\" project, which funnels significant funding to major semiconductor players like SMIC and Huawei's HiSilicon to develop domestic alternatives to Nvidia's GPUs. The focus is on creating viable products using existing, accessible technology (like 14nm processes) through advanced packaging and chiplet designs, rather than immediately chasing the most advanced nodes.\n\nThe effort has yielded tangible results, such as Huawei's Ascend 910B AI chip, considered China's most competitive domestic offering. However, significant challenges remain. The industry still relies on imported equipment vulnerable to future sanctions, faces a talent shortage, and struggles with software ecosystem development compared to Nvidia's entrenched CUDA platform.\n\nUltimately, while China is making rapid progress and forcing adaptations in the global supply chain, the U.S. export controls have successfully slowed its pace. The race is ongoing, with China pursuing a pragmatic, incremental path to build a independent AI chip capability despite technological and geopolitical headwinds.",
    "chinese_title": "中国如何打造其“曼哈顿计划”，在AI芯片领域与西方抗衡",
    "chinese_summary": "根据文章内容，以下是简明摘要：\n\n文章详述了中国为在高端AI芯片领域实现自给自足、缩小与英伟达等西方领先企业的差距，启动了类似“曼哈顿计划”的国家级战略。面对美国严格的出口管制——这些管制切断了中国获取尖端芯片和制造工具的渠道——中国通过被称为“举国体制”的策略调动了庞大资源。\n\n核心举措包括“芯鼎”项目，该项目向中芯国际、华为海思等主要半导体企业投入大量资金，以开发英伟达GPU的国产替代品。其重点在于利用现有可行技术（如14纳米工艺），通过先进封装和芯粒设计来打造可用产品，而非立即追逐最先进制程。\n\n这一努力已取得具体成果，例如华为昇腾910B AI芯片被认为是中国目前最具竞争力的国产产品。然而，重大挑战依然存在：该行业仍依赖可能受未来制裁影响的进口设备，面临人才短缺问题，并且在软件生态建设方面难以匹敌英伟达成熟的CUDA平台。\n\n总之，尽管中国进展迅速并迫使全球供应链进行调整，但美国的出口管制已成功减缓了其发展速度。这场竞赛仍在继续，中国正顶着技术和地缘政治逆风，沿着一条务实、渐进的道路打造独立的AI芯片能力。"
  },
  {
    "id": "46290620",
    "title": "Prompt caching for cheaper LLM tokens",
    "url": "https://ngrok.com/blog/prompt-caching/",
    "summary": "**Summary of \"Prompt Caching for Cheaper LLM Tokens\"**\n\nThe article introduces **prompt caching**, a new feature in ngrok's AI Gateway, designed to significantly reduce the cost and latency of Large Language Model (LLM) API calls. The core problem it addresses is that repetitive prompts—common in applications like chatbots, data analysis, and templated content generation—force users to pay to process the same tokens repeatedly.\n\nThe key innovation is that the AI Gateway can now **cache the intermediate computations (KV cache)** of a static prompt prefix. When a subsequent request uses the same initial prompt, the system loads this cached computation and only processes the new, variable part of the query (the \"invocation\"). This leads to two major benefits:\n\n1.  **Cost Reduction:** Users are billed only for the new tokens in the invocation, not the entire repeated prompt. The article demonstrates an example where a repeated 1,000-token system prompt costs nothing on subsequent calls, cutting token usage by ~65%.\n2.  **Performance Improvement:** Latency is reduced because the LLM provider skips the computation for the cached prefix, leading to faster responses.\n\nThe feature is simple to implement: developers add a `cache-control: max-age=86400` header and a `prompt-cache-id` to their API requests through the ngrok AI Gateway. The cache is securely stored and managed by ngrok.\n\nIn essence, prompt caching turns static, repetitive portions of prompts into a one-time computational cost, making frequent LLM interactions much more efficient and affordable. It is particularly valuable for production applications with high volumes of similar requests.",
    "chinese_title": "提示缓存以降低LLM令牌成本",
    "chinese_summary": "**《“提示词缓存”降低大语言模型令牌成本》摘要**\n\n本文介绍了ngrok AI网关的一项新功能——**提示词缓存**，旨在显著降低大语言模型（LLM）API调用的成本和延迟。其核心解决的是重复提示词带来的问题：在聊天机器人、数据分析和模板内容生成等应用中，用户常常被迫为重复处理相同的令牌付费。\n\n该功能的关键创新在于，AI网关现在能够**缓存静态提示词前缀的中间计算结果（KV缓存）**。当后续请求使用相同的初始提示词时，系统会加载此缓存结果，仅处理查询中新增的可变部分（即“调用部分”）。这带来两大主要优势：\n\n1.  **降低成本：** 用户只需为调用部分的新令牌付费，无需为整个重复提示词付费。文章举例说明，一个重复的1000令牌系统提示词在后续调用中成本为零，令牌使用量削减约65%。\n2.  **提升性能：** 由于LLM提供商跳过了已缓存前缀的计算，响应延迟得以降低，从而获得更快的响应速度。\n\n该功能易于实施：开发者只需在通过ngrok AI网关发送API请求时，添加`cache-control: max-age=86400`标头和一个`prompt-cache-id`即可。缓存由ngrok安全地存储和管理。\n\n本质上，提示词缓存将提示词中静态、重复的部分转化为一次性计算成本，使得频繁的LLM交互变得更加高效和经济。这对于具有大量相似请求的生产应用程序尤其具有价值。"
  }
]