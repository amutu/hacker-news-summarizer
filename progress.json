[
  {
    "id": "46403291",
    "title": "Janet Jackson had the power to crash laptop computers (2022)",
    "url": "https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994",
    "summary": "**Summary:**\n\nIn 2022, a story emerged from Windows XP support about a peculiar technical issue: playing Janet Jackson’s “Rhythm Nation” music video could crash certain models of laptops from a major manufacturer. The problem was traced to the song containing a specific audio frequency that matched the natural resonant frequency of the 5400 rpm hard drives used in those laptops. This resonance caused physical disruption to the drives.\n\nThe issue was so pronounced that it had two bizarre effects: it also crashed some competitors’ laptops with the same drives, and even caused a nearby idle laptop to crash if one was playing the video, due to the airborne sound waves.\n\nThe manufacturer’s solution was to implement a custom audio filter in the software to detect and remove the offending frequency during playback. The article speculates that this legacy fix may still be embedded in systems long after the vulnerable hardware was phased out. It also humorously references the Tacoma Narrows Bridge collapse as a classic example of resonance, while noting the bridge’s failure was not actually due to simple resonance.",
    "chinese_title": "珍妮·杰克逊曾有能力导致笔记本电脑崩溃（2022年）",
    "chinese_summary": "**摘要：**\n\n2022年，一则关于Windows XP支持的轶事揭示了一个奇特的技术问题：播放珍妮特·杰克逊的《节奏国度》音乐视频可能导致某主流厂商特定型号的笔记本电脑崩溃。经排查，问题源于这首歌含有特定音频频率，恰好与这些笔记本电脑使用的5400转硬盘的固有共振频率一致。这种共振对硬盘造成了物理干扰。\n\n该问题影响显著，甚至引发了两类怪异现象：不仅会导致使用同款硬盘的竞争品牌笔记本电脑崩溃，还会因声波在空气中传播，使得附近处于闲置状态的笔记本电脑在播放该视频时也发生崩溃。\n\n厂商的解决方案是在软件中植入定制音频过滤器，以在播放时检测并移除问题频率。文章推测，即使易受影响的硬件早已淘汰，这一遗留修复程序可能仍长期嵌入在系统中。文章还幽默地引用了塔科马海峡大桥坍塌事件作为共振的经典案例，同时指出该桥梁的倒塌实际上并非由简单的共振引起。"
  },
  {
    "id": "46403559",
    "title": "Nvidia's $20B Antitrust Loophole (Not an Acquisition)",
    "url": "https://ossa-ma.github.io/blog/groq",
    "summary": "In December 2025, Nvidia executed a $20 billion deal for Groq’s intellectual property and its senior leadership team, but explicitly did not acquire the company itself. This non-traditional structure—framed as a non-exclusive licensing agreement—allowed Nvidia to avoid lengthy antitrust and CFIUS regulatory reviews that a standard acquisition would trigger.\n\nThe primary value was in Groq’s LPU (Language Processing Unit) architecture, which uses massive on-chip SRAM instead of external memory. This offers superior speed and energy efficiency for running AI inference on models up to 70B parameters, posing a potential long-term challenge to Nvidia’s GPU dominance.\n\nThe deal’s unusual carve-out left GroqCloud, the company’s cloud infrastructure business (including a major $1.5B contract with Saudi Arabia), as a separate, weakened entity. This allowed Nvidia to sidestep geopolitical entanglements. The $20 billion price represented a massive premium over Groq’s recent valuation, paying not just for technology but for strategic advantages: neutralizing a competitor, preempting acquisition by rivals like Google or Microsoft, and gaining favorable political access through connections to Trump administration officials linked to Groq’s investors.",
    "chinese_title": "英伟达200亿美元的反垄断漏洞（并非收购）",
    "chinese_summary": "2025年12月，英伟达以200亿美元的交易获得了Groq的知识产权及其高级管理团队，但明确未收购该公司本身。这种非传统架构——被定义为非排他性许可协议——使英伟达避免了标准收购会引发的漫长反垄断和美国外国投资委员会监管审查。\n\n交易的核心价值在于Groq的LPU（语言处理单元）架构，该架构采用大规模片上静态随机存储器而非外部内存。这为运行高达700亿参数的人工智能推理模型提供了卓越的速度与能效，可能对英伟达的GPU主导地位构成长期挑战。\n\n这笔交易的特殊剥离条款使GroqCloud——该公司的云基础设施业务（包括与沙特阿拉伯签订的15亿美元重大合同）——成为独立且被削弱的实体。此举让英伟达得以规避地缘政治纠葛。200亿美元的收购价较Groq近期估值存在巨额溢价，其支付不仅针对技术，更着眼于战略优势：消除竞争对手、阻止谷歌或微软等对手收购，并通过Groq投资者关联的前特朗普政府官员获得有利的政治通道。"
  },
  {
    "id": "46403200",
    "title": "Gpg.fail",
    "url": "https://gpg.fail",
    "summary": "This article, titled \"Gpg.fail,\" announces a series of critical security vulnerabilities discovered in GnuPG (GNU Privacy Guard) and related tools. The author, \"crackticker,\" states that detailed slides, proof-of-concept exploits, and patches will be released soon.\n\nThe core content is a list of at least 13 distinct vulnerabilities, which include:\n\n*   **Signature and encryption flaws:** Attacks allowing for multiple plaintext recovery, signature forgery, and malleability of encrypted messages.\n*   **Parsing and input validation issues:** Path traversal via filenames, memory corruption in ASCII-armor parsing, and problems with packet parsing that could allow adding arbitrary subkeys to keys.\n*   **Hash and output problems:** Incorrect hash calculation leading to truncated plaintext, algorithm downgrades to weak SHA1, and ambiguous output that fails to clearly distinguish verification success.\n*   **Framework-level issues:** Susceptibility to format confusion in the OpenPGP Cleartext Signature Framework.\n*   **Related tool vulnerabilities:** Trusted comment injection attacks in the **minisign** utility.\n\nIn summary, the article serves as a high-level disclosure notice for a wide-ranging set of security weaknesses affecting the integrity, confidentiality, and parsing mechanisms of GnuPG, indicating that detailed technical information and fixes are forthcoming.",
    "chinese_title": "Gpg.fail",
    "chinese_summary": "本文题为《Gpg.fail》，宣布在GnuPG（GNU隐私卫士）及相关工具中发现一系列关键安全漏洞。作者\"crackticker\"表示，详细的演示文稿、概念验证利用代码和补丁即将发布。\n\n核心内容列出了至少13个独立漏洞，包括：\n\n*   **签名与加密缺陷**：可实现多重明文恢复、签名伪造及加密消息可塑性的攻击手段。\n*   **解析与输入验证问题**：通过文件名实现的路径遍历、ASCII封装解析中的内存损坏，以及数据包解析缺陷导致可向密钥添加任意子密钥。\n*   **哈希与输出问题**：错误哈希计算导致明文截断、算法降级至弱SHA1，以及输出模糊未能清晰区分验证成功状态。\n*   **框架级问题**：OpenPGP明文签名框架易受格式混淆攻击。\n*   **相关工具漏洞**：**minisign**工具中存在可信注释注入攻击。\n\n总之，本文作为高级别披露通告，揭示了影响GnuPG完整性、机密性和解析机制的一系列广泛安全弱点，并表明详细技术信息与修复方案即将公布。"
  },
  {
    "id": "46401612",
    "title": "Floor796",
    "url": "https://floor796.com/",
    "summary": "**Summary of \"Floor796\"**\n\n\"Floor796\" is a massive, real-time animated pixel art project created by Russian developer Nikita. It is a single, continuously scrolling digital canvas depicting a fictional, sprawling office floor and its surroundings.\n\nThe project's core concept is to present a \"living snapshot\" of internet and pop culture. The canvas is densely packed with hundreds of characters, scenes, and references from a vast array of sources, including viral memes, famous movies (like Star Wars, The Matrix), video games (Minecraft, Among Us), anime, and notable events from recent internet history.\n\nAll elements are animated and interact with each other in real-time, creating a dynamic, chaotic, and often humorous tableau. The viewer can explore the entire scene by scrolling, discovering new details and gags with each viewing. It is not a game but an interactive artwork meant for observation and discovery.\n\nThe project gained significant viral attention online for its scale, detail, and the nostalgic joy of recognizing countless embedded references. It serves as a unique cultural artifact, capturing the eclectic and interconnected nature of online culture in a single, immersive visual format.",
    "chinese_title": "Floor796",
    "chinese_summary": "**《Floor796》概述**\n\n《Floor796》是俄罗斯开发者尼基塔创作的一个大型实时动画像素艺术项目。它是一幅连续滚动的数字画布，描绘了一个虚构的、不断延伸的办公楼层及其周边环境。\n\n该项目的核心理念是呈现互联网和流行文化的“动态快照”。画布上密集地布满了来自各种来源的数百个角色、场景和彩蛋，包括病毒式传播的网络迷因、著名电影（如《星球大战》《黑客帝国》）、电子游戏（《我的世界》《Among Us》）、动漫以及近期互联网历史上的知名事件。\n\n所有元素都经过动画处理，并实时互动，创造出一个动态、混乱且常常幽默的生动场景。观看者可以通过滚动来探索整个画面，每次观看都能发现新的细节和趣味点。它并非游戏，而是一件旨在供人观察和探索的互动艺术作品。\n\n该项目因其宏大的规模、精细的细节以及识别无数隐藏彩蛋所带来的怀旧乐趣，在网络上获得了广泛的病毒式关注。它作为一个独特的文化载体，以一种沉浸式的视觉形式，捕捉了网络文化兼收并蓄、相互关联的本质。"
  },
  {
    "id": "46368177",
    "title": "Clock Synchronization Is a Nightmare",
    "url": "https://arpitbhayani.me/blogs/clock-sync-nightmare/",
    "summary": "This article explains the profound challenges of clock synchronization in distributed systems. The core problem is the absence of a global clock, as individual computer clocks, driven by imperfect quartz crystals, inevitably drift apart due to temperature changes and manufacturing variations. This skew causes critical failures, such as incorrect build processes, database inconsistencies, and flawed financial transaction ordering.\n\nTo mitigate this, physical synchronization protocols like NTP (accurate to milliseconds) and PTP (accurate to nanoseconds via hardware) are used. However, for applications requiring causal ordering rather than absolute time, logical clocks offer a solution. Lamport timestamps provide a partial order of events, while Vector Clocks can definitively determine causality, albeit with significant overhead.\n\nThe article highlights Google's innovative approach with its Spanner database and TrueTime API. TrueTime combines GPS and atomic clocks to return a time *interval* with a known uncertainty bound (ε). By having transactions wait until their commit timestamp is definitely in the past, Spanner guarantees external consistency across its global infrastructure, demonstrating a sophisticated solution to this fundamental \"nightmare\" of distributed computing.",
    "chinese_title": "时钟同步是一场噩梦",
    "chinese_summary": "本文阐述了分布式系统中时钟同步所面临的深刻挑战。核心问题在于缺乏全局时钟——由于温度变化和制造差异，由非理想石英晶体驱动的单个计算机时钟不可避免地会产生漂移。这种偏差会导致关键故障，例如错误的构建流程、数据库不一致以及金融交易顺序错乱。\n\n为缓解这一问题，业界采用物理同步协议，如精确到毫秒级的NTP协议，以及通过硬件实现纳秒级精度的PTP协议。然而，对于需要因果顺序而非绝对时间的应用场景，逻辑时钟提供了解决方案。Lamport时间戳能提供事件的部分排序，而向量时钟虽会带来显著开销，却能明确判定因果关系。\n\n文章重点介绍了谷歌通过Spanner数据库和TrueTime API实现的创新方案。TrueTime结合GPS与原子钟技术，返回带有已知误差范围（ε）的时间区间。通过让事务等待直到其提交时间戳明确成为过去时点，Spanner在其全球基础设施中保证了外部一致性，为这一分布式计算的根本性“难题”提供了精妙的解决方案。"
  },
  {
    "id": "46403915",
    "title": "Windows 2 for the Apricot PC/Xi",
    "url": "https://www.ninakalinina.com/notes/win2apri/",
    "summary": "This article details the author's multi-year project to port Windows 2.0 to the non-IBM-compatible Apricot PC/Xi, an 8086-based computer from the 1980s. The goal was to run modern productivity software like Microsoft Word and Excel on this vintage hardware.\n\nThe main challenge was creating or adapting the necessary system drivers. The author initially attempted to write a video driver from scratch but abandoned this due to the Apricot's unique, non-standard graphics mode. A breakthrough came by extracting and modifying the existing video and keyboard drivers from a preserved Windows 1.0 port for the Apricot, using custom tools to integrate them into Windows 2.0. A new system driver also had to be written to enable features like the mouse cursor.\n\nThe successful port allows the Apricot PC/Xi (with at least 512KB RAM) to run Windows 2.0 and its applications, including Word, Excel, and various games, leveraging the machine's high-resolution 800x400 monochrome display. The article concludes with a tour of the working system, highlighting its functionality and the expanded software library now available for this historically niche computer.",
    "chinese_title": "Windows 2 for the Apricot PC/Xi",
    "chinese_summary": "本文详述了作者将Windows 2.0移植到非IBM兼容的Apricot PC/Xi（一款1980年代基于8086处理器的计算机）的多年项目。该项目旨在让这台复古硬件能够运行现代办公软件，如Microsoft Word和Excel。\n\n主要挑战在于创建或适配必要的系统驱动程序。作者最初尝试从头编写视频驱动程序，但由于Apricot独特的非标准图形模式而放弃了这一方案。突破来自于从一份保存完好的Apricot版Windows 1.0移植中提取并修改现有的视频和键盘驱动程序，使用定制工具将其集成到Windows 2.0中。此外，还需编写新的系统驱动程序以实现鼠标光标等功能。\n\n成功的移植使Apricot PC/Xi（至少需512KB内存）能够运行Windows 2.0及其应用程序，包括Word、Excel和各种游戏，充分发挥了该机器800x400高分辨率单色显示器的优势。文章最后展示了运行中的系统，重点介绍了其功能以及为这台历史上小众计算机扩展的软件库。"
  },
  {
    "id": "46400251",
    "title": "Show HN: Ez FFmpeg – Video editing in plain English",
    "url": "http://npmjs.com/package/ezff",
    "summary": "**Summary of \"Show HN: Ez FFmpeg – Video editing in plain English\"**\n\nEz FFmpeg is an open-source Node.js package that simplifies video editing by allowing users to describe edits in plain English, which it then translates into FFmpeg commands. It aims to make the powerful but complex FFmpeg tool accessible to users without needing to memorize its intricate syntax.\n\nThe core function of the library is to parse natural language instructions (e.g., \"trim the first 10 seconds,\" \"compress for web,\" \"add a watermark\") and automatically generate the corresponding FFmpeg command-line arguments. This bridges the gap between high-level editing intent and low-level command execution.\n\nKey features and points include:\n*   **Natural Language Interface:** Users can perform tasks like trimming, compressing, converting formats, adding watermarks, and extracting audio by writing simple instructions.\n*   **Automation Friendly:** As a Node.js library, it is designed to be easily integrated into automated workflows, scripts, and applications.\n*   **Open Source:** The package is available on npm (as `ezff`), allowing developers to install, use, and contribute to its development.\n*   **Target Audience:** It is particularly useful for developers who need to programmatically handle video processing in their projects without becoming FFmpeg experts, as well as for users seeking a more intuitive way to run FFmpeg operations.\n\nIn essence, Ez FFmpeg acts as a translator or wrapper, reducing the learning curve and potential for error associated with direct FFmpeg command-line use, thereby democratizing access to professional-grade video processing.",
    "chinese_title": "Show HN: Ez FFmpeg – 用简单英语进行视频编辑",
    "chinese_summary": "**《Show HN: Ez FFmpeg – 用简单英语进行视频编辑》摘要**\n\nEz FFmpeg 是一个开源的 Node.js 包，它通过允许用户用简单英语描述编辑操作，然后将其翻译成 FFmpeg 命令，从而简化视频编辑流程。其目标是让用户无需记忆 FFmpeg 复杂的语法，也能使用这个功能强大但复杂的工具。\n\n该库的核心功能是解析自然语言指令（例如，“剪掉前10秒”、“为网络压缩”、“添加水印”），并自动生成相应的 FFmpeg 命令行参数。这在高层次的编辑意图与低层次的命令执行之间架起了桥梁。\n\n主要特点和要点包括：\n*   **自然语言界面：** 用户可以通过编写简单的指令来执行修剪、压缩、转换格式、添加水印和提取音频等任务。\n*   **自动化友好：** 作为一个 Node.js 库，它设计为易于集成到自动化工作流、脚本和应用程序中。\n*   **开源：** 该包可在 npm（名为 `ezff`）上获取，允许开发者安装、使用并为其开发做出贡献。\n*   **目标受众：** 它特别适用于需要在项目中以编程方式处理视频处理但又不想成为 FFmpeg 专家的开发者，以及寻求更直观方式运行 FFmpeg 操作的用户。\n\n本质上，Ez FFmpeg 充当了一个翻译器或包装器，降低了直接使用 FFmpeg 命令行所带来的学习曲线和出错可能性，从而使专业级视频处理变得更加普及。"
  },
  {
    "id": "46401499",
    "title": "OrangePi 6 Plus Review",
    "url": "https://boilingsteam.com/orange-pi-6-plus-review/",
    "summary": "The OrangePi 6 Plus is a powerful Arm-based single-board computer (SBC) featuring a 12-core CIX CD8180/60 SoC (4x Cortex-A720 @ 2.8 GHz, 4x @ 2.4 GHz, 4x Cortex-A520), an Arm Immortalis-G720 GPU, and a dedicated 30 TOPS NPU. It comes with 16GB/32GB/64GB LPDDR5 RAM, dual M.2 NVMe slots, dual 5GbE ports, and extensive video outputs including HDMI 2.1 and DisplayPort.\n\nThe review highlights its exceptional desktop performance on the provided Debian Bookworm image, offering a snappy, x86-like experience with smooth 4K video playback. However, software support is a noted limitation, as the system relies on an older 6.6 kernel with proprietary drivers; upgrading breaks key hardware functions like high-resolution display output and NPU support. The NPU requires a specific SDK (NeuralONE) for AI tasks.\n\nBenchmarks show impressive CPU performance, rivaling older desktop chips. Gaming via Box64 is possible with some titles, though driver limitations hinder others. The board runs cool and quiet under load but has a relatively high idle power draw (~15W). Priced from $199, it offers strong value for its raw hardware but requires technical tolerance for its immature software ecosystem.",
    "chinese_title": "OrangePi 6 Plus 评测",
    "chinese_summary": "OrangePi 6 Plus是一款基于Arm架构的强大单板计算机，搭载12核CIX CD8180/60 SoC（4核Cortex-A720 @ 2.8 GHz、4核 @ 2.4 GHz、4核Cortex-A520），配备Arm Immortalis-G720 GPU和专用30 TOPS NPU。它提供16GB/32GB/64GB LPDDR5内存、双M.2 NVMe插槽、双5GbE网口，以及包括HDMI 2.1和DisplayPort在内的丰富视频输出接口。\n\n评测指出，在预装的Debian Bookworm系统上，其桌面性能表现卓越，提供流畅迅捷、接近x86的体验，支持丝滑的4K视频播放。但软件支持是明显短板：系统基于较旧的6.6内核与专有驱动，升级会破坏高分辨率显示输出和NPU支持等关键硬件功能。NPU需依赖特定SDK（NeuralONE）运行AI任务。\n\n基准测试显示其CPU性能可媲美旧款桌面芯片。通过Box64可运行部分游戏，但驱动限制影响兼容性。该板卡在高负载下运行凉爽安静，但待机功耗较高（约15W）。起售价199美元，以硬件配置而言性价比突出，但需用户对其不成熟的软件生态具备一定的技术容忍度。"
  },
  {
    "id": "46393992",
    "title": "How uv got so fast",
    "url": "https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html",
    "summary": "**Summary:**\n\nThe article explains that uv's speed advantage over pip stems primarily from design choices and modern Python packaging standards, not just being written in Rust.\n\nKey enabling factors were recent Python Enhancement Proposals (PEPs). PEP 518 (2016) and PEP 621 (2020) allowed dependencies to be declared statically in `pyproject.toml`, eliminating the need to execute arbitrary code from `setup.py` to discover them. PEP 658 (2022) allowed metadata to be fetched directly from PyPI without downloading entire packages.\n\nuv gains speed by dropping legacy support and simplifying workflows: it ignores obsolete formats like `.egg` files, doesn't parse `pip.conf`, skips bytecode compilation by default, and requires virtual environments. It also makes resolver decisions like ignoring overly restrictive upper Python version bounds to reduce backtracking.\n\nMany optimizations are architectural and not Rust-specific: using HTTP range requests to fetch only package metadata, parallel downloads, a global cache with hardlinks, and using the efficient PubGrub resolver algorithm.\n\nWhile Rust provides benefits like zero-copy deserialization, thread-level parallelism, and no interpreter startup overhead, the article argues that the larger performance gains come from uv's modern, streamlined design that leverages new standards and avoids pip's legacy compatibility burden. The core lesson is that static metadata and upfront resolution are foundational for fast package management.",
    "chinese_title": "紫外线为何如此迅速",
    "chinese_summary": "**摘要：**\n\n本文指出，uv相较于pip的速度优势主要源于其设计选择和对现代Python打包标准的运用，而不仅仅是使用Rust语言编写。\n\n关键的推动因素是近期的Python增强提案（PEP）。PEP 518（2016年）和PEP 621（2020年）允许在`pyproject.toml`中静态声明依赖项，从而无需执行`setup.py`中的任意代码来发现依赖。PEP 658（2022年）允许直接从PyPI获取元数据，而无需下载整个软件包。\n\nuv通过放弃对旧版功能的支持并简化工作流程来提升速度：它忽略`.egg`文件等过时格式，不解析`pip.conf`，默认跳过字节码编译，并要求使用虚拟环境。它还在解析依赖时做出决策，例如忽略过于严格的Python版本上限，以减少回溯。\n\n许多优化是架构层面的，并非Rust特有：使用HTTP范围请求仅获取包元数据、并行下载、采用硬链接的全局缓存，以及使用高效的PubGrub解析算法。\n\n尽管Rust带来了零拷贝反序列化、线程级并行和无解释器启动开销等优势，但文章认为，更大的性能提升来自uv现代化、精简的设计，它充分利用了新标准，并避免了pip遗留的兼容性负担。核心启示在于，静态元数据和预先解析是快速包管理的基础。"
  },
  {
    "id": "46364482",
    "title": "Reflections and rantings from a system design interviewer",
    "url": "https://www.calvinbarker.com/blog/reflections-and-rantings-from-a-system-design-interviewer",
    "summary": "This article shares a system design interviewer's reflections on common mistakes candidates make and advice for success. The interviewer's core goal is to assess a candidate's depth of knowledge, independence, collaboration skills, and decision-making under uncertainty.\n\nKey criticisms include candidates overly relying on AI during interviews, failing to research the company beforehand, and not starting their design process with the end customer in mind. The author emphasizes that a system's ultimate non-functional requirement in a for-profit company is to make money, a consideration often overlooked.\n\nWhile praising the popular **Hello Interview** framework for generally improving candidate performance, the author notes two issues: candidates sometimes panic when deviating from its rigid structure, and they disagree with its advice to skip back-of-the-envelope calculations. The author argues these calculations are essential to determine if a complex, distributed system is even necessary, helping to avoid needless complexity.\n\nRecommended resources include *Designing Data-Intensive Applications* by Martin Kleppmann, *System Design Interview – An insider's guide* by Alex Xu, and Hello Interview (with the caveat to remain agile).",
    "chinese_title": "一位系统设计面试官的反思与吐槽",
    "chinese_summary": "本文分享了一位系统设计面试官对候选人常见失误的反思及成功建议。面试官的核心目标是评估候选人的知识深度、独立性、协作能力以及在不确定性下的决策能力。\n\n主要批评包括候选人在面试中过度依赖人工智能、事先未对公司进行研究，以及设计流程未从终端客户角度出发。作者强调，在营利性公司中，系统的最终非功能性要求是创造利润，这一点常被忽视。\n\n作者赞赏流行的**Hello Interview**框架普遍提升了候选人表现，但也指出两个问题：候选人有时在偏离其固定结构时会慌乱，且不认同其跳过粗略估算的建议。作者认为这些估算对于判断是否需要复杂的分布式系统至关重要，有助于避免不必要的复杂性。\n\n推荐资源包括马丁·克莱普曼的《数据密集型应用系统设计》、亚历克斯·徐的《系统设计面试指南》，以及Hello Interview（但建议保持灵活性）。"
  },
  {
    "id": "46365105",
    "title": "Show HN: Mysti – Claude, Codex, and Gemini debate your code, then synthesize",
    "url": "https://github.com/DeepMyst/Mysti",
    "summary": "**Mysti** is a VS Code extension that integrates multiple AI coding assistants (Claude Code, OpenAI Codex, and Google Gemini) into a single interface. Its key innovation is **Brainstorm Mode**, where two different AIs can collaborate to analyze, debate, and synthesize solutions for your code, aiming to produce more robust results than a single agent.\n\nThe tool is designed to work with users' existing AI subscriptions and CLI tools, requiring no extra costs. It offers **16 specialized developer personas** (like Architect or Debugger) to tailor the AI's approach and provides granular **permission controls** over file access.\n\nKey features include a modern chat interface, conversation history, and intelligent plan detection for multiple solution paths. Brainstorm Mode offers two collaboration styles: **Quick Mode** for fast merging of responses and **Full Mode** for in-depth discussion between the AIs.\n\nMysti positions itself as an alternative to single-provider tools like GitHub Copilot, emphasizing multi-agent collaboration, provider flexibility, and user control. It is free for personal and non-commercial use under a Business Source License.",
    "chinese_title": "展示 HN：Mysti – 让 Claude、Codex 和 Gemini 辩论你的代码，然后综合结论",
    "chinese_summary": "**Mysti** 是一款 VS Code 扩展，它将多种 AI 编程助手（Claude Code、OpenAI Codex 和 Google Gemini）集成到单一界面中。其核心创新在于 **头脑风暴模式**，该模式下两种不同的 AI 可以协作分析、讨论并综合代码解决方案，旨在产生比单一智能体更稳健的结果。\n\n该工具设计为与用户现有的 AI 订阅和 CLI 工具配合使用，无需额外费用。它提供 **16 种专业开发者角色**（如架构师或调试员）来定制 AI 的处理方式，并对文件访问提供精细的 **权限控制**。\n\n主要功能包括现代化的聊天界面、对话历史记录以及针对多解决方案路径的智能计划检测。头脑风暴模式提供两种协作风格：**快速模式**用于快速合并响应，以及 **完整模式**用于 AI 之间的深入讨论。\n\nMysti 将自己定位为 GitHub Copilot 等单一供应商工具的替代品，强调多智能体协作、供应商灵活性和用户控制。它在商业源代码许可下对个人和非商业用途免费。"
  },
  {
    "id": "46403955",
    "title": "Scientists Edited Genes Inside a Living Person for First Time, Saved His Life",
    "url": "https://www.popularmechanics.com/science/health/a64815804/crispr-therapy/",
    "summary": "In 2025, a team of U.S. scientists and doctors performed the world's first custom *in vivo* gene therapy, saving the life of a newborn boy named KJ. The infant was diagnosed with a rare, life-threatening genetic disorder called severe carbamoyl phosphate synthetase 1 (CPS1) deficiency, which prevents the body from processing ammonia.\n\nWith a liver transplant not an option due to his age, doctors developed a bespoke CRISPR-based treatment tailored to KJ's specific genetic variant. After six months of preparation, during which KJ was kept on a protein-free diet, he received the first infusion. The therapy was successful: within two weeks, he began tolerating protein normally. He received two subsequent doses and was eventually able to go home.\n\nPublished in the *New England Journal of Medicine*, this case marks a historic milestone as the first time gene editing was performed inside a living person to cure a genetic disease. The researchers emphasize that this proof-of-concept, built on decades of medical research, opens the door to scaling this approach for many other rare genetic disorders, potentially transforming future medical treatments.",
    "chinese_title": "科学家首次在活人体内编辑基因，挽救其生命。",
    "chinese_summary": "2025年，一支由美国科学家和医生组成的团队实施了全球首例定制化体内基因疗法，拯救了名为KJ的新生男婴的生命。这名婴儿被诊断出患有罕见且危及生命的遗传性疾病——严重型氨基甲酰磷酸合成酶1（CPS1）缺乏症，该疾病会导致身体无法正常代谢氨。\n\n由于患儿年龄过小无法进行肝脏移植，医疗团队针对KJ的特异性基因变异，开发了基于CRISPR技术的定制疗法。在为期六个月、严格控制无蛋白饮食的预备期后，KJ接受了首次输注治疗并获得成功：两周内他开始正常耐受蛋白质摄入。后续他又接受两次剂量治疗，最终得以康复回家。\n\n这项发表于《新英格兰医学杂志》的案例标志着历史性里程碑——首次通过在活体内进行基因编辑治愈遗传疾病。研究人员强调，这项基于数十年医学研究的原理验证，为拓展该疗法至众多其他罕见遗传病打开了大门，或将重塑未来医疗格局。"
  },
  {
    "id": "46401938",
    "title": "NMH BASIC",
    "url": "https://t3x.org/nmhbasic/index.html",
    "summary": "NMH BASIC is a compact BASIC interpreter originally written in the 1990s, notable for its small size (under 5KB in early versions) and nostalgic appeal. The article details its history, key features, and evolution across versions.\n\nThe interpreter supports a unique variable and array system where single-letter variables can function as 10-slot arrays, and larger arrays can be created by overlapping variable spaces. Input/output is handled via pre-assigned \"units\" (files or devices), with programs able to redirect I/O but not open or close files. Conditional statements (`IF`) execute the remainder of the line based on the condition, without `THEN` or `ELSE` keywords.\n\nThe article describes three main versions: the original (1.x), NMH BASIC II (updated in 2024 with corrected operator precedence and a more compact listing format), and NMH BASIC III (a work-in-progress version adding string comparison operators and baudot-encoded I/O for paper tape compatibility). The package includes implementations in BASYL-II, 8086 assembly, and T3X/0, along with example programs like a text-mode minesweeper game.",
    "chinese_title": "NMH BASIC",
    "chinese_summary": "NMH BASIC是一款紧凑型BASIC解释器，最初编写于20世纪90年代，以其小巧的体积（早期版本不足5KB）和怀旧魅力而著称。文章详述了其发展历程、核心特性及各版本的演进。\n\n该解释器采用独特的变量与数组系统：单字母变量可作为10位数组使用，通过重叠变量空间还可创建更大数组。输入输出通过预分配的“单元”（文件或设备）处理，程序可重定向I/O但无法打开或关闭文件。条件语句（`IF`）根据条件执行该行剩余指令，不使用`THEN`或`ELSE`关键字。\n\n文章介绍了三个主要版本：原始版（1.x）、NMH BASIC II（2024年更新，修正了运算符优先级并采用更紧凑的列表格式）以及NMH BASIC III（开发中版本，新增字符串比较运算符和兼容纸带传输的博多码I/O功能）。软件包包含BASYL-II、8086汇编和T3X/0语言的实现版本，并附有文本模式扫雷游戏等示例程序。"
  },
  {
    "id": "46345528",
    "title": "Intertapes – collection of found cassette tapes from different locations",
    "url": "https://intertapes.net/",
    "summary": "**Summary of \"Intertapes\"**\n\n\"Intertapes\" is a project centered on a collection of found cassette tapes gathered from various locations. The core concept involves the discovery, preservation, and presentation of these abandoned or lost audio artifacts.\n\nThe project treats these cassettes not as trash, but as cultural and historical fragments. Each tape represents a small, intimate snapshot of someone's life—potentially containing personal mixtapes, recorded conversations, home recordings, or forgotten commercial music. The act of finding them in disparate places adds a layer of mystery and narrative, inviting speculation about their origins and the stories behind them.\n\nBy archiving and sometimes sharing the audio content (ethically, where possible), Intertapes highlights the materiality and nostalgia of the cassette tape format. It serves as an auditory archaeology project, examining the late 20th-century soundscape and the personal histories embedded in this obsolete medium. The collection underscores themes of memory, loss, and the accidental preservation of everyday life, transforming random finds into a curated exploration of human experience through sound.",
    "chinese_title": "Intertapes – 来自不同地点的拾得卡带收藏",
    "chinese_summary": "**《Intertapes》项目概述**\n\n“Intertapes”是一个围绕从各地收集到的废弃卡式磁带展开的项目。其核心理念在于发现、保存并呈现这些被遗弃或遗失的音频载体。\n\n项目并不将这些磁带视为垃圾，而是作为文化与历史的碎片。每一盘磁带都承载着某人生活中一段微小而私密的片段——可能包含个人混音带、录制的对话、家庭录音或被遗忘的商业音乐。在不同地点偶然发现它们的过程，更增添了一层神秘感和叙事性，引人猜测其来源与背后的故事。\n\n通过归档并在可能时合乎伦理地分享这些音频内容，Intertapes强调了卡式磁带这一形式的物质性与怀旧感。它如同一项听觉考古工程，审视着二十世纪末的声音图景，以及这种过时媒介中埋藏的个人历史。该收藏凸显了记忆、遗失与日常生活被偶然保存的主题，将随机发现转化为一场通过声音对人类体验的精心探索。"
  },
  {
    "id": "46401190",
    "title": "Splice a Fibre",
    "url": "https://react-networks-lib.rackout.net/fibre",
    "summary": "**Summary:**\n\nThe article \"Splice a Fibre\" from React Networks provides a practical example of the fibre optic splicing process. It outlines the key steps involved in creating a permanent, low-loss connection between two optical fibres.\n\nThe core procedure begins with **preparation**: stripping the protective coating from the fibre ends and precisely cleaving them to ensure perfectly flat, smooth end faces. The fibres are then aligned and **fused** together using a specialised fusion splicer, which melts the glass ends with an electric arc to form a single, continuous strand. Following the splice, the joint is protected with a **sleeve** to provide mechanical strength and prevent signal degradation.\n\nThe article emphasises that successful splicing requires precision, cleanliness, and the correct equipment to minimise signal loss (attenuation) and back reflection, which are critical for maintaining network performance. It presents splicing as a fundamental skill in fibre optic network installation, repair, and maintenance.",
    "chinese_title": "拼接光纤",
    "chinese_summary": "**摘要：**\n\nReact Networks的文章《光纤熔接》通过一个实际案例，详细介绍了光纤熔接的操作流程。文章阐述了在两段光纤之间建立永久性低损耗连接的关键步骤。\n\n核心操作始于**准备工作**：剥除光纤端部的保护层，并进行精确切割，以确保端面完全平整光滑。随后，将光纤对准并放入专用熔接机中**熔接**——通过电弧熔化玻璃端头，使其融合成一根连续的光纤。熔接完成后，使用**保护套管**加固接头，以提供机械强度并防止信号衰减。\n\n文章强调，成功的熔接需要精准的操作、清洁的环境和正确的设备，以最大限度减少信号损耗（衰减）和背向反射，这对维持网络性能至关重要。文章将熔接定位为光纤网络安装、维修和维护中的一项基本技能。"
  },
  {
    "id": "46351457",
    "title": "Mruby: Ruby for Embedded Systems",
    "url": "https://github.com/mruby/mruby",
    "summary": "**Summary:** mruby is a lightweight implementation of the Ruby programming language, designed for embedding in applications, particularly for use in embedded systems. It complies with part of the ISO standard and is largely compatible with Ruby 3.x syntax. The core distribution includes an interpreter (`mruby`), an interactive shell (`mirb`), and a compiler (`mrbc`) that can translate Ruby code into bytecode or C source files.\n\nDevelopers can obtain mruby by downloading a stable release or cloning the source from its GitHub repository. The project is built and managed using the Rake build system. It features a built-in package manager called `mrbgems` for creating extensions in C or Ruby, allowing for customization. Documentation for both the mruby API and C API can be generated and viewed.\n\nmruby is released under the MIT License. Contributors retain their copyright but agree to license their code under MIT as part of the \"mruby developers\" group. The project is community-driven, with contributions managed through GitHub issues and pull requests.",
    "chinese_title": "Mruby：面向嵌入式系统的Ruby语言",
    "chinese_summary": "**摘要：** mruby 是 Ruby 编程语言的轻量级实现，专为嵌入应用程序而设计，尤其适用于嵌入式系统。它遵循部分 ISO 标准，并与 Ruby 3.x 语法高度兼容。核心发行版包含解释器（`mruby`）、交互式 shell（`mirb`）以及可将 Ruby 代码编译为字节码或 C 源文件的编译器（`mrbc`）。\n\n开发者可通过下载稳定版本或从其 GitHub 仓库克隆源码获取 mruby。该项目使用 Rake 构建系统进行构建和管理，并内置名为 `mrbgems` 的包管理器，支持用 C 或 Ruby 创建扩展以实现定制化。mruby API 和 C API 的文档均可生成并查阅。\n\nmruby 基于 MIT 许可证发布。贡献者保留其版权，但作为“mruby 开发者”群体的一部分，同意将其代码按 MIT 许可证授权。该项目由社区驱动，通过 GitHub 议题和拉取请求管理贡献内容。"
  },
  {
    "id": "46403741",
    "title": "Cleartext Signatures Considered Harmful",
    "url": "https://gnupg.org/blog/20251226-cleartext-signatures.html",
    "summary": "This article argues that PGP \"cleartext signatures\" are a legacy and insecure format that should be avoided. While they allow text to be read without special tools, they are dangerously misleading.\n\nThe core problem is that the text displayed on a terminal is **not** necessarily what was signed. Terminal escape codes, UTF-8 look-alike characters, and the format's own escaping rules (like for lines starting with a dash) mean the visible text can differ from the verified data. To know what was actually signed, you must use a PGP tool (like `gpg --verify -o signed.txt`) to extract the canonical signed content.\n\nHistorically designed for early 1990s bulletin boards, cleartext signatures are prone to various spoofing attacks, such as fake armor headers or hidden delimiter lines, which can trick users. The author notes that the more secure PGP/MIME standard (for email) and detached signatures have been available for decades.\n\nThe key takeaway is: **Never assume what you see in a cleartext signature is what was signed.** For new work, use detached signatures (where the signature file is separate from the data) or PGP/MIME, and reserve cleartext signatures only for legacy purposes.",
    "chinese_title": "明文签名被认为是有害的",
    "chinese_summary": "本文认为，PGP“明文签名”是一种遗留且不安全的格式，应避免使用。虽然它们允许无需特殊工具即可阅读文本，但具有危险的误导性。\n\n核心问题在于，终端上显示的文本**不一定**是实际签名的内容。终端转义码、UTF-8相似字符以及格式自身的转义规则（例如以短横线开头的行）都意味着可见文本可能与验证数据不同。要了解实际签名的内容，必须使用PGP工具（如`gpg --verify -o signed.txt`）提取规范的签名内容。\n\n明文签名最初为20世纪90年代初的公告板设计，容易遭受各种欺骗攻击，例如伪造的封装头或隐藏的分隔行，这些都可能误导用户。作者指出，更安全的PGP/MIME标准（用于电子邮件）和分离式签名已存在数十年。\n\n关键要点是：**切勿假定你在明文签名中看到的内容就是实际签名的内容。** 对于新工作，请使用分离式签名（签名文件与数据分开）或PGP/MIME，仅将明文签名保留用于遗留用途。"
  },
  {
    "id": "46397609",
    "title": "Exe.dev",
    "url": "https://exe.dev/",
    "summary": "**Summary:**\n\nThe article introduces \"Exe.dev,\" a service that provides persistent, cloud-based Linux environments accessible via SSH. The key features highlighted are:\n\n*   **Persistent Disk:** User data and the state of the environment are saved between sessions, unlike ephemeral containers or temporary virtual machines.\n*   **Full Sudo Access:** Users have administrative (`sudo`) privileges, allowing for complete control over the environment to install software, modify system configurations, and run services.\n*   **Access Method:** The primary interface is through Secure Shell (SSH), using the command `ssh exe.dev` to connect.\n\nIn essence, Exe.dev offers a personal, always-on Linux server in the cloud with root-level access, designed for developers who need a stable, customizable remote workspace for projects, testing, or long-running processes.",
    "chinese_title": "Exe.dev",
    "chinese_summary": "**摘要：**\n\n本文介绍了“Exe.dev”服务，它提供可通过SSH访问的持久性云端Linux环境。其核心特性包括：\n\n*   **持久化磁盘：** 用户数据和环境状态在会话之间得以保存，不同于临时容器或虚拟机。\n*   **完整Sudo权限：** 用户拥有管理员（`sudo`）权限，可完全控制环境以安装软件、修改系统配置和运行服务。\n*   **访问方式：** 主要通过安全外壳（SSH）连接，使用命令 `ssh exe.dev` 进行访问。\n\n本质上，Exe.dev在云端提供了一个拥有根级别访问权限的个人化、持续运行的Linux服务器，专为需要稳定、可定制的远程工作空间进行项目开发、测试或运行长期进程的开发者设计。"
  },
  {
    "id": "46398906",
    "title": "Pre-commit hooks are broken",
    "url": "https://jyn.dev/pre-commit-hooks-are-fundamentally-broken/",
    "summary": "This article argues that pre-commit hooks are a fundamentally broken tool for code quality checks. The author demonstrates their unreliability through a narrative: a hook that checks Rust formatting fails because it runs on the working tree, not the staged changes. While this can be fixed by checking out the staged files to a temporary directory, new problems arise. The hook then blocks commits during a rebase of an older branch with unformatted code, and it fails entirely if a commit contains no Rust files.\n\nThe core issues are that pre-commit hooks run in contexts where they shouldn't (like interactive rebases) and cannot control the state of all branches or commits in a repository's history. This forces developers to use `--no-verify` frequently, undermining the hook's purpose.\n\nThe author strongly recommends using **pre-push hooks** instead, as they avoid these problems by running just before code is shared. Key advice for writing a pre-push hook includes: running checks on the staged index, ensuring checks are fast and reliable, keeping output quiet, and not automating hook setup. The only valid use for a pre-commit hook, in the author's view, is to prevent accidental commits of credentials.",
    "chinese_title": "预提交钩子已损坏",
    "chinese_summary": "本文认为，预提交钩子本质上是一种存在缺陷的代码质量检查工具。作者通过一个实例揭示了其不可靠性：一个用于检查Rust代码格式的钩子之所以失败，是因为它在工作树而非暂存区上运行。虽然可以通过将暂存文件检出到临时目录来解决此问题，但新的问题随之而来——当对包含未格式化代码的旧分支进行交互式变基时，该钩子会阻止提交；而如果提交中不包含Rust文件，它则会完全失效。\n\n核心问题在于，预提交钩子会在不应运行的场景（如交互式变基）中执行，且无法控制仓库历史中所有分支或提交的状态。这迫使开发者频繁使用`--no-verify`跳过检查，从而违背了钩子的设计初衷。\n\n作者强烈建议改用**预推送钩子**，因其仅在代码共享前运行，能有效规避上述问题。编写预推送钩子的关键建议包括：针对暂存区进行检查、确保检查快速可靠、保持输出简洁、避免自动化钩子设置。作者认为，预提交钩子唯一合理的用途是防止意外提交凭证信息。"
  },
  {
    "id": "46376608",
    "title": "Detect memory leaks of C extensions with psutil and psleak",
    "url": "https://gmpy.dev/blog/2025/psutil-heap-introspection-apis",
    "summary": "This article introduces new tools in psutil 7.2.0 for detecting memory leaks in Python C extensions, which are notoriously difficult to find using traditional Python memory tools. These leaks occur when C code allocates native memory (via `malloc` or `mmap`) but fails to free it, and they often don't appear in standard metrics like RSS or Python's `tracemalloc`.\n\nThe new `psutil.heap_info()` function provides direct insight into the platform's native allocator, reporting `heap_used` (small allocations) and `mmap_used` (large allocations). The companion `heap_trim()` function helps reduce allocator noise for cleaner measurements.\n\nThe recommended workflow is to take a heap snapshot before and after repeatedly calling a C extension function. A consistent increase in the reported bytes indicates a leak. To automate this process, the author created **psleak**, a PyPI package that integrates this methodology into a unit testing framework, allowing developers to easily write tests that fail if their C code leaks memory.\n\nIn summary, these new capabilities transform psutil from a monitoring library into a practical debugging tool, closing a significant observability gap for Python projects that depend on C extensions.",
    "chinese_title": "使用psutil和psleak检测C扩展的内存泄漏",
    "chinese_summary": "本文介绍了psutil 7.2.0中用于检测Python C扩展内存泄漏的新工具，这类泄漏传统上很难通过Python内存工具发现。当C代码分配原生内存（通过`malloc`或`mmap`）却未能释放时就会发生此类泄漏，且通常不会体现在RSS或Python的`tracemalloc`等标准指标中。\n\n新增的`psutil.heap_info()`函数可直接探查平台原生分配器，报告`heap_used`（小型分配）和`mmap_used`（大型分配）。配套的`heap_trim()`函数则有助于减少分配器干扰，获得更清晰的测量结果。\n\n推荐工作流程是在重复调用C扩展函数前后分别获取堆内存快照。若报告字节数持续增长则表明存在泄漏。为自动化此过程，作者创建了PyPI包**psleak**，将该方法集成至单元测试框架，使开发者能够轻松编写测试用例——当C代码存在内存泄漏时测试将自动失败。\n\n总之，这些新功能将psutil从监控库转变为实用的调试工具，为依赖C扩展的Python项目填补了重要的可观测性缺口。"
  },
  {
    "id": "46397379",
    "title": "Always bet on text (2014)",
    "url": "https://graydon2.dreamwidth.org/193447.html",
    "summary": "**Summary of \"Always Bet on Text\" (2014)**\n\nThe core argument of this article is that **plain text** is the most durable, flexible, and essential medium for human communication and computing. The author, Graydon Hoare, posits that while flashy graphical and multimedia formats come and go, text remains the fundamental, \"lowest-common-denominator\" tool that underpins all digital systems.\n\nKey points include:\n*   **Universality and Longevity:** Text is the universal interface. Every system, no matter how advanced, can import and export text. It is immune to the obsolescence of proprietary software or hardware platforms, ensuring information remains accessible for decades.\n*   **Power and Flexibility:** Text is not just for documents. It is the foundational material of programming (source code), configuration, data interchange (like JSON, XML), and communication protocols. Its simplicity allows it to be easily parsed, transformed, searched, and version-controlled by both humans and machines.\n*   **Critique of Non-Text Alternatives:** The article critiques trends that move away from text, such as complex binary file formats, \"applified\" environments that lock data away, or visual programming tools that sacrifice the precision and power of textual code. These are seen as fragile and limiting.\n*   **Central Thesis:** For any project intended to last, one should \"always bet on text.\" Storing data and logic in a textual, human-readable format is the best guarantee of future accessibility, interoperability, and editability. It is the bedrock upon which all other digital experiences are built.\n\nIn essence, the article is a defense of textual representation as the most resilient and powerful technology in our digital toolkit.",
    "chinese_title": "永远押注于文本（2014）",
    "chinese_summary": "**《永远押注文本》（2014）摘要**\n\n本文的核心论点是：**纯文本**是人类交流与计算中最持久、最灵活且最基础的媒介。作者格雷顿·霍尔认为，尽管花哨的图形和多媒体格式层出不穷，文本始终是支撑所有数字系统的基础性“最小公分母”工具。\n\n主要观点包括：\n*   **普遍性与持久性：** 文本是通用接口。任何系统，无论多么先进，都能导入和导出文本。它不受专有软件或硬件平台淘汰的影响，确保信息在数十年后仍可访问。\n*   **能力与灵活性：** 文本不仅用于文档。它是编程（源代码）、配置、数据交换（如JSON、XML）和通信协议的基础材料。其简洁性使得人和机器都能轻松解析、转换、搜索及进行版本控制。\n*   **对非文本替代方案的批评：** 文章批评了背离文本的趋势，例如复杂的二进制文件格式、将数据锁死的“应用化”环境，或牺牲了文本代码的精确性与强大功能的可视化编程工具。这些都被视为脆弱且局限的。\n*   **中心论点：** 对于任何旨在长期存在的项目，都应“永远押注文本”。以人类可读的文本格式存储数据和逻辑，是未来可访问性、互操作性和可编辑性的最佳保障。它是构建所有其他数字体验的基石。\n\n本质上，本文旨在捍卫文本表示法，将其视为我们数字工具包中最具韧性和最强大的技术。"
  },
  {
    "id": "46403048",
    "title": "This PNG shows a different version when loaded in Chrome than in Safari",
    "url": "https://lr0.org/blog/p/pngchanges/",
    "summary": "This article details a troubleshooting case where a PNG image appears washed out in Chrome but normal in Safari and desktop apps. The core issue is that the PNG contains an embedded ICC color profile (likely for a wide-gamut color space like Display-P3), which Chrome correctly honors for color-accurate rendering. In contrast, many desktop applications and Safari often ignore or approximate these profiles, displaying the image in a standard sRGB color space, which creates the visual discrepancy.\n\nThe author's initial debugging attempts—stripping metadata, adjusting gamma, and removing PNG chunks—all failed because the problem was not in the pixel data itself but in the color space interpretation. The solution was not to strip the ICC profile but to convert the image's pixels from the embedded color space to sRGB using a tool like ImageMagick, ensuring consistent display across all browsers and applications.\n\nThe key takeaway is that modern color management can lead to inconsistent visual results. Chrome's behavior is technically correct, while other apps provide a \"helpful lie\" by ignoring profiles. To ensure web compatibility, images with non-sRGB color profiles must be properly converted to sRGB.",
    "chinese_title": "此PNG图片在Chrome与Safari浏览器中加载时显示版本不同。",
    "chinese_summary": "本文详述了一个故障排除案例：某PNG图片在Chrome中显示色彩发白，而在Safari及桌面应用中却显示正常。核心问题在于该PNG嵌入了ICC色彩配置文件（可能对应Display-P3等广色域色彩空间），Chrome会遵循此配置进行精确色彩渲染；而许多桌面应用和Safari往往忽略或近似处理这些配置，将图像显示为标准sRGB色彩空间，从而产生视觉差异。\n\n作者最初的调试尝试——清除元数据、调整伽马值、移除PNG数据块——均未奏效，因为问题并非源于像素数据本身，而在于色彩空间的解析方式。解决方案不是删除ICC配置文件，而是使用ImageMagick等工具将图像像素从嵌入的色彩空间转换为sRGB，从而确保所有浏览器和应用中的显示效果一致。\n\n关键结论是：现代色彩管理可能导致不一致的视觉效果。Chrome的处理方式在技术上是正确的，而其他应用通过忽略配置文件提供了“善意的谎言”。为确保网页兼容性，带有非sRGB色彩配置文件的图像必须正确转换为sRGB格式。"
  },
  {
    "id": "46364567",
    "title": "Some Junk Theorems in Lean",
    "url": "https://github.com/James-Hanson/junk-theorems-in-lean",
    "summary": "This article presents a collection of \"junk theorems\" in Lean 4 and Mathlib—formally verified statements that are mathematically nonsensical or surprising. These arise from the interaction between type theory and specific design choices in Lean.\n\nKey examples include:\n*   **Definitional artifacts:** Theorems like \"1/2 = 0\" or \"ζ(1) = ½(γ − log 4π)\" stem from Lean's convention of defining partial functions (like division by zero) to return default values (like 0) to ensure totality.\n*   **Type-theoretic quirks:** Some results, like the equality of proofs of unrelated propositions, follow from how Lean treats propositions as types and proof irrelevance.\n*   **Lean-specific phenomena:** Unique to Lean are theorems where transitivity of equality fails (e.g., a = b and b = c, but a and c are not comparable as they have different types), a consequence of its handling of quotient types. Another shows how low-level compiler assumptions can lead to inconsistency in edge cases.\n\nThe article distinguishes between theorems that are byproducts of standard mathematical definitions in Mathlib, those inherent to type-theoretic foundations, and those specific to Lean's implementation. It highlights how proof assistants, while rigorous, can produce valid proofs of statements that defy conventional mathematical intuition.",
    "chinese_title": "Lean中的一些无用定理",
    "chinese_summary": "本文介绍了一系列Lean 4和Mathlib中的“垃圾定理”——这些经过形式化验证的命题在数学上要么毫无意义，要么令人惊讶。它们源于类型理论与Lean特定设计选择之间的相互作用。\n\n主要例子包括：\n*   **定义性产物**：诸如“1/2 = 0”或“ζ(1) = ½(γ − log 4π)”等定理，源于Lean为确保函数完全性而将偏函数（如除零运算）默认返回值（如0）的约定。\n*   **类型理论特性**：某些结果，如无关命题的证明相等性，源于Lean将命题视为类型并采用证明无关性的处理方式。\n*   **Lean特有现象**：仅出现在Lean中的定理包括等式传递性失效的情况（例如a = b且b = c，但a和c因类型不同而无法比较），这是其处理商类型的结果。另一例展示了底层编译器假设如何在边缘情况下导致不一致性。\n\n文章区分了三种情况：Mathlib标准数学定义的副产品、类型理论基础固有的现象，以及Lean实现特有的现象。它强调了证明助手虽然严谨，却可能产生违背传统数学直觉的命题的有效证明。"
  },
  {
    "id": "46398201",
    "title": "QNX Self-Hosted Developer Desktop",
    "url": "https://devblog.qnx.com/qnx-self-hosted-developer-desktop-initial-release/",
    "summary": "The QNX team has released a self-hosted developer desktop environment running on QNX 8.0. This virtual machine, designed to simplify development and application porting, includes a full XFCE desktop on Wayland, essential development tools (like clang, gcc, Python, and git), a web browser, popular code editors (Geany, Emacs, Neovim), and preloaded sample projects.\n\nCurrently available as a QEMU image for Ubuntu 22.04/24.04, it can be installed via the QNX Software Center with a free license. The initial release focuses on core functionality, with plans to expand support to Windows, macOS, native x86, Raspberry Pi, and CI/CD integration in future updates.\n\nThe team encourages feedback and offers support through the QNX Discord and Reddit communities.",
    "chinese_title": "QNX自托管开发者桌面",
    "chinese_summary": "QNX团队发布了运行于QNX 8.0的自托管开发者桌面环境。该虚拟机旨在简化开发与应用程序移植，包含完整的Wayland驱动XFCE桌面、核心开发工具（如clang、gcc、Python和git）、网页浏览器、常用代码编辑器（Geany、Emacs、Neovim）以及预置示例项目。\n\n目前该环境以QEMU镜像形式提供，支持Ubuntu 22.04/24.04系统，用户可通过QNX软件中心使用免费许可证进行安装。初始版本聚焦核心功能，未来计划扩展对Windows、macOS、原生x86平台、树莓派及CI/CD集成的支持。\n\n团队鼓励用户通过QNX Discord和Reddit社区提供反馈并获取技术支持。"
  },
  {
    "id": "46348251",
    "title": "Langjam-Gamejam Devlog: Making a language, compiler, VM and 5 games in 52 hours",
    "url": "https://github.com/Syn-Nine/gar-lang/blob/main/DEVLOG.md",
    "summary": "This article details the author's participation in Langjam, a game jam requiring participants to create a language, compiler, virtual machine, and five games in just 52 hours.\n\nThe project, named **Syn-Nine**, involved developing **Gar-lang**, a stack-based, concatenative programming language inspired by Forth. The author built a compiler in Rust that translated Gar-lang into bytecode for a custom virtual machine, also written in Rust. The VM was designed to be embedded into games.\n\nDespite the extreme time constraint, the author successfully created five small games to demonstrate the language:\n1.  A simple \"Hello World\" display.\n2.  A number-guessing game.\n3.  A text-based adventure.\n4.  A falling-block puzzle game.\n5.  A top-down maze game.\n\nThe article highlights the intense challenge of the jam, the technical decisions behind the language and VM design, and the practical demonstration of Gar-lang's capabilities through the completed games. The source code was made publicly available on GitHub.",
    "chinese_title": "Langjam-Gamejam开发日志：在52小时内创造一门语言、编译器、虚拟机及5款游戏",
    "chinese_summary": "本文详述了作者参与Langjam的经历，这是一项要求参与者在短短52小时内创建一门语言、编译器、虚拟机以及五款游戏的开发挑战。\n\n该项目名为**Syn-Nine**，其中开发了**Gar-lang**——一门受Forth启发的基于栈的拼接式编程语言。作者使用Rust编写了编译器，将Gar-lang转换为字节码，并在同样用Rust编写的自定义虚拟机中运行。该虚拟机设计为可嵌入游戏中。\n\n尽管时间极其紧张，作者仍成功创建了五款小型游戏以展示该语言的功能：\n1.  简单的“Hello World”显示程序。\n2.  猜数字游戏。\n3.  文字冒险游戏。\n4.  下落方块解谜游戏。\n5.  俯视角迷宫游戏。\n\n文章重点探讨了本次开发挑战的极高难度、语言与虚拟机设计背后的技术决策，以及通过完成的游戏对Gar-lang功能的实际展示。项目源代码已在GitHub上公开。"
  },
  {
    "id": "46391514",
    "title": "Package managers keep using Git as a database, it never works out",
    "url": "https://nesbitt.io/2025/12/24/package-managers-keep-using-git-as-a-database.html",
    "summary": "This article argues that using Git as a database for package registries is a flawed approach that consistently fails to scale. While initially attractive for its free version history and review workflows, it leads to significant performance and infrastructure problems as registries grow.\n\nThe core issue is that Git is designed for synchronizing source code, not for fast, on-demand metadata queries. This mismatch forces package managers like Cargo, Homebrew, and CocoaPods to eventually abandon Git for HTTP-based solutions (sparse protocols, JSON APIs, or CDNs) to avoid slow clones, massive disk usage, and CI bottlenecks. Vcpkg remains trapped by its Git-based architecture, causing errors in CI environments that use shallow clones.\n\nThe problems stem from Git inheriting filesystem limitations—such as directory slowdowns, case-sensitivity conflicts, and path length restrictions—and lacking essential database features like constraints, indexing, and efficient locking. The predictable progression involves implementing complex workarounds only to eventually migrate to a more suitable technology.\n\nThe article concludes that while Git excels at its original purpose of distributed source control, it is ill-suited for package registry backends, a lesson repeatedly learned by major package managers as they scale.",
    "chinese_title": "包管理器总是把Git当数据库用，这从来都行不通。",
    "chinese_summary": "本文认为，将Git用作包注册表的数据库是一种存在缺陷的方法，始终无法有效扩展。虽然其免费的版本历史和审查工作流最初颇具吸引力，但随着注册表规模增长，会引发严重的性能和基础设施问题。\n\n核心问题在于Git是为同步源代码而设计的，并不适用于快速、按需的元数据查询。这种不匹配迫使Cargo、Homebrew和CocoaPods等包管理器最终放弃Git，转而采用基于HTTP的解决方案（稀疏协议、JSON API或CDN），以避免缓慢的克隆、巨大的磁盘占用和CI瓶颈。Vcpkg仍受困于其基于Git的架构，导致在使用浅克隆的CI环境中频繁出错。\n\n这些问题源于Git继承了文件系统的局限性——例如目录访问减速、大小写敏感冲突和路径长度限制——同时缺乏数据库的关键特性，如约束、索引和高效锁定机制。可预见的演进路径是：先实施复杂的变通方案，最终仍不得不迁移到更合适的技术。\n\n文章总结指出，尽管Git在其最初设计的分布式源代码控制领域表现出色，但并不适合作为包注册表的后端。这是各大包管理器在扩展过程中反复验证的教训。"
  },
  {
    "id": "46397991",
    "title": "Publishing your work increases your luck",
    "url": "https://github.com/readme/guides/publishing-your-work",
    "summary": "This article argues that actively sharing your work publicly is a powerful way to increase your \"luck\"—defined as unexpected, positive opportunities. The core idea is based on the \"Luck Surface Area\" formula: **Luck = [Doing Things] x [Telling People]**.\n\nFirst, you must **do the work**, whether that's pursuing personal curiosities or leveraging professional expertise. The author encourages readers to recognize the value in what they already know and build, even if it feels commonplace to them.\n\nSecond, you must **publish that work**. This means overcoming fears of criticism or imperfection and sharing your process, learnings, and creations on platforms like blogs, social media, or GitHub. Publishing is a skill that builds with practice and invites others into your journey.\n\nBy combining consistent creation with public sharing, you expand your visibility and reputation. This larger \"surface area\" makes it more likely for serendipitous opportunities to find you, such as job offers, speaking invitations, collaboration requests, or a growing audience for your projects. While putting yourself out there can be daunting, the potential rewards and silent support from an admiring community far outweigh the risks.",
    "chinese_title": "发表作品能增加你的运气。",
    "chinese_summary": "本文认为，主动公开分享你的工作是增加“运气”的强大方式——这里的“运气”被定义为意想不到的积极机遇。其核心思想基于“运气表面积”公式：**运气 = [做事] × [告诉他人]**。\n\n首先，你必须**付诸行动**，无论是追求个人兴趣还是发挥专业特长。作者鼓励读者认识到自己已有知识和成果的价值，即使这些对他们来说看似平常。\n\n其次，你必须**公开发布这些成果**。这意味着要克服对批评或不完美的恐惧，在博客、社交媒体或GitHub等平台上分享你的过程、心得与创作。发布是一项通过练习培养的技能，它能邀请他人参与你的旅程。\n\n通过将持续创作与公开分享相结合，你可以扩大自己的可见度和声誉。这个更大的“表面积”会让更多意外机遇找到你，例如工作邀约、演讲邀请、合作请求，或是项目受众的增长。虽然展示自我可能令人畏惧，但潜在的回报以及来自欣赏者社群的默默支持，远胜于其中的风险。"
  },
  {
    "id": "46365726",
    "title": "The best things and stuff of 2025",
    "url": "https://blog.fogus.me/2025/12/23/the-best-things-and-stuff-of-2025.html",
    "summary": "In his 2025 year-in-review, Michael Fogus (fogus.me) shares his discoveries across technology, literature, music, film, and games. He highlights insightful articles on topics like recursive real arithmetic and the history of Magic: The Gathering, and notes his own increased writing on non-technical subjects like weird fiction and board games on his blog.\n\nHis reading list was dominated by fiction, with standout books including the mystery *The Eye of Osiris*, the unfinished Dickens novel *The Mystery of Edwin Drood*, and the subversive sci-fi novel *We Who Are About To…*. Musically, he discovered ambient artists like lovesliescrushing and Maria Chiara Argirò, while his favorite new film was the horror movie *Weapons*.\n\nIn gaming, he enjoyed the historical card game Jacoby and the strategic board game *East India Companies*. Professionally, his work remained focused on Clojure (his 16th year using it) and Java, while his personal exploration included the concatenative language Joy. The post reflects a year of deep, eclectic curiosity across multiple creative and technical domains.",
    "chinese_title": "2025年最佳事物与精选",
    "chinese_summary": "迈克尔·福格斯（fogus.me）在2025年度回顾中，分享了自己在技术、文学、音乐、电影和游戏领域的发现。他重点推荐了关于递归实数运算和《万智牌》历史等主题的深度文章，并提到自己在博客中增加了对怪诞小说和桌游等非技术主题的写作。\n\n他的阅读清单以小说为主，包括悬疑作品《奥西里斯之眼》、狄更斯未完成的《埃德温·德鲁德之谜》以及颠覆性科幻小说《我们即将…》。音乐方面，他发掘了lovesliescrushing和Maria Chiara Argirò等氛围音乐艺术家，而年度最爱电影是恐怖片《武器》。\n\n游戏领域，他喜欢历史卡牌游戏《雅各比》和策略桌游《东印度公司》。专业上，他仍专注于Clojure（使用第16年）和Java，个人探索则涉及拼接式语言Joy。这篇总结折射出他一年来跨越多个创意与技术领域的广泛而深入的好奇心。"
  },
  {
    "id": "46341904",
    "title": "Faster practical modular inversion",
    "url": "https://purplesyringa.moe/blog/faster-practical-modular-inversion/",
    "summary": "This article introduces an optimized version of the binary extended Euclidean algorithm (Stein's algorithm) for computing modular inverses, addressing a gap noted by Lemire, who found previous implementations slower than the textbook Euclidean method.\n\nThe core algorithm efficiently computes the greatest common divisor (GCD) using bit shifts and subtractions when the modulus is odd. To extend it for modular inversion, the author tracks coefficients as fractions with a shared power-of-two denominator, avoiding non-integer issues. For 32-bit inputs, this yields a fast implementation using Montgomery reduction to finalize the result.\n\nFor 64-bit inputs, a key challenge is that coefficients grow to 128 bits, slowing operations. The solution uses a \"reset\" technique: coefficients are periodically recomputed and reduced modulo the modulus, keeping them within 64 bits. This is further optimized by packing two 32-bit coefficients into a single 64-bit integer, enabling efficient updates.\n\nBenchmarks show the optimized algorithm is typically 1.3–2 times faster than the textbook method across various architectures, though results can vary due to compiler and microarchitectural differences. The implementation focuses on modular inversion; solving general linear Diophantine equations may require additional steps. Code is available in a Rust library.",
    "chinese_title": "更快的实用模逆运算",
    "chinese_summary": "本文介绍了一种用于计算模逆元的优化版二进制扩展欧几里得算法（Stein算法），以解决Lemire指出的现有实现比经典欧几里得方法更慢的问题。该核心算法在模数为奇数时，通过位移和减法高效计算最大公约数（GCD）。为扩展至模逆计算，作者采用以2的幂为公共分母的分数形式追踪系数，从而避免非整数问题。对于32位输入，该算法结合蒙哥马利约减完成最终计算，实现了快速运算。\n\n针对64位输入，关键挑战在于系数会增长至128位，导致运算速度下降。解决方案采用“重置”技术：定期重新计算系数并对其取模，使系数保持在64位以内。通过将两个32位系数打包至单个64位整数中，进一步优化了更新效率。\n\n基准测试表明，优化后的算法在不同架构上通常比经典方法快1.3至2倍，但受编译器和微架构差异影响，结果可能有所波动。该实现专注于模逆计算；求解一般线性丢番图方程可能需要额外步骤。相关代码已发布于Rust库中。"
  },
  {
    "id": "46401539",
    "title": "Apple releases open-source model that instantly turns 2D photos into 3D views",
    "url": "https://github.com/apple/ml-sharp",
    "summary": "**Summary:**\n\nApple has released SHARP, an open-source AI model that can generate a 3D scene from a single 2D photograph in under a second on a standard GPU. The system uses a neural network to predict the parameters for a \"3D Gaussian\" representation of the scene, which can then be rendered in real-time to produce high-quality, photorealistic images from new viewpoints.\n\nKey advancements include state-of-the-art performance, improving image quality metrics (LPIPS and DISTS) by 21–43% over prior models while being roughly 1,000 times faster. It also generalizes well across different datasets without needing specific training.\n\nThe software is available for public use. After a simple installation, users can run predictions via a command-line interface to create 3D Gaussian Splatting (.ply) files. These files are compatible with various public 3D renderers. An optional feature allows for rendering video fly-throughs of the 3D scene, though this currently requires a CUDA GPU.\n\nThe research paper is available on arXiv, and the model is released under specific open-source licenses for both code and weights.",
    "chinese_title": "苹果发布开源模型，可将2D照片即时转换为3D视图。",
    "chinese_summary": "**摘要：**\n\n苹果公司发布了SHARP开源AI模型，该模型能在标准GPU上于一秒内从单张2D照片生成3D场景。该系统通过神经网络预测场景的“3D高斯”表示参数，随后可实时渲染生成新视角下的高质量逼真图像。\n\n关键进展包括：实现业界领先的性能，在图像质量指标（LPIPS和DISTS）上较先前模型提升21%-43%，同时速度提升约1000倍。该模型无需针对性训练即可在不同数据集上良好泛化。\n\n该软件已向公众开放。简单安装后，用户可通过命令行界面运行预测，生成兼容各类公共3D渲染器的3D高斯泼溅文件（.ply格式）。可选功能支持渲染3D场景的飞览视频，但目前需配备CUDA显卡。\n\n研究论文发布于arXiv平台，模型代码与权重均采用特定开源协议发布。"
  }
]